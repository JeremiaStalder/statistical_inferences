<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 7 Confidence Intervals | Improving Your Statistical Inferences</title>
<meta name="author" content="DaniÃ«l Lakens">
<meta name="description" content="When we report point estimates, we should acknowledge and quantify the uncertainty in these estimates. Confidence intervals provide a way to quantify the precision of an estimate. By reporting an...">
<meta name="generator" content="bookdown 0.25 with bs4_book()">
<meta property="og:title" content="Chapter 7 Confidence Intervals | Improving Your Statistical Inferences">
<meta property="og:type" content="book">
<meta property="og:url" content="https://lakens.github.io/statistical_inferences/confint.html">
<meta property="og:image" content="https://lakens.github.io/statistical_inferences/images/logo.png">
<meta property="og:description" content="When we report point estimates, we should acknowledge and quantify the uncertainty in these estimates. Confidence intervals provide a way to quantify the precision of an estimate. By reporting an...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 7 Confidence Intervals | Improving Your Statistical Inferences">
<meta name="twitter:description" content="When we report point estimates, we should acknowledge and quantify the uncertainty in these estimates. Confidence intervals provide a way to quantify the precision of an estimate. By reporting an...">
<meta name="twitter:image" content="https://lakens.github.io/statistical_inferences/images/logo.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/_Open%20Sans-0.4.1/font.css" rel="stylesheet">
<link href="libs/_Fira%20Code-0.4.1/font.css" rel="stylesheet">
<link href="libs/_Montserrat-0.4.1/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-0MK2WTGRM3"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-0MK2WTGRM3');
    </script><link rel="shortcut icon" href="images/favicon.ico">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="include/style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Improving Your Statistical Inferences</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Introduction</a></li>
<li><a class="" href="pvalue.html"><span class="header-section-number">1</span> Using p-values to test a hypothesis</a></li>
<li><a class="" href="errorcontrol.html"><span class="header-section-number">2</span> Error control</a></li>
<li><a class="" href="likelihoods.html"><span class="header-section-number">3</span> Likelihoods</a></li>
<li><a class="" href="bayes.html"><span class="header-section-number">4</span> Bayesian statistics</a></li>
<li><a class="" href="questions.html"><span class="header-section-number">5</span> Asking Statistical Questions</a></li>
<li><a class="" href="effectsize.html"><span class="header-section-number">6</span> Effect Sizes</a></li>
<li><a class="active" href="confint.html"><span class="header-section-number">7</span> Confidence Intervals</a></li>
<li><a class="" href="power.html"><span class="header-section-number">8</span> Sample Size Justification</a></li>
<li><a class="" href="equivalencetest.html"><span class="header-section-number">9</span> Equivalence Testing and Interval Hypotheses</a></li>
<li><a class="" href="sequential.html"><span class="header-section-number">10</span> Sequential Analysis</a></li>
<li><a class="" href="meta.html"><span class="header-section-number">11</span> Meta-analysis</a></li>
<li><a class="" href="bias.html"><span class="header-section-number">12</span> Bias detection</a></li>
<li><a class="" href="prereg.html"><span class="header-section-number">13</span> Preregistration and Transparency</a></li>
<li><a class="" href="computationalreproducibility.html"><span class="header-section-number">14</span> Computational Reproducibility</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/Lakens/statistical_inferences">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><span class="Z3988" title="url_ver=Z39.88-2004&amp;ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fzotero.org%3A2&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adc&amp;rft.type=webpage&amp;rft.title=Improving%20Your%20Statistical%20Inferences&amp;rft.rights=CC-BY-NC-SA&amp;rft.description=This%20open%20educational%20resource%20contains%20information%20to%20improve%20statistical%20inferences%2C%20design%20better%20experiments%2C%20and%20report%20scientific%20research%20more%20transparently.&amp;rft.identifier=https%3A%2F%2Fdoi.org%2F10.5281%2Fzenodo.6409077&amp;rft.aufirst=Dani%C3%ABl&amp;rft.aulast=Lakens&amp;rft.au=Dani%C3%ABl%20Lakens&amp;rft.date=2022&amp;rft.language=en"></span>
<div id="confint" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> Confidence Intervals<a class="anchor" aria-label="anchor" href="#confint"><i class="fas fa-link"></i></a>
</h1>
<p>When we report point estimates, we should acknowledge and quantify the uncertainty in these estimates. Confidence intervals provide a way to quantify the precision of an estimate. By reporting an estimate with a confidence interval, results are reported within a range of value that contain the true value of the parameter with a desired percentage. For example, when we report an effect size estimate with a 95% confidence interval, the expectation is that the interval is wide enough such that 95% of the time the range of values around the estimate contains the true parameter value.</p>
<div id="population-vs.-sample" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Population vs. Sample<a class="anchor" aria-label="anchor" href="#population-vs.-sample"><i class="fas fa-link"></i></a>
</h2>
<p>In statistics, we differentiate between the population and the sample. The population is everyone you are interested in, such as all people in the world, elderly who are depressed, or people who buy innovative products. Your sample is everyone you were able to measure from the population you are interested in. We similarly distinguish between a parameter and a statistic. A parameter is a characteristic of the population, while a statistic is a characteristic of a sample. Sometimes, you have data about your entire population. For example, we have measured the height of all the people who have ever walked on the moon. We can calculate the average height of these twelve individuals, and so we know the true parameter. We do not need inferential statistics. However, we do not know the average height of all people who have ever walked on the earth. Therefore, we need to estimate this parameter, using a statistic based on a sample. Although it is rare that a study includes the entire population, it is not impossible, as illustrated in Figure <a href="confint.html#fig:population">7.1</a>.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:population"></span>
<img src="images/population.png" alt="Example of a registry-based study in which the entire population was included in the study. From https://doi.org/10.1093/ije/dyab066" width="100%"><p class="caption">
Figure 7.1: Example of a registry-based study in which the entire population was included in the study. From <a href="https://doi.org/10.1093/ije/dyab066" class="uri">https://doi.org/10.1093/ije/dyab066</a>
</p>
</div>
<p>When the entire population is measured there is no need to perform a hypothesis test. After all, there is no population to generalize to (although it is possible to argue we are still making an inference, even when the entire population is observed, because we have observed a <em>metaphorical population</em> from one of many possible worlds, see <span class="citation">D. Spiegelhalter (<a href="references.html#ref-spiegelhalter_art_2019" role="doc-biblioref">2019</a>)</span>). When data from the entire population has been collected, the population effect size is known and there is no confidence interval to compute. If the total population size is known, but not measured completely, then the confidence interval width should shrink to zero the closer a study gets to measuring the entire population. This is known as the finite population correction factor for the variance of the estimator <span class="citation">(<a href="references.html#ref-kish_survey_1965" role="doc-biblioref">Kish, 1965</a>)</span>. The variance of a sample mean is <span class="math inline">\(\sigma^2/n\)</span>, which for finite populations is multiplied by the finite population correction factor of the standard error:
<span class="math display">\[FPC = \sqrt{\frac{(N - n)}{(N-1)}}\]</span>
where <em>N</em> is the size of the population, and <em>n</em> is the size of the sample. When <em>N</em> is much larger than <em>n</em>, the correction factor will be close to 1 (and therefore this correction is typically ignored when populations are very large, even when populations are finite), and will not have a noticeable effect on the variance. When the total population is measured the correction factor is 0, such that the variance becomes 0 as well. For example, when the total population consists of 100 top athletes, and data is collected from a sample of 35 athletes, the finite population correction is <span class="math inline">\(\sqrt{(100 - 35)/(100-1)}\)</span> = 0.81. The <code>superb</code> R package can compute population corrected confidence intervals <span class="citation">(<a href="references.html#ref-cousineau_superb_2019" role="doc-biblioref">Cousineau &amp; Chiasson, 2019</a>)</span>.</p>
</div>
<div id="what-is-a-confidence-interval" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> What is a Confidence Interval?<a class="anchor" aria-label="anchor" href="#what-is-a-confidence-interval"><i class="fas fa-link"></i></a>
</h2>
<p>Confidence intervals are a statement about the percentage of confidence intervals that contain the true parameter value. This behavior of confidence intervals is nicely visualized on this website by Kristoffer Magnusson: <a href="http://rpsychologist.com/d3/CI/" class="uri">http://rpsychologist.com/d3/CI/</a>. In Figure <a href="confint.html#fig:cisim">7.2</a> We see blue dots that represent means from a sample, and that fall around a red vertical line, which represents the true value of the parameter in the population. Due to variation in the sample, the estimates do not all fall on the red line. The horizontal lines around the blue dots are the confidence intervals. By default, the visualization shows 95% confidence intervals. Most of the lines are black (which means the confidence interval overlaps with the red line indication the true population value), but some are red (indicating they do not capture the true population value). In the long run, 95% of the horizontal bars will be black, and 5% will be red.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cisim"></span>
<img src="images/cisim.png" alt="Series of simulated point estimates and confidence intervals" width="100%"><p class="caption">
Figure 7.2: Series of simulated point estimates and confidence intervals
</p>
</div>
<p>We can now see what is meant by the sentence âConfidence intervals are a statement about the percentage of confidence intervals that contain the true parameter valueâ. In the long run, for 95% of the samples, the red line (the population parameter) is contained within the 95% confidence interval around the sample mean, and in 5% of the confidence intervals this is not true. As we will see when we turn to the formula for confidence intervals, the width of a confidence interval depends on the sample size and the standard deviation. The larger the sample size, the smaller the confidence intervals.</p>
</div>
<div id="relatCIp" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> The relation between confidence intervals and <em>p</em>-values<a class="anchor" aria-label="anchor" href="#relatCIp"><i class="fas fa-link"></i></a>
</h2>
<p>There is a direct relationship between the CI around an effect size and statistical significance of a null-hypothesis significance test. For example, if an effect is statistically significant (<em>p</em> &lt; 0.05) in a two-sided independent <em>t</em>-test with an alpha of .05, the 95% CI for the mean difference between the two groups will not include zero. Confidence intervals are sometimes said to be more informative than <em>p</em>-values, because they do not only provide information about whether an effect is statistically significant (i.e., when the confidence interval does not overlap with the value representing the null hypothesis), but also communicate the precision of the effect size estimate. This is true, but as mentioned in the chapter on <a href="pvalue"><em>p</em>-values</a> it is still recommended to add exact <em>p</em>-values, which facilitates the re-use of results for secondary analyses <span class="citation">(<a href="references.html#ref-appelbaum_journal_2018" role="doc-biblioref">Appelbaum et al., 2018</a>)</span>, and allows other researchers to compare the <em>p</em>-value to an alpha level they would have preferred to use <span class="citation">(<a href="references.html#ref-lehmann_testing_2005" role="doc-biblioref">Lehmann &amp; Romano, 2005</a>)</span>.</p>
<p>In order to maintain the direct relationship between a confidence interval and a <em>p</em>-value it is necessary to adjust the confidence interval level whenever the alpha level is adjusted. For example, if an alpha level of 5% is corrected for three comparisons to 0.05/3 - 0.0167, the corresponding confidence interval would be a 1 - 0.0167 = 0.9833 confidence interval. Similarly, if a <em>p</em>-value is computed for a one-sided <em>t</em>-test, there is only an upper or lower limit of the interval, and the other end of the interval ranges to ââ or â.</p>
<p>To maintain a direct relationship between an <em>F</em>-test and its confidence interval, a 90% CI for effect sizes from an <em>F</em>-test should be provided. The reason for this is explained by <a href="http://core.ecu.edu/psyc/wuenschk/docs30/CI-Eta2-Alpha.doc">Karl Wuensch</a>. Where Cohenâs d can take both positive and negative values, rÂ² or Î·Â² are squared, and can therefore only take positive values. This is related to the fact that <em>F</em>-tests (as commonly used in ANOVA) are one-sided. If you calculate a 95% CI, you can get situations where the confidence interval includes 0, but the test reveals a statistical difference with a <em>p</em> &lt; .05 (for a more mathematical explanation, see <span class="citation">Steiger (<a href="references.html#ref-steiger_beyond_2004" role="doc-biblioref">2004</a>)</span>). This means that a 95% CI around Cohen's <em>d</em> in an independent <em>t</em>-test equals a 90% CI around Î·Â² for exactly the same test performed as an ANOVA. As a final detail, because eta-squared cannot be smaller than zero, the lower bound for the confidence interval can not be smaller than 0. This means that a confidence interval for an effect that is not statistically different from 0 has to start at 0. You report such a CI as 90% CI [.00; .XX] where the XX is the upper limit of the CI.</p>
<p>Confidence intervals are often used in forest plots that communicate the results from a meta-analysis. In the plot below, we see 4 rows. Each row shows the effect size estimate from one study (in Hedgesâ g). For example, study 1 yielded an effect size estimate of 0.44, with a confidence interval around the effect size from 0.08 to 0.8. The horizontal black line, similarly to the visualization we played around with before, is the width of the confidence interval. When it does not touch the effect size 0 (indicated by a black vertical line) the effect is statistically significant.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:meta"></span>
<img src="07-CI_files/figure-html/meta-1.png" alt="Meta-analysis of 4 studies" width="100%"><p class="caption">
Figure 7.3: Meta-analysis of 4 studies
</p>
</div>
<p>We can see, based on the fact that the confidence intervals do not overlap with 0, that studies 1 and 3 were statistically significant. The diamond shape next the FE model (Fixed Effect model) is the meta-analytic effect size. Instead of using a black horizontal line, the upper limit and lower limit of the confidence interval are indicated by the left and right points of the diamond, and the center of the diamond is the meta-analytic effect size estimate. A meta-analysis calculates the effect size by combining and weighing all studies. The confidence interval for a meta-analytic effect size estimate is always narrower than that for a single study, because of the combined sample size of all studies included in the meta-analysis.</p>
<p>In the preceding section, we focused on examining whether the confidence interval overlapped with 0. This is a confidence interval approach to a null-hypothesis significance test. Even though we are not computing a <em>p</em>-value, we can directly see from the confidence interval whether <em>p</em> &lt; <span class="math inline">\(\alpha\)</span>. The confidence interval approach to hypothesis testing makes it quite intuitive to think about performing tests against non-zero null hypotheses <span class="citation">(<a href="references.html#ref-bauer_unifying_1996" role="doc-biblioref">Bauer &amp; Kieser, 1996</a>)</span>. For example, we could test whether we can reject an effect of 0.5 by examining if the 95% confidence interval does not overlap with 0.5. We can test whether an effect is <em>smaller</em> that 0.5 by examining if the 95% confidence interval falls completely <em>below</em> 0.5. We will see that this is leads to a logical extension of null-hypothesis testing where, instead of testing to reject an effect of 0, we can test whether we can reject other effects of interest in <strong>range predictions</strong> and <a href="equivalencetest.html#equivalencetest"><strong>equivalence tests</strong></a>.</p>
</div>
<div id="the-standard-error-and-95-confidence-intervals" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> The Standard Error and 95% Confidence Intervals<a class="anchor" aria-label="anchor" href="#the-standard-error-and-95-confidence-intervals"><i class="fas fa-link"></i></a>
</h2>
<p>To calculate a confidence interval, we need the standard error. The standard error (SE) estimates the variability between sample means that would be obtained after taking several measurements from the same population. It is easy to confuse it with the standard deviation, which is the degree to which individuals within the sample differ from the sample mean. Formally, statisticians distinguish between Ï and <span class="math inline">\(\widehat{\sigma}\)</span>, where the hat means the value is estimated from a sample, and the lack of a hat means it is the population value â but Iâll leave out the hat, even when Iâll mostly talk about estimated values based on a sample in the formulas below. Mathematically (where Ï is the standard
deviation),</p>
<p><span class="math display">\[
Standard \ Error \ (SE) = \sigma/\sqrt n
\]</span></p>
<p>The standard error of the sample will tend to zero with increasing sample size, because the estimate of the population mean will become more and more accurate. The standard deviation of the sample will become more and more similar to the population standard deviation as the sample size increases, but it will not become smaller. Where the standard deviation is a statistic that is descriptive of your sample, the standard error describes bounds on a random sampling process.</p>
<p>The standard error is used to construct confidence intervals (CI) around sample estimates, such as the mean, or differences between means, or whatever statistics you might be interested in. To calculate a confidence interval around a mean (indicated by the Greek letter mu: Î¼), we use the <em>t</em> distribution with the corresponding degrees of freedom (<em>df</em> : in a one-sample <em>t</em>-test, the degrees of freedom are n-1):</p>
<p><span class="math display">\[
\mu \pm t_{df, 1-(\alpha/2)} SE
\]</span></p>
<p>With a 95% confidence interval, the <span class="math inline">\(\alpha\)</span> = 0.05, and thus the critical <em>t</em>-value for the degrees of freedom for 1- <span class="math inline">\(\alpha\)</span> /2, or the 0.975th quantile is calculated. Remember that a <em>t</em>-distribution has slightly thicker tails than a Z-distribution. Where the 0.975th quantile for a Z-distribution is 1.96, the value for a <em>t</em>-distribution with for example df = 19 is 2.093. This value is multiplied by the standard error, and added (for the upper limit of the confidence interval) or subtracted (for the lower limit of the confidence interval) from the mean.</p>
</div>
<div id="overlapping-confidence-intervals" class="section level2" number="7.5">
<h2>
<span class="header-section-number">7.5</span> Overlapping Confidence Intervals<a class="anchor" aria-label="anchor" href="#overlapping-confidence-intervals"><i class="fas fa-link"></i></a>
</h2>
<p>Confidence intervals are often used in plots. In Figure <a href="confint.html#fig:cioverlap">7.4</a> below, three estimates are vizluaized (the dots), surrounded by three lines (the 95% confidence intervals). The left two dots (X and Y) represent the <em>means</em> of the independent groups X and Y on a scale from 0 to 8 (see the axis from 0-8 on the left side of the plot). The dotted lines between the two confidence intervals visualize the overlap between the confidence intervals around the means. The two confidence intervals around means in columns X and Y are commonly shown in a figure in a scientific article. The third dot, slightly larger, is the <em>mean difference</em> between X and Y, and slightly thicker line visualizes the confidence interval of this mean difference. The difference score is expressed using the axis on the right (from -3 to 5). In the plot below, the mean of group X is 3, the mean of group Y is 5.6, and the difference is 2.6. The plot is based on 50 observations per group, and the confidence interval around the mean difference ranges from 0.49 to 4.68, which is quite wide.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cioverlap"></span>
<img src="07-CI_files/figure-html/cioverlap-1.png" alt="Means and 95% confidence intervals of two independent groups and the mean difference and it's 95% confidence interval." width="100%"><p class="caption">
Figure 7.4: Means and 95% confidence intervals of two independent groups and the mean difference and it's 95% confidence interval.
</p>
</div>
<p>As mentioned earlier, when a 95% confidence interval does not contain 0, the effect is statistically different from 0. In Figure <a href="confint.html#fig:cioverlap">7.4</a> above the mean difference and the 95% confidence interval around it are indicaed by the 'difference' label. As the 95% confidence interval does not contain 0, the <em>t</em>-test is significant at an alpha of 0.05. The <em>p</em>-value is indicated in the plot as 0.016. Even though the two means differ statistically from each other, the confidence interval around each mean overlap. One might intuitively believe that an effect is only statistically significant if the confidence interval around the individual means do not overlap, but this is not true. The significance test is related to the confidence interval around the mean difference.</p>
</div>
<div id="prediction-intervals" class="section level2" number="7.6">
<h2>
<span class="header-section-number">7.6</span> Prediction Intervals<a class="anchor" aria-label="anchor" href="#prediction-intervals"><i class="fas fa-link"></i></a>
</h2>
<p>Even though 95% of future confidence intervals will contain the true parameter, a 95% confidence interval will not contain 95% of future individual observations. Sometimes, researchers want to predict the interval within which a single value will fall. This is called the prediction interval. It is always much wider than a confidence interval. The reason is that individual observations can vary substantially, but means of future samples (which fall within a normal confidence interval 95% of the time) will vary much less.</p>
<p>In Figure <a href="confint.html#fig:predictioninterval">7.5</a> the orange background illustrates the 95% confidence interval around the mean, and the lighter yellow background illustrates the 95% prediction interval (PI).</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:predictioninterval"></span>
<img src="07-CI_files/figure-html/predictioninterval-1.png" alt="A comparison of a 95% confidence interval (gold) and 95% prediction interval (yellow)." width="100%"><p class="caption">
Figure 7.5: A comparison of a 95% confidence interval (gold) and 95% prediction interval (yellow).
</p>
</div>
<p>To calculate the prediction interval, we need a slightly different formula for the standard error, that was used for the confidence interval, namely:</p>
<p><span class="math display">\[
Standard \ Error \ (SE) = \sigma/\sqrt(1+1/n)
\]</span></p>
<p>When we rewrite the formula used for the confidence interval to <span class="math inline">\(\sigma/\sqrt(1/N)\)</span>, we see the difference between a confidence interval and the prediction interval is in the â1+â which always leads to wider intervals. Prediction intervals are <strong>wider</strong>, because they are constructed so that they will contain <strong>a single future value</strong> 95% of the time, instead of the <strong>mean</strong>. The fact that prediction intervals are wide is a good reminder that it is difficult to predict what will happen for any single individual.</p>
</div>
<div id="capture-percentages" class="section level2" number="7.7">
<h2>
<span class="header-section-number">7.7</span> Capture Percentages<a class="anchor" aria-label="anchor" href="#capture-percentages"><i class="fas fa-link"></i></a>
</h2>
<p>It can be difficult to understand why a 95% confidence interval does not provide us with the interval where 95% of future means will fall. The percentage of means that falls within a single confidence interval is called the <strong>capture percentage</strong>. A capture percentage is not something we would ever use to make inferences about data, but it is useful to learn about capture percentages to prevent misinterpreting confidence intervals. In Figure <a href="confint.html#fig:metaci">7.6</a> we see two randomly simulated studies with the same sample size from the same population. The true effect size in both studies is 0, and we see that the 95% confidence intervals for both studies contain the true population value of 0. However, the two confidence intervals cover quite different ranges of effect sizes, with the confidence interval in Study 1 ranging from -0.07 to 0.48, and the confidence interval in Study 2 ranging from -0.50 to 0.06. It can not be true that in the future, 95% of the effect sizes we should expect will fall between -0.07 to 0.048, <strong>and</strong> 95% of the effect sizes we should expect will fall between -0.50 to 0.06.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:metaci"></span>
<img src="07-CI_files/figure-html/metaci-1.png" alt="Meta-analysis of 2 simulated studies from the same population." width="100%"><p class="caption">
Figure 7.6: Meta-analysis of 2 simulated studies from the same population.
</p>
</div>
<p>The only situation in which a 95% confidence interval happens to also be a 95% capture percentage is when the observed effect size in a sample happens to be exactly the same as the true population parameter. In Figure <a href="confint.html#fig:metaci">7.6</a> that means we would need to observe an effect of exactly 0. However, you canât know whether your observed effect size happens to be exactly the same as the population effect size. When a sample estimate is not identical to the true population value (which is almost always the case) less than 95% of future effect sizes will fall within the CI from your current sample. As we have observed two studies with observed effect sizes a bit removed from the true effect size, we will find effect size estimates in future studies that fall outside the observed 95% confidence interval quite often. So, the percentage of future means that fall within a single confidence interval depends upon which single confidence interval you happened to observe. Based on simulation studies it is possible to show that on average, in the long run, a 95% CI has an 83.4% capture probability <span class="citation">(<a href="references.html#ref-cumming_confidence_2006" role="doc-biblioref">Cumming &amp; Maillardet, 2006</a>)</span>.</p>
</div>
<div id="calculating-confidence-intervals-around-standard-deviations." class="section level2" number="7.8">
<h2>
<span class="header-section-number">7.8</span> Calculating Confidence Intervals around Standard Deviations.<a class="anchor" aria-label="anchor" href="#calculating-confidence-intervals-around-standard-deviations."><i class="fas fa-link"></i></a>
</h2>
<p>If we calculate a standard deviation (SD) from a sample, this value is an
estimate of the true value in the population. In small samples, our estimate can be quite far off. But due to the law of large numbers, as our sample size increases, we will be measuring the standard deviation more accurately. Since the sample standard deviation is an estimate with uncertainty, we can calculate a 95% confidence interval around it.</p>
<p>Keeping the uncertainty in our estimate of the standard deviation in mind can be important. When researchers perform an a-priori power analysis based on an effect size of interest expressed on a raw scale, they need accurate estimates of the standard deviation when performing the power analysis. Sometimes researchers will use pilot data to get an estimate of the standard deviation. Since the estimate of the population standard deviation based on a pilot study has some uncertainty, the sample size from the a-priori power analysis contains uncertainty (see the 'Test Yourself' questions below). Use validated or existing measures for which accurate estimates of the standard deviation in your population of interest are available. And keep in mind that all estimates from a sample have uncertainty.</p>
</div>
<div id="computing-confidence-intervals-around-effect-sizes" class="section level2" number="7.9">
<h2>
<span class="header-section-number">7.9</span> Computing Confidence Intervals around Effect Sizes<a class="anchor" aria-label="anchor" href="#computing-confidence-intervals-around-effect-sizes"><i class="fas fa-link"></i></a>
</h2>
<p>Cohen <span class="citation">(<a href="references.html#ref-cohen_earth_1994" role="doc-biblioref">1994</a>)</span> reflected on the reason confidence intervals were rarely reporting in 1994: "I suspect that the main reason they are not reported is that they are so embarrassingly large!" This might be, but another reason might have been that statistical software rarely provided confidence intervals around effect sizes in the time when Cohen wrote his article. It has become increasingly easy to report confidence intervals with the popularity of free software packages in R, even though these packages might not provide solutions for all statistical tests yet. The <a href="https://apastyle.apa.org/jars/quantitative">Journal Article Reporting Standards</a> recommend to report "effect-size estimates and confidence intervals on estimates that correspond to each inferential test conducted, when possible".</p>
<p>One easy solution to calculating effect sizes and confidence intervals is <a href="https://www.aggieerin.com/shiny-server/">MOTE</a> made by Dr. Erin Buchanan and her lab. The website comes with a full collections of tutorials, comparisons with other software packages, and demonstration videos giving accessible overviews of how to compute effect sizes and confidence intervals for a wide range of tests based on summary statistics. This means that whichever software you use to perform statistical tests, you can enter sample sizes and means, standard deviations, or test statistics to compute effect sizes and their confidence intervals. For example, the video below gives an overview of how to compute a confidence interval around Cohen's <em>d</em> for an independent <em>t</em>-test.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/kH3UOoFh9Ng?start=9" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p>MOTE is also available as an R package <span class="citation">(<a href="references.html#ref-buchanan_mote_2017" role="doc-biblioref">Buchanan et al., 2017</a>)</span>. Although many solutions exists to compute Cohen's <em>d</em>, MOTE sets itself apart by allowing researchers to compute effect sizes and confidence intervals for many additional effect sizes, such as (partial) omega squared for between subjects ANOVA (<span class="math inline">\(\omega^{2}\)</span> and <span class="math inline">\(\omega^{2}_p\)</span>), generalized omega squared for ANOVA (<span class="math inline">\(\omega^{2}_G\)</span>), epsilon squared for ANOVA (<span class="math inline">\(\varepsilon^{2}\)</span>) and (partial) generalized eta squared for ANOVA (<span class="math inline">\(\eta^{2}_G\)</span>).</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">MOTE</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MOTE/man/d.ind.t.html">d.ind.t</a></span><span class="op">(</span>m1 <span class="op">=</span> <span class="fl">1.7</span>, m2 <span class="op">=</span> <span class="fl">2.1</span>, sd1 <span class="op">=</span> <span class="fl">1.01</span>, sd2 <span class="op">=</span> <span class="fl">0.96</span>, n1 <span class="op">=</span> <span class="fl">77</span>, n2 <span class="op">=</span> <span class="fl">78</span>, a <span class="op">=</span> <span class="fl">.05</span><span class="op">)</span><span class="op">$</span><span class="va">estimate</span></code></pre></div>
<pre><code>## [1] "$d_s$ = -0.41, 95\\% CI [-0.72, -0.09]"</code></pre>
<p>MBESS is another R package that has a range of options to compute effect sizes and their confidence intervals <span class="citation">(<a href="references.html#ref-kelley_confidence_2007" role="doc-biblioref">Kelley, 2007</a>)</span>. The code below reproduces the example for MOTE above.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">MBESS</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/MBESS/man/smd.html">smd</a></span><span class="op">(</span>Mean.1 <span class="op">=</span> <span class="fl">1.7</span>, Mean.2 <span class="op">=</span> <span class="fl">2.1</span>, s.1 <span class="op">=</span> <span class="fl">1.01</span>, s.2 <span class="op">=</span> <span class="fl">0.96</span>, n.1 <span class="op">=</span> <span class="fl">77</span>, n.2 <span class="op">=</span> <span class="fl">78</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -0.406028</code></pre>
<p>If you feel comfortable analyzing your data in R, the <code>effectsize</code> package offers a complete set of convenient solutions to compute effect sizes and confidence intervals <span class="citation">(<a href="references.html#ref-ben-shachar_effectsize_2020" role="doc-biblioref">Ben-Shachar et al., 2020a</a>)</span>.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">33</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">20</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="fl">2.5</span><span class="op">)</span> <span class="co">#create sample from normal distribution</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">200</span>, mean <span class="op">=</span> <span class="fl">1.5</span>, sd <span class="op">=</span> <span class="fl">3.5</span><span class="op">)</span> <span class="co">#create sample from normal distribution</span>

<span class="fu">effectsize</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/effectsize/reference/cohens_d.html">cohens_d</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span><span class="op">)</span></code></pre></div>
<div class="kable-table">
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="right">Cohens_d</th>
<th align="right">CI</th>
<th align="right">CI_low</th>
<th align="right">CI_high</th>
</tr></thead>
<tbody><tr class="odd">
<td align="right">-0.443983</td>
<td align="right">0.95</td>
<td align="right">-0.9050134</td>
<td align="right">0.0180575</td>
</tr></tbody>
</table></div>
</div>
<p>I am personally impressed by the way the <code>effectsize</code> package incorporates the state of the art (although I might be a bit biased). For example, after our recommendation to by default use Welch's <em>t</em>-test instead of students <em>t</em>-test <span class="citation">(<a href="references.html#ref-delacre_why_2017" role="doc-biblioref">Delacre et al., 2017</a>)</span>, and based on a recent simulation study recommended to report Hedgesâ <span class="math inline">\(g_s^*\)</span> as the effect size for Welch's <em>t</em>-test <span class="citation">(<a href="references.html#ref-delacre_why_2021" role="doc-biblioref">Delacre et al., 2021</a>)</span>, the <code>effectsize</code> package was the first to incorporate it.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">effectsize</span><span class="fu">::</span><span class="fu"><a href="https://easystats.github.io/effectsize/reference/cohens_d.html">cohens_d</a></span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span>, pooled_sd <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
<div class="kable-table">
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th align="right">Cohens_d</th>
<th align="right">CI</th>
<th align="right">CI_low</th>
<th align="right">CI_high</th>
</tr></thead>
<tbody><tr class="odd">
<td align="right">-0.5328286</td>
<td align="right">0.95</td>
<td align="right">-0.8972773</td>
<td align="right">-0.1613138</td>
</tr></tbody>
</table></div>
</div>
<p>Free statistical software <a href="https://www.jamovi.org/">jamovi</a> and <a href="https://jasp-stats.org/">JAPS</a> are strong alternatives to SPSS that (unlike SPSS) allows users to compute Cohen's <em>d</em> and the confidence interval for both independent and dependent <em>t</em>tests.</p>
<p>For jamovi, the ESCI module allows users to compute effect sizes and confidence intervals, and accompanies educational material that focusses more on estimation and less on testing <span class="citation">(<a href="references.html#ref-cumming_introduction_2016" role="doc-biblioref">Cumming &amp; Calin-Jageman, 2016</a>)</span>.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:escijamovi"></span>
<img src="images/escijamovi.png" alt="Output from ESCI module in jamovi." width="100%"><p class="caption">
Figure 7.7: Output from ESCI module in jamovi.
</p>
</div>
<p>JASP offers a wide range of frequentist and Bayesian analyses, and in addition to Cohen's <em>d</em> also allows users to compute omega squared <span class="math inline">\(\omega^{2}\)</span>, the less biased version of <span class="math inline">\(\eta^{2}\)</span> <span class="citation">(<a href="references.html#ref-albers_when_2018" role="doc-biblioref">Albers &amp; Lakens, 2018</a>; <a href="references.html#ref-okada_is_2013" role="doc-biblioref">Okada, 2013</a>)</span>.</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:jasp1"></span>
<img src="images/jaspeffectci1.png" alt="JASP menu option allows you to select Cohen's d and a CI around it." width="100%"><p class="caption">
Figure 7.8: JASP menu option allows you to select Cohen's d and a CI around it.
</p>
</div>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:jasp2"></span>
<img src="images/jaspeffectci2.png" alt="JASP output returns Cohen's d and the confidence interval around it." width="100%"><p class="caption">
Figure 7.9: JASP output returns Cohen's d and the confidence interval around it.
</p>
</div>
</div>
<div id="test-yourself-5" class="section level2" number="7.10">
<h2>
<span class="header-section-number">7.10</span> Test Yourself<a class="anchor" aria-label="anchor" href="#test-yourself-5"><i class="fas fa-link"></i></a>
</h2>
<p><strong>Q1</strong>: Go to the online app by Kristoffer Magnusson:
<a href="http://rpsychologist.com/d3/CI/" class="uri">http://rpsychologist.com/d3/CI/</a>. You might want more confidence intervals to contain the true population parameter than 95%. Drag the âSlide meâ button to the far right, and you will see the simulation for 99% confidence intervals. Which statement is true?</p>
<ol style="list-style-type: upper-alpha">
<li>The confidence intervals are larger, and the sample means fall closer to the true mean.</li>
<li>The confidence intervals are smaller, and the sample means fall closer to the true mean.</li>
<li>The confidence intervals are larger, and the sample means fall as close to the true mean as for a 95% confidence interval.</li>
<li>The confidence intervals are smaller, and the sample means fall as close to the true mean as for a 95% confidence interval.</li>
</ol>
<p><strong>Q2</strong>: As we could see from the formulas for confidence intervals, sample means and their confidence intervals depend on the sample size. We can change the sample size in the online app (see the setting underneath the vizualization). By default, the sample size is set to 5. Change the sample size to 50 (you can type it in). Which statement is true?</p>
<ol style="list-style-type: upper-alpha">
<li>The larger the sample size, the larger the confidence intervals. The sample size does not influence how the sample means vary around the true population mean.</li>
<li>The larger the sample size, the smaller the confidence intervals. The sample size does not influence how the sample means vary around the true population mean.</li>
<li>The larger the sample size, the larger the confidence intervals, and the closer the sample means are to the true population mean.</li>
<li>The larger the sample size, the smaller the confidence intervals, and the closer the sample means are to the true population mean.</li>
</ol>
<p><strong>Q3</strong>: In the forest plot below, we see the effect size (indicated by the square) and the confidence interval of the effect size (indicated by the line around the effect). Which of the studies 1 to 4 in the forest plot below were statistically significant?</p>

<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:metaQ"></span>
<img src="07-CI_files/figure-html/metaQ-1.png" alt="Meta-analysis of 4 studies" width="100%"><p class="caption">
Figure 7.10: Meta-analysis of 4 studies
</p>
</div>
<ol style="list-style-type: upper-alpha">
<li>Studies 1, 2, 3, and 4</li>
<li>Only study 3</li>
<li>None of the four studies</li>
<li>Studies 1, 2 and 4</li>
</ol>
<p><strong>Q4</strong>: The light black diamond in the bottom row is the fixed effects meta-analytic effect size estimate. Instead of using a black horizontal line, the upper limit and lower limit of the confidence interval are indicated by the left and right points of the diamond. The center of the diamond is the meta-analytic effect size estimate. A meta-analysis calculates the effect size by combining and weighing all studies. Which statement is true?</p>
<ol style="list-style-type: upper-alpha">
<li>The confidence interval for a fixed effect meta-analytic effect size estimate is always wider than that for a single study, because of the additional variation between studies.</li>
<li>The confidence interval for a fixed effect meta-analytic effect size estimate is always more narrow than that for a single study, because of the combined sample size of all studies included in the meta-analysis.</li>
<li>The confidence interval for a fixed effect meta-analytic effect size estimate does not become wider or more narrow compared to the confidence interval of a single study, it just becomes closer to the true population parameter.</li>
</ol>
<p><strong>Q5</strong>: Letâs assume a researcher calculates a mean of 7.5, and a standard deviation of 6.3, in a sample of 20 people. The critical value for a <em>t</em>-distribution with df = 19 is 2.093. Calculate the upper limit of the confidence interval around the mean using the formula below. Is it:
<span class="math display">\[
\mu \pm t_{df, 1-(\alpha/2)} SE
\]</span></p>
<ol style="list-style-type: upper-alpha">
<li>1.40</li>
<li>2.95</li>
<li>8.91</li>
<li>10.45</li>
</ol>
<p>Copy the code below into R and run the code. It will generate plots like the one in Figure <a href="confint.html#fig:cioverlap">7.4</a>. Run the entire script as often as you want (notice the variability in the <em>p</em>-values due to the relatively low power in the test!), to answer the following question. The <em>p</em>-value in the plot will tell you if the difference is statistically significant, and what the <em>p</em>-value is. Run the simulation until you find a <em>p</em>-value close to <em>p</em> = 0.05.</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50</span>, mean <span class="op">=</span> <span class="fl">3</span>, sd <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="co"># get sample group 1</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">50</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">5</span><span class="op">)</span> <span class="co"># get sample group 2</span>

<span class="va">d</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>
  labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"X"</span>, <span class="st">"Y"</span>, <span class="st">"Difference"</span><span class="op">)</span>,
  mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>,
  lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x</span><span class="op">)</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span>,
  upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">x</span><span class="op">)</span><span class="op">[[</span><span class="fl">4</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>
<span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="cn">NA</span>, xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">.5</span>, <span class="fl">3.5</span><span class="op">)</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">upper</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>, bty <span class="op">=</span> <span class="st">"l"</span>, 
     xaxt <span class="op">=</span> <span class="st">"n"</span>, xlab <span class="op">=</span> <span class="st">""</span>, ylab <span class="op">=</span> <span class="st">"Mean"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, pch <span class="op">=</span> <span class="fl">19</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span><span class="fl">1</span>, <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">5</span>, <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span><span class="fl">2</span>, <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">5</span>, <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="va">d</span><span class="op">$</span><span class="va">labels</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="va">d</span><span class="op">$</span><span class="va">lower</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="va">d</span><span class="op">$</span><span class="va">upper</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/axis.html">axis</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">-</span> <span class="fl">3</span><span class="op">)</span>, <span class="op">(</span><span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="fl">5</span><span class="op">)</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">5</span>, by <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/points.html">points</a></span><span class="op">(</span><span class="fl">3</span>, <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, pch <span class="op">=</span> <span class="fl">19</span>, cex <span class="op">=</span> <span class="fl">1.5</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span><span class="fl">3</span>, <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">d</span><span class="op">$</span><span class="va">lower</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, <span class="fl">3</span>, <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">d</span><span class="op">$</span><span class="va">upper</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>, lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/mtext.html">mtext</a></span><span class="op">(</span><span class="st">"Difference"</span>, side <span class="op">=</span> <span class="fl">4</span>, at <span class="op">=</span> <span class="va">d</span><span class="op">$</span><span class="va">mean</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, line <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span>, <span class="va">d</span><span class="op">$</span><span class="va">upper</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="va">d</span><span class="op">$</span><span class="va">upper</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/segments.html">segments</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">1</span>, <span class="va">d</span><span class="op">$</span><span class="va">lower</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">2</span>, <span class="va">d</span><span class="op">$</span><span class="va">lower</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">]</span>, lty <span class="op">=</span> <span class="fl">3</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/text.html">text</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"P-value"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">$</span><span class="va">p.value</span>, digits <span class="op">=</span> <span class="fl">3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="07-CI_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;"></div>
<p><strong>Q6</strong>: How much do two 95% confidence intervals around individual means from independent groups overlap when the mean difference between the two means is only just statistically significant (<em>p</em> â 0.05 at an alpha of 0.05)?</p>
<ol style="list-style-type: upper-alpha">
<li>When the 95% confidence interval around one mean does not contain the mean of the other group, the groups always differ significantly from each other.</li>
<li>When the 95% confidence interval around one mean does not overlap with the 95% confidence interval of the mean of the other group, the groups always differ significantly from each other.</li>
<li>When the overlap between the two confidence intervals around each mean overlap a little bit (the upper bound of the CI overlaps with the lower quarter of the confidence interval around the other mean) the groups differ significantly from each other at approximately <em>p</em> = 0.05.</li>
<li>There is no relationship between the overlap of the 95% confidence intervals around two independent means, and the <em>p</em>-value for the difference between these groups.</li>
</ol>
<p>Note that this visual overlap rule can only be used when the comparison is made between independent groups, not between dependent groups! The 95% confidence interval around effect sizes is therefore typically more easily interpretable in relation to the significance of a test.</p>
<p>Letâs experience this through simulation. The simulation in the R script below generates a large number of additional samples, after the initial one that was plotted. The simulation returns the number of CI that contains the mean (which should be 95% in the long run). The simulation also returns the % of means from future studies that fall within the 95% of the original study, or the capture percentage. It differs from (and is often lower, but sometimes higher, than) the confidence interval.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>

<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">20</span> <span class="co"># set sample size</span>
<span class="va">nsims</span> <span class="op">&lt;-</span> <span class="fl">100000</span> <span class="co"># set number of simulations</span>

<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">100</span>, sd <span class="op">=</span> <span class="fl">15</span><span class="op">)</span> <span class="co"># create sample from normal distribution</span>

<span class="co"># 95% Confidence Interval</span>
<span class="va">ciu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, df <span class="op">=</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span>
<span class="va">cil</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, df <span class="op">=</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span>

<span class="co"># 95% Prediction Interval</span>
<span class="va">piu</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, df <span class="op">=</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span>
<span class="va">pil</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, df <span class="op">=</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="co"># plot data</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_rect</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>xmin <span class="op">=</span> <span class="va">pil</span>, xmax <span class="op">=</span> <span class="va">piu</span>, ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="cn">Inf</span><span class="op">)</span>,
            fill <span class="op">=</span> <span class="st">"gold"</span><span class="op">)</span> <span class="op">+</span> <span class="co"># draw yellow PI area</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_rect</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>xmin <span class="op">=</span> <span class="va">cil</span>, xmax <span class="op">=</span> <span class="va">ciu</span>, ymin <span class="op">=</span> <span class="fl">0</span>, ymax <span class="op">=</span> <span class="cn">Inf</span><span class="op">)</span>,
            fill <span class="op">=</span> <span class="st">"#E69F00"</span><span class="op">)</span> <span class="op">+</span> <span class="co"># draw orange CI area</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>colour <span class="op">=</span> <span class="st">"black"</span>, fill <span class="op">=</span> <span class="st">"grey"</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">..density..</span><span class="op">)</span>, bins <span class="op">=</span> <span class="fl">20</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="st">"Score"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="st">"frequency"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">20</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>panel.grid.major.x <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_blank</a></span><span class="op">(</span><span class="op">)</span>, axis.text.y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_blank</a></span><span class="op">(</span><span class="op">)</span>,
        panel.grid.minor.x <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_blank</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.background <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_rect</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="va">backgroundcolor</span><span class="op">)</span><span class="op">)</span>  <span class="op">+</span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>panel.background <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_rect</a></span><span class="op">(</span>fill <span class="op">=</span> <span class="va">backgroundcolor</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">150</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">150</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, y <span class="op">=</span> <span class="fl">0.02</span>, label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span>
    <span class="st">"Mean = "</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>, <span class="st">"\n"</span>,
    <span class="st">"SD = "</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span>, sep <span class="op">=</span> <span class="st">""</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">6.5</span><span class="op">)</span>

<span class="co"># Simulate Confidence Intervals</span>
<span class="va">ciu_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">nsims</span><span class="op">)</span>
<span class="va">cil_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">nsims</span><span class="op">)</span>
<span class="va">mean_sim</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span><span class="op">(</span><span class="va">nsims</span><span class="op">)</span>

<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="va">nsims</span><span class="op">)</span> <span class="op">{</span> <span class="co"># for each simulated experiment</span>
  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span>n <span class="op">=</span> <span class="va">n</span>, mean <span class="op">=</span> <span class="fl">100</span>, sd <span class="op">=</span> <span class="fl">15</span><span class="op">)</span> <span class="co"># create sample from normal distribution</span>
  <span class="va">ciu_sim</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, df <span class="op">=</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span>
  <span class="va">cil_sim</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">0.975</span>, df <span class="op">=</span> <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1</span> <span class="op">/</span> <span class="va">n</span><span class="op">)</span>
  <span class="va">mean_sim</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="co"># store means of each sample</span>
<span class="op">}</span>

<span class="co"># Save only those simulations where the true value was inside the 95% CI</span>
<span class="va">ciu_sim</span> <span class="op">&lt;-</span> <span class="va">ciu_sim</span><span class="op">[</span><span class="va">ciu_sim</span> <span class="op">&lt;</span> <span class="fl">100</span><span class="op">]</span>
<span class="va">cil_sim</span> <span class="op">&lt;-</span> <span class="va">cil_sim</span><span class="op">[</span><span class="va">cil_sim</span> <span class="op">&gt;</span> <span class="fl">100</span><span class="op">]</span>

<span class="co"># Calculate how many times the observed mean fell within the 95% CI of the original study</span>
<span class="va">mean_sim</span> <span class="op">&lt;-</span> <span class="va">mean_sim</span><span class="op">[</span><span class="va">mean_sim</span> <span class="op">&gt;</span> <span class="va">cil</span> <span class="op">&amp;</span> <span class="va">mean_sim</span> <span class="op">&lt;</span> <span class="va">ciu</span><span class="op">]</span>

<span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="op">(</span><span class="fl">100</span> <span class="op">*</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">ciu_sim</span><span class="op">)</span> <span class="op">/</span> <span class="va">nsims</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">cil_sim</span><span class="op">)</span> <span class="op">/</span> <span class="va">nsims</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
    <span class="st">"% of the 95% confidence intervals contained the true mean"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"The capture percentage for the plotted study, or the % of values within
    the observed confidence interval from"</span>, <span class="va">cil</span>, <span class="st">"to"</span>, <span class="va">ciu</span>,
    <span class="st">"is:"</span>, <span class="fl">100</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">mean_sim</span><span class="op">)</span> <span class="op">/</span> <span class="va">nsims</span>, <span class="st">"%"</span><span class="op">)</span></code></pre></div>
<p><strong>Q7</strong>: Run the simulations multiple times. Look at the output you will get in the R console. For example: â95.077 % of the 95% confidence intervals contained the true meanâ and âThe capture percentage for the plotted study, or the % of values within the observed confidence interval from 88.17208 to 103.1506 is: 82.377 %â. While running the simulations multiple times, look at the confidence interval around the sample mean, and relate this to the capture percentage. Run the simulation until you have seen a range of means closer and further away from the true mean in the simulation (100). Which statement is true?</p>
<ol style="list-style-type: upper-alpha">
<li>The farther the sample mean is from the true population mean, the lower the capture percentage.</li>
<li>The farther the sample mean is from the true population mean, the higher the capture percentage.</li>
</ol>
<p><strong>Q8</strong>: Simulations in R are randomly generated, but you can make a specific simulation reproducible by setting the seed of the random generation process. Copy-paste âset.seed(1000)â to the first line of the R script, and run the simulation. The sample mean should be 94. What is the capture percentage? (Donât forget to remove the set.seed command if you want to generate more random simulations!).</p>
<ol style="list-style-type: upper-alpha">
<li>95%</li>
<li>42.1%</li>
<li>84.3%</li>
<li>89.2%</li>
</ol>
<p>Capture percentages are rarely directly used to make statistical inferences. The main reason we discuss them here is really to prevent the common misunderstanding that 95% of future means fall within a single confidence interval: Capture percentages clearly show that is not true. Prediction intervals are also rarely used in psychology, but are more common in data science.</p>
<p><strong>Q9</strong>: If you run lines the first lines of the code below, you will see that with an alpha level of 0.05, 100 observations, and a true standard deviation of 1, the 95% CI is [0.88; 1.16]. Change the assumed population standard deviation from 1 to 2 (st_dev &lt;- 2). Keep all other settings the same. What is the 95% CI around the standard deviation of 2 with 100 observations?</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">alpha_level</span> <span class="op">&lt;-</span> <span class="fl">0.05</span> <span class="co">#set alpha level</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co">#set number of observations</span>
<span class="va">st_dev</span> <span class="op">&lt;-</span> <span class="fl">1</span> <span class="co">#set true standard deviation</span>
<span class="va">effect</span> <span class="op">&lt;-</span> <span class="fl">0.5</span> <span class="co">#set effect size (raw mean difference)</span>

<span class="co"># calculate lower and upper critical values c_l and c_u</span>
<span class="va">c_l</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq</a></span><span class="op">(</span><span class="va">alpha_level</span><span class="op">/</span><span class="fl">2</span>, <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span>, lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span>
<span class="va">c_u</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="op">(</span><span class="va">n</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">qchisq</a></span><span class="op">(</span><span class="va">alpha_level</span><span class="op">/</span><span class="fl">2</span>, <span class="va">n</span> <span class="op">-</span> <span class="fl">1</span>, lower.tail <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>

<span class="co"># calculate lower and upper confidence interval for sd</span>
<span class="va">st_dev</span> <span class="op">*</span> <span class="va">c_l</span>
<span class="va">st_dev</span> <span class="op">*</span> <span class="va">c_u</span>

<span class="co"># d based on lower bound of the 95CI around the SD</span>
<span class="va">effect</span><span class="op">/</span><span class="op">(</span><span class="va">st_dev</span> <span class="op">*</span> <span class="va">c_l</span><span class="op">)</span>
<span class="co"># d based on upper bound of the 95CI around the SD</span>
<span class="va">effect</span><span class="op">/</span><span class="op">(</span><span class="va">st_dev</span> <span class="op">*</span> <span class="va">c_u</span><span class="op">)</span>

<span class="fu">pwr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pwr/man/pwr.t.test.html">pwr.t.test</a></span><span class="op">(</span>d <span class="op">=</span> <span class="va">effect</span><span class="op">/</span><span class="op">(</span><span class="va">st_dev</span> <span class="op">*</span> <span class="va">c_l</span><span class="op">)</span>, power <span class="op">=</span> <span class="fl">0.9</span>, sig.level <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>
<span class="fu">pwr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pwr/man/pwr.t.test.html">pwr.t.test</a></span><span class="op">(</span>d <span class="op">=</span> <span class="va">effect</span><span class="op">/</span><span class="op">(</span><span class="va">st_dev</span> <span class="op">*</span> <span class="va">c_u</span><span class="op">)</span>, power <span class="op">=</span> <span class="fl">0.9</span>, sig.level <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>

<span class="co"># Power analysis for true standard deviation for comparison</span>
<span class="fu">pwr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/pwr/man/pwr.t.test.html">pwr.t.test</a></span><span class="op">(</span>d <span class="op">=</span> <span class="va">effect</span><span class="op">/</span><span class="va">st_dev</span>, power <span class="op">=</span> <span class="fl">0.9</span>, sig.level <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span></code></pre></div>
<ol style="list-style-type: upper-alpha">
<li>95% CI [1.38; 3.65]</li>
<li>95% CI [1.76; 2.32]</li>
<li>95% CI [1.82; 2.22]</li>
<li>95% CI [1.84; 2.20]</li>
</ol>
<p><strong>Q10</strong>: Change the assumed population standard deviation back from 2 to 1. Lower the sample size from 100 to 20 (n &lt;- 20). This will inform us about the width of the confidence interval for a standard deviation when we run a pilot study with 20 observations. Keep all other settings the same. What is the 95% CI around the standard deviation of 1 with 20 observations?</p>
<ol style="list-style-type: upper-alpha">
<li>95% CI [0.91; 1.11]</li>
<li>95% CI [0.82; 1.28]</li>
<li>95% CI [0.76; 1.46]</li>
<li>95% CI [1.52; 2.92]</li>
</ol>
<p><strong>Q11</strong>: If we want the 95% CI around the standard deviation of 1 to be at most 0.05 away from the assumed population standard deviation, how large should our number of observations be? Note that this means we want the 95% CI to fall within 0.95 and 1.05. But notice from the calculations above that the distribution of the sample standard deviations is not symmetrical. Standard deviations canât be smaller than 0 (because they are the square rooted variance). So in practice the question is: What is the <strong>smallest</strong> number of observations for the upper 95% CI to be smaller than 1.05? Replace n with each of the values in the answer options.</p>
<ol style="list-style-type: upper-alpha">
<li>n = 489</li>
<li>n = 498</li>
<li>n = 849</li>
<li>n = 948</li>
</ol>
<p>Letâs explore what the consequences of an inaccurate estimate of the population standard deviation are on a-priori power analyses. Letâs imagine we want to perform an a-priori power analysis for a smallest effect size of interest of half a scale point (on a scale from 1-5) on a measure that has an (unknown) true population standard deviation of 1.2.</p>
<p><strong>Q12</strong>: Change the number of observations to 50. Change the assumed population standard deviation to 1.2. Keep the effect as 0.5. The 95% confidence interval for the standard deviation based on a sample of 50 observation ranges from 1.002 to 1.495. To perform an a-priori power analysis we need to calculate Cohenâs d, which is the difference divided by the standard deviation. In our example, we want to at least observe a difference of 0.5. What is Cohenâs d (effect/SD) for the lower bound of the 95% confidence interval (where SD = 1.002) or the upper bound (where SD = 1.495)?</p>
<ol style="list-style-type: upper-alpha">
<li>d = 0.33 and d = 0.50</li>
<li>d = 0.40 and d = 0.60</li>
<li>d = 0.43 and d = 0.57</li>
<li>d = 0.29 and d = 0.55</li>
</ol>
<p>If we draw a sample of 50 observations we can happen to observe a value that, due to random variation, is much smaller or much larger than the true population value. We can examine the effect this has on the number of observations that we think will be required when we perform an a-priori power analysis.</p>
<p><strong>Q13</strong>: An a-priori power analysis is performed that uses the estimate of Cohenâs d based on the lower 95% CI of the standard deviation. Which statement is true?</p>
<ol style="list-style-type: upper-alpha">
<li>Because the lower bound of the 95% CI is <strong>smaller</strong> than the true population SD, Cohenâs d is <strong>smaller</strong>, and the a-priori power analysis will yield a sample size that is <strong>smaller</strong> than the sample size we really need.</li>
<li>Because the lower bound of the 95% CI is <strong>smaller</strong> than the true population SD, Cohenâs d is <strong>larger</strong>, and the a-priori power analysis will yield a sample size that is <strong>larger</strong> than the sample size we really need.</li>
<li>Because the lower bound of the 95% CI is <strong>smaller</strong> than the true population SD, Cohenâs d is <strong>smaller</strong>, and the a-priori power analysis will yield a sample size that is <strong>larger</strong> than the sample size we really need.</li>
<li>Because the lower bound of the 95% CI is <strong>smaller</strong> than the true population SD, Cohenâs d is <strong>larger</strong>, and the a-priori power analysis will yield a sample size that is <strong>smaller</strong> than the sample size we really need.</li>
</ol>
<p><strong>Q14</strong>: Letâs check if our answer on the previous question was correct. We still have an alpha level of 0.05, n = 50, a standard deviation of 1.2, and an effect of interest of 0.5. Run the power analyses using the <code>pwr</code> package. The first power analysis uses Cohenâs d based on the lower bound of the 95% confidence interval. The second power analysis uses the upper bound of the 95% confidence interval. (There is also a third power analysis based on the (in real-life situations unknown) true standard deviation, just for comparison). Which statement is true (note that the sample size for a power analysis is rounded up, as we can't collect a partial observation)?</p>
<ol style="list-style-type: upper-alpha">
<li>The sample size per group is 68 when calculating the effect size based on the lower bound on the 95% CI around the standard deviation, and 86 when using the upper bound of the 95% CI around the standard deviation.</li>
<li>The sample size per group is 68 when calculating the effect size based on the lower bound on the 95% CI around the standard deviation, and 123 when using the upper bound of the 95% CI around the standard deviation.</li>
<li>The sample size per group is 86 when calculating the effect size based on the lower bound on the 95% CI around the standard deviation, and 123 when using the upper bound of the 95% CI around the standard deviation.</li>
<li>The sample size per group is 86 when calculating the effect size based on the lower bound on the 95% CI around the standard deviation, and 189 when using the upper bound of the 95% CI around the standard deviation.</li>
</ol>
<div id="open-questions-5" class="section level3" number="7.10.1">
<h3>
<span class="header-section-number">7.10.1</span> Open Questions<a class="anchor" aria-label="anchor" href="#open-questions-5"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li><p>What is the definition of a confidence interval?</p></li>
<li><p>How is a confidence interval related to statistical significance?</p></li>
<li><p>What happens to a confidence interval when the sample size increases?</p></li>
<li><p>What is the difference between a confidence interval and a capture percentage?</p></li>
<li><p>What is a prediction interval?</p></li>
<li><p>If you have data from the entire population, do you need to calculate a confidence interval?</p></li>
<li><p>What are confidence intervals a statement about?</p></li>
<li><p>What does it mean to say that after you have collected the data, the confidence interval either contains the true parameter, or it doesnât?</p></li>
<li><p>What is the difference between estimates from small vs. large samples?</p></li>
</ol>
</div>
</div>
</div>
<script>
$( document ).ready(function() {
  var cite = ' ';
  var license = ' <a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="blank"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a>';

  $("footer div.row div:eq(1) p").html(
    license + cite
  );

  function move_sidebar() {
    var w = window.innerWidth;
    if (w < 992) {
      $("#toc").appendTo($("#main-nav"));
    } else {
      $("#toc").appendTo($("div.sidebar-chapter"));
    }
  }
  move_sidebar();
  window.onresize = move_sidebar;
});
</script><div class="chapter-nav">
<div class="prev"><a href="effectsize.html"><span class="header-section-number">6</span> Effect Sizes</a></div>
<div class="next"><a href="power.html"><span class="header-section-number">8</span> Sample Size Justification</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#confint"><span class="header-section-number">7</span> Confidence Intervals</a></li>
<li><a class="nav-link" href="#population-vs.-sample"><span class="header-section-number">7.1</span> Population vs. Sample</a></li>
<li><a class="nav-link" href="#what-is-a-confidence-interval"><span class="header-section-number">7.2</span> What is a Confidence Interval?</a></li>
<li><a class="nav-link" href="#relatCIp"><span class="header-section-number">7.3</span> The relation between confidence intervals and p-values</a></li>
<li><a class="nav-link" href="#the-standard-error-and-95-confidence-intervals"><span class="header-section-number">7.4</span> The Standard Error and 95% Confidence Intervals</a></li>
<li><a class="nav-link" href="#overlapping-confidence-intervals"><span class="header-section-number">7.5</span> Overlapping Confidence Intervals</a></li>
<li><a class="nav-link" href="#prediction-intervals"><span class="header-section-number">7.6</span> Prediction Intervals</a></li>
<li><a class="nav-link" href="#capture-percentages"><span class="header-section-number">7.7</span> Capture Percentages</a></li>
<li><a class="nav-link" href="#calculating-confidence-intervals-around-standard-deviations."><span class="header-section-number">7.8</span> Calculating Confidence Intervals around Standard Deviations.</a></li>
<li><a class="nav-link" href="#computing-confidence-intervals-around-effect-sizes"><span class="header-section-number">7.9</span> Computing Confidence Intervals around Effect Sizes</a></li>
<li>
<a class="nav-link" href="#test-yourself-5"><span class="header-section-number">7.10</span> Test Yourself</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#open-questions-5"><span class="header-section-number">7.10.1</span> Open Questions</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/Lakens/statistical_inferences/blob/master/07-CI.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/Lakens/statistical_inferences/edit/master/07-CI.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>Lakens, D. (2022). Improving Your Statistical Inferences. https://doi.org/10.5281/zenodo.6409077. Built on 2022-04-12.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png"></a></p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
