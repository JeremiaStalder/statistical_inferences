\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{apalike}
\HyPL@Entry{0<</S/r>>}
\HyPL@Entry{1<</S/r>>}
\@writefile{toc}{\contentsline {fm}{List of Figures}{vii}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {fm}{List of Tables}{xii}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {fm}{Introduction}{xiii}{chapter*.3}\protected@file@percent }
\newlabel{introduction}{{}{xiii}{Introduction}{chapter*.3}{}}
\citation{gosset_application_1904}
\citation{greenland_statistical_2016}
\citation{fisher_statistical_1956}
\citation{zabell_r_1992}
\citation{schweder_confidence_2016}
\HyPL@Entry{14<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Using \emph  {p}-values to test a hypothesis}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{pvalue}{{1}{1}{\texorpdfstring {Using \emph {p}-values to test a hypothesis}{Using p-values to test a hypothesis}}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Philosophical approaches to \emph  {p}-values}{1}{section.1.1}\protected@file@percent }
\newlabel{philosophical-approaches-to-p-values}{{1.1}{1}{\texorpdfstring {Philosophical approaches to \emph {p}-values}{Philosophical approaches to p-values}}{section.1.1}{}}
\citation{dienes_understanding_2008}
\citation{neyman_inductive_1957}
\citation{cox_problems_1958}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Ratings for the Lord of the Rings extended trilogy by two groups of friends.\relax }}{3}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:friends}{{1.1}{3}{Ratings for the Lord of the Rings extended trilogy by two groups of friends.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Creating a null model}{3}{section.1.2}\protected@file@percent }
\newlabel{creating-a-null-model}{{1.2}{3}{Creating a null model}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Calculating a \emph  {p}-value}{5}{section.1.3}\protected@file@percent }
\newlabel{calculating-a-p-value}{{1.3}{5}{\texorpdfstring {Calculating a \emph {p}-value}{Calculating a p-value}}{section.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Which \emph  {p}-values can you expect?}{5}{section.1.4}\protected@file@percent }
\newlabel{whichpexpect}{{1.4}{5}{\texorpdfstring {Which \emph {p}-values can you expect?}{Which p-values can you expect?}}{section.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces A \emph  {t}-distribution with 18 degrees of freedom.\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:tdist}{{1.1}{6}{A \emph {t}-distribution with 18 degrees of freedom.\relax }{figure.caption.5}{}}
\citation{hung_behavior_1997,ulrich_properties_2018}
\citation{lindley_statistical_1957}
\citation{spanos_who_2013}
\citation{cumming_replication_2008}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Distribution of \emph  {p}-values when power = 50\%.\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:pdistr1}{{1.2}{7}{Distribution of \emph {p}-values when power = 50\%.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Probability density function for \emph  {p}-values from a two-sided \emph  {t}-test.\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:pdft}{{1.3}{8}{Probability density function for \emph {p}-values from a two-sided \emph {t}-test.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Distribution of \emph  {p}-values when the null hypothesis is true.\relax }}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig:pdistr2}{{1.4}{8}{Distribution of \emph {p}-values when the null hypothesis is true.\relax }{figure.caption.8}{}}
\citation{leamer_specification_1978,maier_justify_2022,good_bayesnon-bayes_1992}
\citation{appelbaum_journal_2018}
\citation{lehmann_testing_2005}
\citation{fisher_design_1935}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Lindley's paradox}{9}{section.1.5}\protected@file@percent }
\newlabel{lindley}{{1.5}{9}{Lindley's paradox}{section.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Correctly reporting and interpreting \emph  {p}-values}{9}{section.1.6}\protected@file@percent }
\newlabel{correctly-reporting-and-interpreting-p-values}{{1.6}{9}{\texorpdfstring {Correctly reporting and interpreting \emph {p}-values}{Correctly reporting and interpreting p-values}}{section.1.6}{}}
\citation{niiniluoto_verisimilitude_1998,popper_logic_2002}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces \emph  {P}-value distribution for 0 (grey horizontal line, 50 percent power (black solid curve), and 99 percent power (black dotted curve, where \emph  {p}-values just below 0.05 are more likely when \(H_0\) is true than when \(H_1\) is true).\relax }}{10}{figure.caption.9}\protected@file@percent }
\newlabel{fig:paradox}{{1.5}{10}{\emph {P}-value distribution for 0 (grey horizontal line, 50 percent power (black solid curve), and 99 percent power (black dotted curve, where \emph {p}-values just below 0.05 are more likely when \(H_0\) is true than when \(H_1\) is true).\relax }{figure.caption.9}{}}
\citation{popper_logic_2002}
\citation{hacking_logic_1965}
\citation{neyman_inductive_1957}
\citation{bland_introduction_2015}
\citation{lakens_why_2022}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Preventing common misconceptions about \emph  {p}-values}{11}{section.1.7}\protected@file@percent }
\newlabel{misconceptions}{{1.7}{11}{\texorpdfstring {Preventing common misconceptions about \emph {p}-values}{Preventing common misconceptions about p-values}}{section.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent \emph  {t}-test.\relax }}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig:fig131}{{1.6}{12}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent \emph {t}-test.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 5000 observations per group in an independent \emph  {t}-test when \emph  {d} = 0.\relax }}{13}{figure.caption.11}\protected@file@percent }
\newlabel{fig:fig132}{{1.7}{13}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 5000 observations per group in an independent \emph {t}-test when \emph {d} = 0.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Screenshot from G*Power software visualizing the null model (red distribution) and alternative model (blue distribution) and the critical \emph  {t}-value (1.66055) that is the threshold distinguishing significant and non-significant results.\relax }}{14}{figure.caption.12}\protected@file@percent }
\newlabel{fig:gpowerscreenshot}{{1.8}{14}{Screenshot from G*Power software visualizing the null model (red distribution) and alternative model (blue distribution) and the critical \emph {t}-value (1.66055) that is the threshold distinguishing significant and non-significant results.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent \emph  {t}-test when \emph  {d} = 0.\relax }}{15}{figure.caption.13}\protected@file@percent }
\newlabel{fig:fig134}{{1.9}{15}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent \emph {t}-test when \emph {d} = 0.\relax }{figure.caption.13}{}}
\citation{harms_making_2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1}Misunderstanding 1: A non-significant \emph  {p}-value means that the null hypothesis is true}{16}{subsection.1.7.1}\protected@file@percent }
\newlabel{misconception1}{{1.7.1}{16}{\texorpdfstring {Misunderstanding 1: A non-significant \emph {p}-value means that the null hypothesis is true}{Misunderstanding 1: A non-significant p-value means that the null hypothesis is true}}{subsection.1.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent t-test for \emph  {d} = 0 and \emph  {d} = 0.5 when observing \emph  {d} = 0.35.\relax }}{17}{figure.caption.14}\protected@file@percent }
\newlabel{fig:fig136}{{1.10}{17}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent t-test for \emph {d} = 0 and \emph {d} = 0.5 when observing \emph {d} = 0.35.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.2}Misunderstanding 2: A significant \emph  {p}-value means that the null hypothesis is false.}{17}{subsection.1.7.2}\protected@file@percent }
\newlabel{misunderstanding-2-a-significant-p-value-means-that-the-null-hypothesis-is-false.}{{1.7.2}{17}{\texorpdfstring {Misunderstanding 2: A significant \emph {p}-value means that the null hypothesis is false.}{Misunderstanding 2: A significant p-value means that the null hypothesis is false.}}{subsection.1.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent \emph  {t}-test when \emph  {d} = 0 and observing \emph  {d} = 0.5.\relax }}{18}{figure.caption.15}\protected@file@percent }
\newlabel{fig:fig137}{{1.11}{18}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent \emph {t}-test when \emph {d} = 0 and observing \emph {d} = 0.5.\relax }{figure.caption.15}{}}
\citation{anvari_not_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.3}Misunderstanding 3: A significant \emph  {p}-value means that a practically important effect has been discovered}{19}{subsection.1.7.3}\protected@file@percent }
\newlabel{misunderstanding-3-a-significant-p-value-means-that-a-practically-important-effect-has-been-discovered}{{1.7.3}{19}{\texorpdfstring {Misunderstanding 3: A significant \emph {p}-value means that a practically important effect has been discovered}{Misunderstanding 3: A significant p-value means that a practically important effect has been discovered}}{subsection.1.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 20 observations per group in an independent \emph  {t}-test when \emph  {d} = 0.\relax }}{20}{figure.caption.16}\protected@file@percent }
\newlabel{fig:fig138}{{1.12}{20}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 20 observations per group in an independent \emph {t}-test when \emph {d} = 0.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.4}Misunderstanding 4: If you have observed a significant finding, the probability that you have made a Type 1 error (a false positive) is 5\%.}{20}{subsection.1.7.4}\protected@file@percent }
\newlabel{misconception4}{{1.7.4}{20}{Misunderstanding 4: If you have observed a significant finding, the probability that you have made a Type 1 error (a false positive) is 5\%}{subsection.1.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.5}Misunderstanding 5: One minus the \emph  {p}-value is the probability that the effect will replicate when repeated.}{21}{subsection.1.7.5}\protected@file@percent }
\newlabel{misunderstanding-5-one-minus-the-p-value-is-the-probability-that-the-effect-will-replicate-when-repeated.}{{1.7.5}{21}{\texorpdfstring {Misunderstanding 5: One minus the \emph {p}-value is the probability that the effect will replicate when repeated.}{Misunderstanding 5: One minus the p-value is the probability that the effect will replicate when repeated.}}{subsection.1.7.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Test Yourself}{21}{section.1.8}\protected@file@percent }
\newlabel{test-yourself}{{1.8}{21}{Test Yourself}{section.1.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Questions about which \emph  {p}-values you can expect}{21}{subsection.1.8.1}\protected@file@percent }
\newlabel{questions-about-which-p-values-you-can-expect}{{1.8.1}{21}{\texorpdfstring {Questions about which \emph {p}-values you can expect}{Questions about which p-values you can expect}}{subsection.1.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Questions about \emph  {p}-value misconceptions}{25}{subsection.1.8.2}\protected@file@percent }
\newlabel{questions-about-p-value-misconceptions}{{1.8.2}{25}{\texorpdfstring {Questions about \emph {p}-value misconceptions}{Questions about p-value misconceptions}}{subsection.1.8.2}{}}
\citation{tversky_belief_1971}
\citation{miller_what_2009}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Screenshot of first paragraph in Tversky and Kahneman, 1971\relax }}{28}{figure.caption.17}\protected@file@percent }
\newlabel{fig:smallnumbers}{{1.13}{28}{Screenshot of first paragraph in Tversky and Kahneman, 1971\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.3}Open Questions}{29}{subsection.1.8.3}\protected@file@percent }
\newlabel{open-questions}{{1.8.3}{29}{Open Questions}{subsection.1.8.3}{}}
\citation{benjamini_its_2016}
\citation{fricker_assessing_2019}
\citation{mayo_statistical_2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Error control}{30}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{errorcontrol}{{2}{30}{Error control}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Which outcome can you expect if you perform a study?}{30}{section.2.1}\protected@file@percent }
\newlabel{which-outcome-can-you-expect-if-you-perform-a-study}{{2.1}{30}{Which outcome can you expect if you perform a study?}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Difference between Type 1 and Type 2 errors. Figure made by <a href="https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/">Paul Ellis</a>\relax }}{31}{figure.caption.18}\protected@file@percent }
\newlabel{fig:errortypes}{{2.1}{31}{Difference between Type 1 and Type 2 errors. Figure made by <a href="https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/">Paul Ellis</a>\relax }{figure.caption.18}{}}
\gdef \LT@i {\LT@entry 
    {1}{181.39241pt}\LT@entry 
    {1}{148.16707pt}\LT@entry 
    {1}{140.24356pt}}
\citation{ioannidis_why_2005}
\citation{wacholder_assessing_2004}
\citation{colquhoun_false_2019}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Positive predictive value}{32}{section.2.2}\protected@file@percent }
\newlabel{ppv}{{2.2}{32}{Positive predictive value}{section.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Why there are more vaccinated people in the hospital. OKAY BUT THE ABOVE PARAGRAPH TALKS ABOUT \emph  {EQUAL} NUMBERS OF EACH CATEGORY.\relax }}{33}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ppvhospital}{{2.2}{33}{Why there are more vaccinated people in the hospital. OKAY BUT THE ABOVE PARAGRAPH TALKS ABOUT \emph {EQUAL} NUMBERS OF EACH CATEGORY.\relax }{figure.caption.19}{}}
\citation{dunn_multiple_1961}
\citation{babbage_reflections_1830}
\citation{barber_pitfalls_1976}
\citation{kerr_harking_1998}
\citation{fiedler_questionable_2015,john_measuring_2012,van_de_schoot_use_2021,chin_questionable_2021,makel_both_2021}
\citation{jostmann_short_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Screenshot of the output of the results of the PPV Shiny app by <a href="http://shinyapps.org/apps/PPV/">Michael Zehetleitner and Felix Schönbrodt </a>\relax }}{34}{figure.caption.20}\protected@file@percent }
\newlabel{fig:ppvexample}{{2.3}{34}{Screenshot of the output of the results of the PPV Shiny app by <a href="http://shinyapps.org/apps/PPV/">Michael Zehetleitner and Felix Schönbrodt </a>\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Type 1 error inflation}{34}{section.2.3}\protected@file@percent }
\newlabel{type-1-error-inflation}{{2.3}{34}{Type 1 error inflation}{section.2.3}{}}
\citation{elson_press_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Quote from the 1830 book by Babbage Reflections on the Decline of Science in England And on Some of Its Causes\relax }}{35}{figure.caption.21}\protected@file@percent }
\newlabel{fig:cooking}{{2.4}{35}{Quote from the 1830 book by Babbage Reflections on the Decline of Science in England And on Some of Its Causes\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Optional stopping}{35}{section.2.4}\protected@file@percent }
\newlabel{optionalstopping}{{2.4}{35}{Optional stopping}{section.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Plot of publications using CRTT (blue) and unique quantifications of the measure (red). Figure from FlexibleMeasures.com by Malte Elson\relax }}{36}{figure.caption.22}\protected@file@percent }
\newlabel{fig:flexiblemeasure}{{2.5}{36}{Plot of publications using CRTT (blue) and unique quantifications of the measure (red). Figure from FlexibleMeasures.com by Malte Elson\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Screenshot a scientific paper explicitly admitting to using optional stopping\relax }}{36}{figure.caption.23}\protected@file@percent }
\newlabel{fig:optionalstoppingexample}{{2.6}{36}{Screenshot a scientific paper explicitly admitting to using optional stopping\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Simulated \emph  {p}-values for each additional observation when the null is true.\relax }}{38}{figure.caption.24}\protected@file@percent }
\newlabel{fig:animatep}{{2.7}{38}{Simulated \emph {p}-values for each additional observation when the null is true.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Simulated \emph  {p}-values for each additional observation when d = 0.3.\relax }}{38}{figure.caption.25}\protected@file@percent }
\newlabel{fig:animatep2}{{2.8}{38}{Simulated \emph {p}-values for each additional observation when d = 0.3.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Simulation of 500000 studies performing 5 interim analyses at an alpha level of 5\%\relax }}{40}{figure.caption.26}\protected@file@percent }
\newlabel{fig:optionalstopfig}{{2.9}{40}{Simulation of 500000 studies performing 5 interim analyses at an alpha level of 5\%\relax }{figure.caption.26}{}}
\citation{neyman_problem_1933}
\citation{cowles_origins_1982,kennedy-shaffer_before_2019}
\citation{cohen_statistical_1988}
\citation{uygun_tunc_epistemic_2021}
\citation{johnson_revised_2013}
\citation{lakens_justify_2018}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Justifying Error Rates}{41}{section.2.5}\protected@file@percent }
\newlabel{justifyerrorrate}{{2.5}{41}{Justifying Error Rates}{section.2.5}{}}
\citation{mudge_setting_2012}
\citation{maier_justify_2022}
\citation{maier_justify_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Weighted combined error rate, minimized at alpha = 0.037.\relax }}{42}{figure.caption.27}\protected@file@percent }
\newlabel{fig:minimizeerror}{{2.10}{42}{Weighted combined error rate, minimized at alpha = 0.037.\relax }{figure.caption.27}{}}
\citation{leamer_specification_1978}
\citation{perneger_whats_1998}
\citation{neyman_inductive_1957}
\citation{mayo_statistical_2018}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Why you don't need to adjust your alpha level for all tests you'll do in your lifetime.}{43}{section.2.6}\protected@file@percent }
\newlabel{why-you-dont-need-to-adjust-your-alpha-level-for-all-tests-youll-do-in-your-lifetime.}{{2.6}{43}{Why you don't need to adjust your alpha level for all tests you'll do in your lifetime}{section.2.6}{}}
\citation{dmitrienko_traditional_2013}
\citation{bretz_multiple_2011}
\citation{bender_adjusting_2001}
\citation{benjamini_controlling_1995}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Power Analysis}{45}{section.2.7}\protected@file@percent }
\newlabel{power-analysis}{{2.7}{45}{Power Analysis}{section.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Test Yourself}{45}{section.2.8}\protected@file@percent }
\newlabel{test-yourself-1}{{2.8}{45}{Test Yourself}{section.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Questions about the positive predictive value}{45}{subsection.2.8.1}\protected@file@percent }
\newlabel{questions-about-the-positive-predictive-value}{{2.8.1}{45}{Questions about the positive predictive value}{subsection.2.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Distribution of \emph  {d} = 0 and \emph  {d} = 0.5 for an independent \emph  {t}-test with \emph  {n} = 50.\relax }}{46}{figure.caption.28}\protected@file@percent }
\newlabel{fig:powerd}{{2.11}{46}{Distribution of \emph {d} = 0 and \emph {d} = 0.5 for an independent \emph {t}-test with \emph {n} = 50.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Questions about optional stopping}{47}{subsection.2.8.2}\protected@file@percent }
\newlabel{questions-about-optional-stopping}{{2.8.2}{47}{Questions about optional stopping}{subsection.2.8.2}{}}
\citation{wagenmakers_practical_2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.3}Open Questions}{49}{subsection.2.8.3}\protected@file@percent }
\newlabel{open-questions-1}{{2.8.3}{49}{Open Questions}{subsection.2.8.3}{}}
\citation{pawitan_all_2001,dienes_understanding_2008}
\citation{taper_philosophy_2011}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Likelihoods}{51}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{likelihoods}{{3}{51}{Likelihoods}{chapter.3}{}}
\citation{aldrich_r_1997}
\citation{millar_maximum_2011}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Binomial likelihood function for 8 successes in 10 trials.\relax }}{53}{figure.caption.29}\protected@file@percent }
\newlabel{fig:like1}{{3.1}{53}{Binomial likelihood function for 8 successes in 10 trials.\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Binomial likelihood function for 0 successes in 10 trials.\relax }}{53}{figure.caption.30}\protected@file@percent }
\newlabel{fig:like2}{{3.2}{53}{Binomial likelihood function for 0 successes in 10 trials.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Combining likelihoods.\relax }}{54}{figure.caption.31}\protected@file@percent }
\newlabel{fig:like3}{{3.3}{54}{Combining likelihoods.\relax }{figure.caption.31}{}}
\citation{royall_statistical_1997}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Likelihood function for 5/10, 50/100 and 500/1000 heads in coin flips.\relax }}{55}{figure.caption.32}\protected@file@percent }
\newlabel{fig:like4}{{3.4}{55}{Likelihood function for 5/10, 50/100 and 500/1000 heads in coin flips.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Likelihood ratios}{55}{section.3.1}\protected@file@percent }
\newlabel{likelihood-ratios}{{3.1}{55}{Likelihood ratios}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Computing a likelihood ratio for \emph  {p} = 0.5 relative to \emph  {p} = 0.8 when observing \emph  {p} = 0.8.\relax }}{56}{figure.caption.33}\protected@file@percent }
\newlabel{fig:like5}{{3.5}{56}{Computing a likelihood ratio for \emph {p} = 0.5 relative to \emph {p} = 0.8 when observing \emph {p} = 0.8.\relax }{figure.caption.33}{}}
\citation{franco_publication_2014,fanelli_positive_2010}
\citation{schimmack_ironic_2012,francis_frequency_2014}
\citation{lakens_too_2017}
\citation{wacholder_assessing_2004}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Computing a likelihood ratio for \emph  {p} = 0.5 relative to \emph  {p} = 0.8 when observing \emph  {p} = 0.4.\relax }}{57}{figure.caption.34}\protected@file@percent }
\newlabel{fig:like6}{{3.6}{57}{Computing a likelihood ratio for \emph {p} = 0.5 relative to \emph {p} = 0.8 when observing \emph {p} = 0.4.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Likelihood of mixed results in sets of studies}{57}{section.3.2}\protected@file@percent }
\newlabel{likelihood-of-mixed-results-in-sets-of-studies}{{3.2}{57}{Likelihood of mixed results in sets of studies}{section.3.2}{}}
\citation{ioannidis_exploratory_2007}
\citation{royall_statistical_1997}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Computing a likelihood ratio for \emph  {p} = 0.3 relative to \emph  {p} = 0.8 when observing \emph  {p} = 0.5 in 100 coin flips.\relax }}{58}{figure.caption.35}\protected@file@percent }
\newlabel{fig:like7}{{3.7}{58}{Computing a likelihood ratio for \emph {p} = 0.3 relative to \emph {p} = 0.8 when observing \emph {p} = 0.5 in 100 coin flips.\relax }{figure.caption.35}{}}
\citation{scheel_excess_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Computing a likelihood ratio for 2 out of three significant results, assuming an alpha of 5\% and 80\% power.\relax }}{59}{figure.caption.36}\protected@file@percent }
\newlabel{fig:like8}{{3.8}{59}{Computing a likelihood ratio for 2 out of three significant results, assuming an alpha of 5\% and 80\% power.\relax }{figure.caption.36}{}}
\citation{glover_likelihood_2004,pawitan_all_2001}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Likelihood ratio for observed \emph  {t}-value under H0 and H1.\relax }}{60}{figure.caption.37}\protected@file@percent }
\newlabel{fig:like9}{{3.9}{60}{Likelihood ratio for observed \emph {t}-value under H0 and H1.\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Likelihoods for \emph  {t}-tests}{60}{section.3.3}\protected@file@percent }
\newlabel{likettest}{{3.3}{60}{\texorpdfstring {Likelihoods for \emph {t}-tests}{Likelihoods for t-tests}}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Test Yourself}{61}{section.3.4}\protected@file@percent }
\newlabel{test-yourself-2}{{3.4}{61}{Test Yourself}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Questions about likelihoods}{61}{subsection.3.4.1}\protected@file@percent }
\newlabel{questions-about-likelihoods}{{3.4.1}{61}{Questions about likelihoods}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Questions about mixed results}{62}{subsection.3.4.2}\protected@file@percent }
\newlabel{questions-about-mixed-results}{{3.4.2}{62}{Questions about mixed results}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Open Questions}{64}{subsection.3.4.3}\protected@file@percent }
\newlabel{open-questions-2}{{3.4.3}{64}{Open Questions}{subsection.3.4.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Bayesian statistics}{65}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{bayes}{{4}{65}{Bayesian statistics}{chapter.4}{}}
\citation{dienes_understanding_2008,kass_bayes_1995}
\citation{kruschke_doing_2014}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Bayes factors}{66}{section.4.1}\protected@file@percent }
\newlabel{bayes-factors}{{4.1}{66}{Bayes factors}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Four examples of Bayesian priors\relax }}{67}{figure.caption.38}\protected@file@percent }
\newlabel{fig:bayes1}{{4.1}{67}{Four examples of Bayesian priors\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Four examples of how different priors are updated based on data to the posterior.\relax }}{68}{figure.caption.39}\protected@file@percent }
\newlabel{fig:bayes2}{{4.2}{68}{Four examples of how different priors are updated based on data to the posterior.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Updating our belief}{68}{section.4.2}\protected@file@percent }
\newlabel{updating-our-belief}{{4.2}{68}{Updating our belief}{section.4.2}{}}
\citation{rouder_bayesian_2009}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Plot for the prior, likelihood, and posterior.\relax }}{69}{figure.caption.40}\protected@file@percent }
\newlabel{fig:bayes4}{{4.3}{69}{Plot for the prior, likelihood, and posterior.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Screenshot of the online calculator for binomially distributed observations\relax }}{69}{figure.caption.41}\protected@file@percent }
\newlabel{fig:gpower-screenshot-bayes}{{4.4}{69}{Screenshot of the online calculator for binomially distributed observations\relax }{figure.caption.41}{}}
\citation{jeffreys_theory_1939}
\citation{dienes_using_2014}
\citation{lakens_improving_2020}
\citation{wong_potential_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Plot for the prior, likelihood, and posterior.\relax }}{70}{figure.caption.42}\protected@file@percent }
\newlabel{fig:bayes6}{{4.5}{70}{Plot for the prior, likelihood, and posterior.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Plot for the prior, likelihood, and posterior.\relax }}{71}{figure.caption.43}\protected@file@percent }
\newlabel{fig:bayes7}{{4.6}{71}{Plot for the prior, likelihood, and posterior.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Bayesian Estimation}{71}{section.4.3}\protected@file@percent }
\newlabel{bayesest}{{4.3}{71}{Bayesian Estimation}{section.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Plot for the mean of the posterior when 10 out of 20 heads are observed given a uniform prior.\relax }}{72}{figure.caption.44}\protected@file@percent }
\newlabel{fig:bayes8}{{4.7}{72}{Plot for the mean of the posterior when 10 out of 20 heads are observed given a uniform prior.\relax }{figure.caption.44}{}}
\citation{albers_credible_2018}
\citation{mcelreath_statistical_2016}
\citation{berger_interplay_2004}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Test Yourself}{73}{section.4.4}\protected@file@percent }
\newlabel{test-yourself-3}{{4.4}{73}{Test Yourself}{section.4.4}{}}
\citation{rozeboom_fallacy_1960}
\citation{frick_appropriate_1996}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Open Questions}{78}{subsection.4.4.1}\protected@file@percent }
\newlabel{open-questions-3}{{4.4.1}{78}{Open Questions}{subsection.4.4.1}{}}
\citation{kenett_information_2016}
\citation{shmueli_explain_2010}
\citation{gerring_mere_2012}
\citation{scheel_why_2021}
\citation{shmueli_explain_2010}
\citation{wynants_prediction_2020}
\citation{yarkoni_choosing_2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Asking Statistical Questions}{79}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{questions}{{5}{79}{Asking Statistical Questions}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Description}{79}{section.5.1}\protected@file@percent }
\newlabel{description}{{5.1}{79}{Description}{section.5.1}{}}
\citation{meehl_appraising_1990}
\citation{uygun_tunc_falsificationist_2022}
\citation{fiedler_tools_2004}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Distinction between a theoretical hypothesis, a statistical hypothesis, and observations. Figure based on Meehl, 1990.\relax }}{80}{figure.caption.45}\protected@file@percent }
\newlabel{fig:meehl1990}{{5.1}{80}{Distinction between a theoretical hypothesis, a statistical hypothesis, and observations. Figure based on Meehl, 1990.\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Prediction}{80}{section.5.2}\protected@file@percent }
\newlabel{prediction}{{5.2}{80}{Prediction}{section.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Explanation}{80}{section.5.3}\protected@file@percent }
\newlabel{explanation}{{5.3}{80}{Explanation}{section.5.3}{}}
\citation{scheel_why_2021}
\citation{dubin_theory_1969}
\citation{royall_statistical_1997}
\citation{dongen_multiple_2019,lakens_improving_2020,tendeiro_review_2019}
\citation{jeffreys_theory_1939}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Loosening and Tightening}{81}{section.5.4}\protected@file@percent }
\newlabel{loosening-and-tightening}{{5.4}{81}{Loosening and Tightening}{section.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Three statistical philosophies}{81}{section.5.5}\protected@file@percent }
\newlabel{three-statistical-philosophies}{{5.5}{81}{Three statistical philosophies}{section.5.5}{}}
\citation{lakens_practical_2021}
\citation{cohen_earth_1994}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Four phases of clinical research. <a href="https://clinicalinfo.hiv.gov/en/glossary/phase-1-trial">Source</a>.\relax }}{82}{figure.caption.46}\protected@file@percent }
\newlabel{fig:trialphase}{{5.2}{82}{Four phases of clinical research. <a href="https://clinicalinfo.hiv.gov/en/glossary/phase-1-trial">Source</a>.\relax }{figure.caption.46}{}}
\citation{hand_deconstructing_1994}
\citation{de_groot_methodology_1969}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Do You Really Want to Test a Hypothesis?}{83}{section.5.6}\protected@file@percent }
\newlabel{do-you-really-want-to-test-a-hypothesis}{{5.6}{83}{Do You Really Want to Test a Hypothesis?}{section.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Some fields make black and white predictions about the presence or absence of observables, but in many sciences, predictions are probabilistic, and shades of grey.\relax }}{84}{figure.caption.47}\protected@file@percent }
\newlabel{fig:blackwhite}{{5.3}{84}{Some fields make black and white predictions about the presence or absence of observables, but in many sciences, predictions are probabilistic, and shades of grey.\relax }{figure.caption.47}{}}
\citation{mayo_statistical_2018}
\citation{baguley_serious_2012}
\citation{jones_test_1952}
\citation{cho_is_2013}
\citation{schulz_sample_2005}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Directional (One-Sided) versus Non-Directional (Two-Sided) Tests}{85}{section.5.7}\protected@file@percent }
\newlabel{onesided}{{5.7}{85}{Directional (One-Sided) versus Non-Directional (Two-Sided) Tests}{section.5.7}{}}
\citation{baguley_serious_2012}
\citation{de_groot_methodology_1969}
\citation{meehl_theoretical_1978}
\citation{meehl_appraising_1990}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Ratio of the required sample size for a one-sample \emph  {t}-test for a non-directional/directional test to achieve 50\%, 80\% or 95\% power.\relax }}{86}{figure.caption.48}\protected@file@percent }
\newlabel{fig:onesidedtwosidedratio}{{5.4}{86}{Ratio of the required sample size for a one-sample \emph {t}-test for a non-directional/directional test to achieve 50\%, 80\% or 95\% power.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Distribution and rejection areas for a two-sided t-test and the corresponding F-test with df1 = 1 and df2 = 100.\relax }}{87}{figure.caption.49}\protected@file@percent }
\newlabel{fig:fandt}{{5.5}{87}{Distribution and rejection areas for a two-sided t-test and the corresponding F-test with df1 = 1 and df2 = 100.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Systematic Noise, or the Crud Factor}{87}{section.5.8}\protected@file@percent }
\newlabel{crud}{{5.8}{87}{Systematic Noise, or the Crud Factor}{section.5.8}{}}
\citation{orben_crud_2020}
\citation{ferguson_providing_2021}
\citation{morey_pre-registered_2021}
\citation{odonnell_registered_2018}
\citation{verschuere_registered_2018}
\citation{wagenmakers_registered_2016}
\citation{hagger_multilab_2016}
\citation{colling_registered_2020}
\citation{mccarthy_registered_2018}
\citation{baguley_standardized_2009}
\citation{cohen_things_1990}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Effect Sizes}{90}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{effectsize}{{6}{90}{Effect Sizes}{chapter.6}{}}
\citation{kelley_effect_2012}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Effect sizes}{91}{section.6.1}\protected@file@percent }
\newlabel{effect-sizes}{{6.1}{91}{Effect sizes}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}The Facebook experiment}{91}{section.6.2}\protected@file@percent }
\newlabel{the-facebook-experiment}{{6.2}{91}{The Facebook experiment}{section.6.2}{}}
\citation{danziger_extraneous_2011}
\citation{glockner_irrational_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Proportion of rulings in favor of the prisoners by ordinal position. Circled points indicate the first decision in each of the three decision sessions; tick marks on x axis denote every third case; dotted line denotes food break. From Danziger, S., Levav, J., Avnaim-Pesso, L. (2011). Extraneous factors in judicial decisions. Proceedings of the National Academy of Sciences, 108(17), 6889--6892. \url  {https://doi.org/10.1073/PNAS.1018033108}\relax }}{93}{figure.caption.50}\protected@file@percent }
\newlabel{fig:hungryjudges}{{6.1}{93}{Proportion of rulings in favor of the prisoners by ordinal position. Circled points indicate the first decision in each of the three decision sessions; tick marks on x axis denote every third case; dotted line denotes food break. From Danziger, S., Levav, J., Avnaim-Pesso, L. (2011). Extraneous factors in judicial decisions. Proceedings of the National Academy of Sciences, 108(17), 6889--6892. \url {https://doi.org/10.1073/PNAS.1018033108}\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}The Hungry Judges study}{93}{section.6.3}\protected@file@percent }
\newlabel{the-hungry-judges-study}{{6.3}{93}{The Hungry Judges study}{section.6.3}{}}
\citation{richard_one_2003}
\citation{weinshall-margel_overlooked_2011,chatziathanasiou_beware_2022}
\citation{hilgard_maximal_2021}
\citation{rosenthal_contrasts_2000}
\citation{cohen_statistical_1988}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Standardised Mean Differences}{94}{section.6.4}\protected@file@percent }
\newlabel{cohend}{{6.4}{94}{Standardised Mean Differences}{section.6.4}{}}
\citation{lakens_calculating_2013}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces A vizualization of 2 groups (although the difference is hardly visible) representing d = 0.001.\relax }}{95}{figure.caption.51}\protected@file@percent }
\newlabel{fig:rpsychd1}{{6.2}{95}{A vizualization of 2 groups (although the difference is hardly visible) representing d = 0.001.\relax }{figure.caption.51}{}}
\citation{richard_one_2003}
\citation{mcgraw_common_1992}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces A vizualization of 2 groups representing d = 0.43.\relax }}{97}{figure.caption.52}\protected@file@percent }
\newlabel{fig:rpsychd2}{{6.3}{97}{A vizualization of 2 groups representing d = 0.43.\relax }{figure.caption.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces A vizualization of 2 groups representing d = 2.\relax }}{97}{figure.caption.53}\protected@file@percent }
\newlabel{fig:rpsychd3}{{6.4}{97}{A vizualization of 2 groups representing d = 2.\relax }{figure.caption.53}{}}
\citation{maxwell_designing_2004}
\citation{cumming_understanding_2013}
\citation{mcgrath_when_2006}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Interpreting effect sizes}{98}{section.6.5}\protected@file@percent }
\newlabel{interpreting-effect-sizes}{{6.5}{98}{Interpreting effect sizes}{section.6.5}{}}
\citation{chambers_past_2022,nosek_registered_2014}
\citation{open_science_collaboration_estimating_2015}
\citation{primbs_are_2022,anvari_not_2021}
\citation{gotz_small_2022}
\citation{baguley_standardized_2009,funder_evaluating_2019}
\citation{funder_evaluating_2019}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Correlations and Variance Explained}{99}{section.6.6}\protected@file@percent }
\newlabel{correlations-and-variance-explained}{{6.6}{99}{Correlations and Variance Explained}{section.6.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Screenshot from Guess the Correlation game (the correct answer is r = 0.24).\relax }}{100}{figure.caption.54}\protected@file@percent }
\newlabel{fig:guesscorrelation}{{6.5}{100}{Screenshot from Guess the Correlation game (the correct answer is r = 0.24).\relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Screenshot from correation effect size vizualization by Kristoffer Magnusson for r - 0.21.\relax }}{101}{figure.caption.55}\protected@file@percent }
\newlabel{fig:sharedvariance}{{6.6}{101}{Screenshot from correation effect size vizualization by Kristoffer Magnusson for r - 0.21.\relax }{figure.caption.55}{}}
\citation{keppel_design_1991}
\citation{cohen_statistical_1988}
\citation{thompson_effect_2007}
\citation{okada_is_2013,albers_when_2018}
\citation{olejnik_generalized_2003}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Correcting for Bias}{102}{section.6.7}\protected@file@percent }
\newlabel{correcting-for-bias}{{6.7}{102}{Correcting for Bias}{section.6.7}{}}
\citation{maxwell_designing_2004}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Effect Sizes for Interactions}{103}{section.6.8}\protected@file@percent }
\newlabel{effect-sizes-for-interactions}{{6.8}{103}{Effect Sizes for Interactions}{section.6.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Schematic illustration of a disordinal (or cross-over) and ordinal interaction\relax }}{104}{figure.caption.56}\protected@file@percent }
\newlabel{fig:interactions}{{6.7}{104}{Schematic illustration of a disordinal (or cross-over) and ordinal interaction\relax }{figure.caption.56}{}}
\citation{lakens_simulation-based_2021}
\citation{debruine_understanding_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Disordinal (or cross-over) and ordinal interaction with means of 0 and 1, n = 50 per group, and an sd of 2.\relax }}{105}{figure.caption.57}\protected@file@percent }
\newlabel{fig:interactionplots}{{6.8}{105}{Disordinal (or cross-over) and ordinal interaction with means of 0 and 1, n = 50 per group, and an sd of 2.\relax }{figure.caption.57}{}}
\citation{richard_one_2003}
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Test Yourself}{106}{section.6.9}\protected@file@percent }
\newlabel{test-yourself-4}{{6.9}{106}{Test Yourself}{section.6.9}{}}
\citation{mcgrath_when_2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.1}Open Questions}{108}{subsection.6.9.1}\protected@file@percent }
\newlabel{open-questions-4}{{6.9.1}{108}{Open Questions}{subsection.6.9.1}{}}
\citation{spiegelhalter_art_2019}
\citation{kish_survey_1965}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Confidence Intervals}{109}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{confint}{{7}{109}{Confidence Intervals}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Population vs.\nobreakspace  {}Sample}{109}{section.7.1}\protected@file@percent }
\newlabel{population-vs.-sample}{{7.1}{109}{Population vs.~Sample}{section.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Example of a registry-based study in which the entire population was included in the study. From \url  {https://doi.org/10.1093/ije/dyab066}\relax }}{109}{figure.caption.58}\protected@file@percent }
\newlabel{fig:population}{{7.1}{109}{Example of a registry-based study in which the entire population was included in the study. From \url {https://doi.org/10.1093/ije/dyab066}\relax }{figure.caption.58}{}}
\citation{cousineau_superb_2019}
\citation{appelbaum_journal_2018}
\citation{lehmann_testing_2005}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}What is a Confidence Interval?}{110}{section.7.2}\protected@file@percent }
\newlabel{what-is-a-confidence-interval}{{7.2}{110}{What is a Confidence Interval?}{section.7.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}The relation between confidence intervals and \emph  {p}-values}{110}{section.7.3}\protected@file@percent }
\newlabel{relatCIp}{{7.3}{110}{\texorpdfstring {The relation between confidence intervals and \emph {p}-values}{The relation between confidence intervals and p-values}}{section.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Series of simulated point estimates and confidence intervals\relax }}{111}{figure.caption.59}\protected@file@percent }
\newlabel{fig:cisim}{{7.2}{111}{Series of simulated point estimates and confidence intervals\relax }{figure.caption.59}{}}
\citation{steiger_beyond_2004}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Meta-analysis of 4 studies\relax }}{112}{figure.caption.60}\protected@file@percent }
\newlabel{fig:meta}{{7.3}{112}{Meta-analysis of 4 studies\relax }{figure.caption.60}{}}
\citation{bauer_unifying_1996}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}The Standard Error and 95\% Confidence Intervals}{113}{section.7.4}\protected@file@percent }
\newlabel{the-standard-error-and-95-confidence-intervals}{{7.4}{113}{The Standard Error and 95\% Confidence Intervals}{section.7.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Means and 95\% confidence intervals of two independent groups and the mean difference between the two groups and its 95\% confidence interval.\relax }}{114}{figure.caption.61}\protected@file@percent }
\newlabel{fig:cioverlap}{{7.4}{114}{Means and 95\% confidence intervals of two independent groups and the mean difference between the two groups and its 95\% confidence interval.\relax }{figure.caption.61}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Overlapping Confidence Intervals}{114}{section.7.5}\protected@file@percent }
\newlabel{overlapping-confidence-intervals}{{7.5}{114}{Overlapping Confidence Intervals}{section.7.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces A comparison of a 95\% confidence interval (orange) and 95\% prediction interval (yellow).\relax }}{115}{figure.caption.62}\protected@file@percent }
\newlabel{fig:predictioninterval}{{7.5}{115}{A comparison of a 95\% confidence interval (orange) and 95\% prediction interval (yellow).\relax }{figure.caption.62}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Prediction Intervals}{115}{section.7.6}\protected@file@percent }
\newlabel{prediction-intervals}{{7.6}{115}{Prediction Intervals}{section.7.6}{}}
\citation{cumming_confidence_2006}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Meta-analysis of two simulated studies from the same population.\relax }}{116}{figure.caption.63}\protected@file@percent }
\newlabel{fig:metaci}{{7.6}{116}{Meta-analysis of two simulated studies from the same population.\relax }{figure.caption.63}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Capture Percentages}{116}{section.7.7}\protected@file@percent }
\newlabel{capture-percentages}{{7.7}{116}{Capture Percentages}{section.7.7}{}}
\citation{cohen_earth_1994}
\citation{buchanan_mote_2017}
\citation{kelley_confidence_2007}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Calculating Confidence Intervals around Standard Deviations.}{117}{section.7.8}\protected@file@percent }
\newlabel{calculating-confidence-intervals-around-standard-deviations.}{{7.8}{117}{Calculating Confidence Intervals around Standard Deviations}{section.7.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.9}Computing Confidence Intervals around Effect Sizes}{117}{section.7.9}\protected@file@percent }
\newlabel{computing-confidence-intervals-around-effect-sizes}{{7.9}{117}{Computing Confidence Intervals around Effect Sizes}{section.7.9}{}}
\citation{ben-shachar_effectsize_2020}
\citation{delacre_why_2017}
\citation{delacre_why_2021}
\citation{cumming_introduction_2016}
\citation{okada_is_2013,albers_when_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Output from ESCI module in jamovi.\relax }}{119}{figure.caption.64}\protected@file@percent }
\newlabel{fig:escijamovi}{{7.7}{119}{Output from ESCI module in jamovi.\relax }{figure.caption.64}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces JASP menu option allows you to select Cohen's d and a CI around it.\relax }}{120}{figure.caption.65}\protected@file@percent }
\newlabel{fig:jasp1}{{7.8}{120}{JASP menu option allows you to select Cohen's d and a CI around it.\relax }{figure.caption.65}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces JASP output returns Cohen's d and the confidence interval around it.\relax }}{120}{figure.caption.66}\protected@file@percent }
\newlabel{fig:jasp2}{{7.9}{120}{JASP output returns Cohen's d and the confidence interval around it.\relax }{figure.caption.66}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.10}Test Yourself}{120}{section.7.10}\protected@file@percent }
\newlabel{test-yourself-5}{{7.10}{120}{Test Yourself}{section.7.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces Meta-analysis of 4 studies\relax }}{121}{figure.caption.67}\protected@file@percent }
\newlabel{fig:metaQ}{{7.10}{121}{Meta-analysis of 4 studies\relax }{figure.caption.67}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.10.1}Open Questions}{127}{subsection.7.10.1}\protected@file@percent }
\newlabel{open-questions-5}{{7.10.1}{127}{Open Questions}{subsection.7.10.1}{}}
\citation{lakens_sample_2022}
\citation{hedges_power_2001}
\citation{valentine_how_2010}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Sample Size Justification}{129}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{power}{{8}{129}{Sample Size Justification}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Six Approaches to Justify Sample Sizes}{129}{section.8.1}\protected@file@percent }
\newlabel{six-approaches-to-justify-sample-sizes}{{8.1}{129}{Six Approaches to Justify Sample Sizes}{section.8.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Overview of possible justifications for the sample size in a study.\relax }}{129}{table.caption.68}\protected@file@percent }
\newlabel{tab:table-pow-just}{{8.1}{129}{Overview of possible justifications for the sample size in a study.\relax }{table.caption.68}{}}
\citation{lakens_sample_2022}
\citation{eckermann_value_2010}
\citation{detsky_using_1990}
\citation{wilson_practical_2015,halpern_sample_2001}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Six Ways to Evaluate Which Effect Sizes are Interesting}{130}{section.8.2}\protected@file@percent }
\newlabel{six-ways-to-evaluate-which-effect-sizes-are-interesting}{{8.2}{130}{Six Ways to Evaluate Which Effect Sizes are Interesting}{section.8.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.2}{\ignorespaces Overview of possible ways to evaluate which effect sizes are interesting.\relax }}{131}{table.caption.69}\protected@file@percent }
\newlabel{tab:table-effect-eval}{{8.2}{131}{Overview of possible ways to evaluate which effect sizes are interesting.\relax }{table.caption.69}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}The Value of Information}{131}{section.8.3}\protected@file@percent }
\newlabel{the-value-of-information}{{8.3}{131}{The Value of Information}{section.8.3}{}}
\citation{lenth_practical_2001}
\citation{bulus_bound_2021}
\citation{parker_sample_2003}
\citation{maxwell_ethics_2011}
\citation{halpern_continuing_2002}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Measuring (Almost) the Entire Population}{132}{section.8.4}\protected@file@percent }
\newlabel{measuring-almost-the-entire-population}{{8.4}{132}{Measuring (Almost) the Entire Population}{section.8.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Resource Constraints}{132}{section.8.5}\protected@file@percent }
\newlabel{resource-constraints}{{8.5}{132}{Resource Constraints}{section.8.5}{}}
\citation{cumming_new_2014}
\citation{ter_schure_accumulation_2019}
\@writefile{lot}{\contentsline {table}{\numberline {8.3}{\ignorespaces Overview of recommendations when reporting a sample size justification based on resource constraints.\relax }}{133}{table.caption.70}\protected@file@percent }
\newlabel{tab:table-pow-rec}{{8.3}{133}{Overview of recommendations when reporting a sample size justification based on resource constraints.\relax }{table.caption.70}{}}
\citation{westfall_statistical_2014}
\citation{ferron_power_1996,mcintosh_power_2020}
\citation{lakens_justify_2018}
\citation{lakens_too_2017}
\@writefile{toc}{\contentsline {section}{\numberline {8.6}A-priori Power Analysis}{134}{section.8.6}\protected@file@percent }
\newlabel{aprioripower}{{8.6}{134}{A-priori Power Analysis}{section.8.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Power curve for an independent \emph  {t} test with an effect of \emph  {d} = 0.5 and α = 0.05 as a function of the sample size.\relax }}{135}{figure.caption.71}\protected@file@percent }
\newlabel{fig:power-2}{{8.1}{135}{Power curve for an independent \emph {t} test with an effect of \emph {d} = 0.5 and α = 0.05 as a function of the sample size.\relax }{figure.caption.71}{}}
\citation{meyners_equivalence_2012,lakens_equivalence_2017,rogers_using_1993}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Null (\emph  {d} = 0, grey dashed line) and alternative (\emph  {d} = 0.5, solid black line) hypothesis, with α = 0.05 and n = 80 per group.\relax }}{136}{figure.caption.72}\protected@file@percent }
\newlabel{fig:power-3}{{8.2}{136}{Null (\emph {d} = 0, grey dashed line) and alternative (\emph {d} = 0.5, solid black line) hypothesis, with α = 0.05 and n = 80 per group.\relax }{figure.caption.72}{}}
\citation{morris_using_2019}
\citation{aberson_applied_2019,cohen_statistical_1988,murphy_statistical_2014,julious_sample_2004}
\citation{maxwell_sample_2008,brysbaert_how_2019,perugini_practical_2018,faul_gpower_2007,baguley_understanding_2004}
\citation{debruine_understanding_2021,lakens_simulation-based_2021,green_simr_2016,brysbaert_power_2018,westfall_statistical_2014,schoemann_determining_2017,kruschke_bayesian_2013}
\citation{lakens_equivalence_2018}
\citation{cumming_introduction_2016,maxwell_sample_2008,kruschke_rejecting_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces All details about the power analysis that is performed can be exported in G*Power.\relax }}{138}{figure.caption.73}\protected@file@percent }
\newlabel{fig:gpowprotocol}{{8.3}{138}{All details about the power analysis that is performed can be exported in G*Power.\relax }{figure.caption.73}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.4}{\ignorespaces Overview of recommendations when reporting an a-priori power analysis.\relax }}{138}{table.caption.74}\protected@file@percent }
\newlabel{tab:table-pow-rec-2}{{8.4}{138}{Overview of recommendations when reporting an a-priori power analysis.\relax }{table.caption.74}{}}
\citation{maxwell_sample_2008}
\citation{kelley_sample_2006}
\citation{kelley_confidence_2007}
\citation{morey_power_2020}
\citation{kruschke_rejecting_2018}
\citation{hilgard_maximal_2021}
\citation{berkeley_defence_1735}
\@writefile{toc}{\contentsline {section}{\numberline {8.7}Planning for Precision}{139}{section.8.7}\protected@file@percent }
\newlabel{planning-for-precision}{{8.7}{139}{Planning for Precision}{section.8.7}{}}
\citation{wilson_vanvoorhis_understanding_2007}
\citation{green_how_1991}
\citation{simmons_false-positive_2011}
\citation{simmons_life_2013}
\citation{simonsohn_small_2015}
\@writefile{toc}{\contentsline {section}{\numberline {8.8}Heuristics}{140}{section.8.8}\protected@file@percent }
\newlabel{heuristics}{{8.8}{140}{Heuristics}{section.8.8}{}}
\citation{cook_assessing_2014}
\citation{keefe_defining_2013}
\citation{king_point_2011}
\citation{copay_understanding_2007}
\citation{lakens_equivalence_2018}
\@writefile{toc}{\contentsline {section}{\numberline {8.9}No Justification}{141}{section.8.9}\protected@file@percent }
\newlabel{no-justification}{{8.9}{141}{No Justification}{section.8.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.10}What is Your Inferential Goal?}{141}{section.8.10}\protected@file@percent }
\newlabel{what-is-your-inferential-goal}{{8.10}{141}{What is Your Inferential Goal?}{section.8.10}{}}
\citation{murphy_statistical_2014}
\citation{kelley_effect_2012}
\citation{brown_errors_1983,aberson_applied_2019,albers_when_2018,cascio_open_1983,dienes_using_2014,lenth_practical_2001}
\citation{cook_assessing_2014}
\citation{phillips_statistical_2001}
\@writefile{toc}{\contentsline {section}{\numberline {8.11}What is the Smallest Effect Size of Interest?}{142}{section.8.11}\protected@file@percent }
\newlabel{what-is-the-smallest-effect-size-of-interest}{{8.11}{142}{What is the Smallest Effect Size of Interest?}{section.8.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.12}The Minimal Statistically Detectable Effect}{142}{section.8.12}\protected@file@percent }
\newlabel{minimaldetectable}{{8.12}{142}{The Minimal Statistically Detectable Effect}{section.8.12}{}}
\citation{lakens_equivalence_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces Critical effect size for an independent \emph  {t} test with n = 15 per group and \(\mitalpha \) = 0.05.\relax }}{143}{figure.caption.75}\protected@file@percent }
\newlabel{fig:power-effect1}{{8.4}{143}{Critical effect size for an independent \emph {t} test with n = 15 per group and \(\alpha \) = 0.05.\relax }{figure.caption.75}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces The critical correlation of a test based on a total sample size of 30 and α = 0.05 calculated in G*Power.\relax }}{144}{figure.caption.76}\protected@file@percent }
\newlabel{fig:gcrit2}{{8.5}{144}{The critical correlation of a test based on a total sample size of 30 and α = 0.05 calculated in G*Power.\relax }{figure.caption.76}{}}
\citation{kenny_unappreciated_2019,olsson-collentine_heterogeneity_2020}
\@writefile{toc}{\contentsline {section}{\numberline {8.13}What is the Expected Effect Size?}{145}{section.8.13}\protected@file@percent }
\newlabel{what-is-the-expected-effect-size}{{8.13}{145}{What is the Expected Effect Size?}{section.8.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.14}Using an Estimate from a Meta-Analysis}{145}{section.8.14}\protected@file@percent }
\newlabel{using-an-estimate-from-a-meta-analysis}{{8.14}{145}{Using an Estimate from a Meta-Analysis}{section.8.14}{}}
\citation{carter_correcting_2019}
\citation{lakens_simulation-based_2021}
\citation{leon_role_2011}
\@writefile{lot}{\contentsline {table}{\numberline {8.5}{\ignorespaces Overview of recommendations when justifying the use of a meta-analytic effect size estimate for a power analysis.\relax }}{146}{table.caption.77}\protected@file@percent }
\newlabel{tab:tablemetajust}{{8.5}{146}{Overview of recommendations when justifying the use of a meta-analytic effect size estimate for a power analysis.\relax }{table.caption.77}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.15}Using an Estimate from a Previous Study}{146}{section.8.15}\protected@file@percent }
\newlabel{using-an-estimate-from-a-previous-study}{{8.15}{146}{Using an Estimate from a Previous Study}{section.8.15}{}}
\citation{richardson_eta_2011}
\citation{albers_when_2018}
\citation{taylor_bias_1996}
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces Distribution of partial eta squared under the null hypothesis (dotted grey curve) and a medium true effect of 0.0588 (solid black curve) for 3 groups with 25 observations.\relax }}{147}{figure.caption.78}\protected@file@percent }
\newlabel{fig:followupbias}{{8.6}{147}{Distribution of partial eta squared under the null hypothesis (dotted grey curve) and a medium true effect of 0.0588 (solid black curve) for 3 groups with 25 observations.\relax }{figure.caption.78}{}}
\citation{anderson_sample-size_2017}
\citation{perugini_safeguard_2014}
\citation{teare_sample_2014}
\citation{tversky_features_1977}
\@writefile{lot}{\contentsline {table}{\numberline {8.6}{\ignorespaces Overview of recommendations when justifying the use of an effect size estimate from a single study.\relax }}{148}{table.caption.79}\protected@file@percent }
\newlabel{tab:table-es-just}{{8.6}{148}{Overview of recommendations when justifying the use of an effect size estimate from a single study.\relax }{table.caption.79}{}}
\citation{kelley_confidence_2007}
\citation{cumming_understanding_2013}
\citation{smithson_confidence_2003}
\citation{albers_credible_2018,kruschke_bayesian_2011}
\citation{richard_one_2003}
\@writefile{toc}{\contentsline {section}{\numberline {8.16}Using an Estimate from a Theoretical Model}{149}{section.8.16}\protected@file@percent }
\newlabel{using-an-estimate-from-a-theoretical-model}{{8.16}{149}{Using an Estimate from a Theoretical Model}{section.8.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.17}Compute the Width of the Confidence Interval around the Effect Size}{149}{section.8.17}\protected@file@percent }
\newlabel{compute-the-width-of-the-confidence-interval-around-the-effect-size}{{8.17}{149}{Compute the Width of the Confidence Interval around the Effect Size}{section.8.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces Central (black dashed line) and 2 non-central (dark grey and light grey dashed lines) \emph  {t} distributions; ncp = noncentrality parameter\relax }}{150}{figure.caption.80}\protected@file@percent }
\newlabel{fig:noncentralt}{{8.7}{150}{Central (black dashed line) and 2 non-central (dark grey and light grey dashed lines) \emph {t} distributions; ncp = noncentrality parameter\relax }{figure.caption.80}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.18}Plot a Sensitivity Power Analysis}{150}{section.8.18}\protected@file@percent }
\newlabel{plot-a-sensitivity-power-analysis}{{8.18}{150}{Plot a Sensitivity Power Analysis}{section.8.18}{}}
\citation{bacchetti_current_2010}
\citation{cook_assessing_2014,correll_avoid_2020}
\citation{funder_evaluating_2019}
\citation{brysbaert_how_2019}
\citation{bosco_correlational_2015,hill_empirical_2008,kraft_interpreting_2020,lovakov_empirically_2017,funder_evaluating_2019}
\@writefile{toc}{\contentsline {section}{\numberline {8.19}The Distribution of Effect Sizes in a Research Area}{151}{section.8.19}\protected@file@percent }
\newlabel{the-distribution-of-effect-sizes-in-a-research-area}{{8.19}{151}{The Distribution of Effect Sizes in a Research Area}{section.8.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.8}{\ignorespaces Sensitivity power analysis in G*Power software.\relax }}{152}{figure.caption.81}\protected@file@percent }
\newlabel{fig:gsens0}{{8.8}{152}{Sensitivity power analysis in G*Power software.\relax }{figure.caption.81}{}}
\citation{scheel_why_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {8.9}{\ignorespaces Plot of the effect size against the desired power when n = 15 per group and alpha = 0.05.\relax }}{153}{figure.caption.82}\protected@file@percent }
\newlabel{fig:gsens1}{{8.9}{153}{Plot of the effect size against the desired power when n = 15 per group and alpha = 0.05.\relax }{figure.caption.82}{}}
\citation{zumbo_note_1998}
\citation{lenth_post_2007}
\citation{jaeschke_measurement_1989}
\citation{neyman_problem_1933}
\citation{cohen_statistical_1988}
\@writefile{toc}{\contentsline {section}{\numberline {8.20}Additional Considerations When Designing an Informative Study}{154}{section.8.20}\protected@file@percent }
\newlabel{additional-considerations-when-designing-an-informative-study}{{8.20}{154}{Additional Considerations When Designing an Informative Study}{section.8.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.21}Compromise Power Analysis}{154}{section.8.21}\protected@file@percent }
\newlabel{compromise-power-analysis}{{8.21}{154}{Compromise Power Analysis}{section.8.21}{}}
\citation{cascio_open_1983}
\citation{erdfelder_gpower_1996}
\citation{faul_gpower_2007}
\citation{winer_statistical_1962}
\citation{maier_justify_2022,murphy_statistical_2014,miller_quest_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {8.10}{\ignorespaces Compromise power analysis in G*Power.\relax }}{156}{figure.caption.83}\protected@file@percent }
\newlabel{fig:gpowcompromise}{{8.10}{156}{Compromise power analysis in G*Power.\relax }{figure.caption.83}{}}
\citation{jeffreys_theory_1939,good_bayesnon-bayes_1992}
\citation{maier_justify_2022}
\citation{zumbo_note_1998,lenth_post_2007}
\citation{hoenig_abuse_2001}
\@writefile{lot}{\contentsline {table}{\numberline {8.7}{\ignorespaces Overview of recommendations when justifying error rates based on a compromise power analysis.\relax }}{157}{table.caption.84}\protected@file@percent }
\newlabel{tab:table-compromise-just}{{8.7}{157}{Overview of recommendations when justifying error rates based on a compromise power analysis.\relax }{table.caption.84}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.22}What to do if Your Editor Asks for Post-hoc Power?}{157}{section.8.22}\protected@file@percent }
\newlabel{posthocpower}{{8.22}{157}{What to do if Your Editor Asks for Post-hoc Power?}{section.8.22}{}}
\citation{lenth_post_2007}
\citation{hoenig_abuse_2001,lenth_post_2007,yuan_post_2005,schulz_sample_2005}
\@writefile{lof}{\contentsline {figure}{\numberline {8.11}{\ignorespaces Relationship between \emph  {p} values and power for an independent \emph  {t} test with α = 0.05 and n = 10.\relax }}{158}{figure.caption.85}\protected@file@percent }
\newlabel{fig:obs-power-plot-2}{{8.11}{158}{Relationship between \emph {p} values and power for an independent \emph {t} test with α = 0.05 and n = 10.\relax }{figure.caption.85}{}}
\citation{wassmer_group_2016,proschan_statistical_2006}
\citation{dodge_method_1929}
\citation{wald_sequential_1945}
\citation{westberg_combining_1985}
\citation{jennison_group_2000}
\citation{schonbrodt_sequential_2017}
\citation{grunwald_safe_2019}
\citation{schnuerch_controlling_2020}
\citation{wassmer_group_2016}
\citation{ter_schure_accumulation_2019}
\citation{lakens_performing_2014}
\citation{cho_is_2013}
\citation{rice_heads_1994}
\@writefile{toc}{\contentsline {section}{\numberline {8.23}Sequential Analyses}{159}{section.8.23}\protected@file@percent }
\newlabel{sequentialsamplesize}{{8.23}{159}{Sequential Analyses}{section.8.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.24}Increasing Power Without Increasing the Sample Size}{159}{section.8.24}\protected@file@percent }
\newlabel{increasing-power-without-increasing-the-sample-size}{{8.24}{159}{Increasing Power Without Increasing the Sample Size}{section.8.24}{}}
\citation{cascio_open_1983,mudge_setting_2012,murphy_statistical_2014,miller_quest_2019}
\citation{field_minimizing_2004,baguley_understanding_2004}
\citation{maxwell_designing_2017}
\citation{maxwell_designing_2017}
\citation{allison_power_1997,bausell_power_2002,hallahan_statistical_1996}
\citation{williams_impact_1995}
\citation{meyvis_increasing_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {8.12}{\ignorespaces Distributions of two dependent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.\relax }}{161}{figure.caption.86}\protected@file@percent }
\newlabel{fig:plot-1}{{8.12}{161}{Distributions of two dependent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.\relax }{figure.caption.86}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.13}{\ignorespaces Distributions of two independent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.7.\relax }}{161}{figure.caption.87}\protected@file@percent }
\newlabel{fig:plot-4}{{8.13}{161}{Distributions of two independent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.7.\relax }{figure.caption.87}{}}
\citation{gupta_intention_2011}
\citation{baguley_standardized_2009,lenth_practical_2001}
\citation{westfall_statistical_2014,debruine_understanding_2021}
\citation{parsons_psychological_2019}
\citation{smithson_confidence_2003}
\citation{wittes_role_1990}
\citation{friede_sample_2006,proschan_two-stage_2005}
\citation{chang_adaptive_2016}
\@writefile{toc}{\contentsline {section}{\numberline {8.25}Know Your Measure}{162}{section.8.25}\protected@file@percent }
\newlabel{know-your-measure}{{8.25}{162}{Know Your Measure}{section.8.25}{}}
\citation{johnson_revised_2013}
\citation{mullan_town_1985}
\citation{fried_method_1993}
\citation{morse_significance_1995}
\citation{marshall_does_2013}
\@writefile{toc}{\contentsline {section}{\numberline {8.26}Conventions as meta-heuristics}{163}{section.8.26}\protected@file@percent }
\newlabel{conventions-as-meta-heuristics}{{8.26}{163}{Conventions as meta-heuristics}{section.8.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.27}Sample Size Justification in Qualitative Research}{163}{section.8.27}\protected@file@percent }
\newlabel{sample-size-justification-in-qualitative-research}{{8.27}{163}{Sample Size Justification in Qualitative Research}{section.8.27}{}}
\citation{fugard_supporting_2015}
\citation{rijnsoever_i_2017}
\citation{button_power_2013,brown_errors_1983,halpern_continuing_2002}
\citation{lindsay_replication_2015,sedlmeier_studies_1989,fraley_n-pact_2014,button_power_2013}
\citation{moshontz_psychological_2018}
\@writefile{toc}{\contentsline {section}{\numberline {8.28}Discussion}{164}{section.8.28}\protected@file@percent }
\newlabel{discussion}{{8.28}{164}{Discussion}{section.8.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.29}Test Yourself}{165}{section.8.29}\protected@file@percent }
\newlabel{test-yourself-6}{{8.29}{165}{Test Yourself}{section.8.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.29.1}Open Questions}{167}{subsection.8.29.1}\protected@file@percent }
\newlabel{open-questions-6}{{8.29.1}{167}{Open Questions}{subsection.8.29.1}{}}
\citation{altman_statistics_1995}
\citation{dienes_using_2014}
\citation{hodges_testing_1954}
\citation{nunnally_place_1960}
\citation{bauer_unifying_1996}
\citation{kruschke_bayesian_2013}
\citation{cribbie_recommendations_2004,levine_communication_2008,hoenig_abuse_2001,rogers_using_1993,quertemont_how_2011}
\citation{bem_feeling_2011}
\citation{anderson_theres_2016,lakens_equivalence_2017,simonsohn_small_2015}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Equivalence Testing and Interval Hypotheses}{168}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{equivalencetest}{{9}{168}{Equivalence Testing and Interval Hypotheses}{chapter.9}{}}
\citation{nickerson_null_2000}
\citation{lakens_practical_2021}
\citation{murphy_testing_1999}
\citation{murphy_statistical_2014}
\citation{meehl_appraising_1990,orben_crud_2020}
\citation{ferguson_providing_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Two-sided null hypothesis test (A), interval hypothesis test (B), equivalence test (C) and minimum effect test (D).\relax }}{170}{figure.caption.88}\protected@file@percent }
\newlabel{fig:intervaltest}{{9.1}{170}{Two-sided null hypothesis test (A), interval hypothesis test (B), equivalence test (C) and minimum effect test (D).\relax }{figure.caption.88}{}}
\citation{schumi_through_2011,mazzolari_myths_2022}
\citation{hauck_new_1984,westlake_use_1972}
\citation{schuirmann_comparison_1987,seaman_equivalence_1998,wellek_testing_2010}
\citation{parkhurst_statistical_2001}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Equivalence tests}{171}{section.9.1}\protected@file@percent }
\newlabel{equivalence-tests}{{9.1}{171}{Equivalence tests}{section.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces The mean difference and its confidence interval plotted below the \emph  {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5.\relax }}{172}{figure.caption.89}\protected@file@percent }
\newlabel{fig:tdistequivalence}{{9.2}{172}{The mean difference and its confidence interval plotted below the \emph {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5.\relax }{figure.caption.89}{}}
\citation{delacre_why_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }}{174}{figure.caption.90}\protected@file@percent }
\newlabel{fig:ciequivalence1}{{9.3}{174}{The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }{figure.caption.90}{}}
\citation{schweder_confidence_2016}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Reporting Equivalence Tests}{175}{section.9.2}\protected@file@percent }
\newlabel{reporting-equivalence-tests}{{9.2}{175}{Reporting Equivalence Tests}{section.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }}{176}{figure.caption.91}\protected@file@percent }
\newlabel{fig:ciequivalence2}{{9.4}{176}{The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }{figure.caption.91}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces The mean difference and its confidence interval plotted below the \emph  {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5 when performing a minimum effect test.\relax }}{177}{figure.caption.92}\protected@file@percent }
\newlabel{fig:tmet}{{9.5}{177}{The mean difference and its confidence interval plotted below the \emph {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5 when performing a minimum effect test.\relax }{figure.caption.92}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Minimum Effect Tests}{177}{section.9.3}\protected@file@percent }
\newlabel{MET}{{9.3}{177}{Minimum Effect Tests}{section.9.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Power Analysis for Interval Hypothesis Tests}{178}{section.9.4}\protected@file@percent }
\newlabel{power-analysis-for-interval-hypothesis-tests}{{9.4}{178}{Power Analysis for Interval Hypothesis Tests}{section.9.4}{}}
\citation{kruschke_bayesian_2013}
\citation{kruschke_bayesian_2017}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}The Bayesian ROPE procedure}{180}{section.9.5}\protected@file@percent }
\newlabel{ROPE}{{9.5}{180}{The Bayesian ROPE procedure}{section.9.5}{}}
\citation{kruschke_doing_2014}
\citation{mcelreath_statistical_2016}
\citation{gosset_application_1904}
\@writefile{toc}{\contentsline {section}{\numberline {9.6}Which interval width should be used?}{182}{section.9.6}\protected@file@percent }
\newlabel{whichinterval}{{9.6}{182}{Which interval width should be used?}{section.9.6}{}}
\citation{king_point_2011}
\citation{popper_logic_2002}
\citation{ferguson_vast_2012}
\@writefile{toc}{\contentsline {section}{\numberline {9.7}Setting the Smallest Effect Size of Interest}{183}{section.9.7}\protected@file@percent }
\newlabel{sesoi}{{9.7}{183}{Setting the Smallest Effect Size of Interest}{section.9.7}{}}
\citation{burriss_changes_2015}
\citation{jaeschke_measurement_1989,norman_truly_2004,king_point_2011}
\citation{button_minimal_2015}
\citation{anvari_using_2021}
\@writefile{toc}{\contentsline {section}{\numberline {9.8}Specifying a SESOI based on theory}{184}{section.9.8}\protected@file@percent }
\newlabel{specifying-a-sesoi-based-on-theory}{{9.8}{184}{Specifying a SESOI based on theory}{section.9.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.9}Anchor based methods to set a SESOI}{184}{section.9.9}\protected@file@percent }
\newlabel{anchor-based-methods-to-set-a-sesoi}{{9.9}{184}{Anchor based methods to set a SESOI}{section.9.9}{}}
\citation{ball_effects_2002}
\citation{viamonte_cost-benefit_2006}
\citation{mrozek_what_2002}
\citation{abelson_value_2003}
\citation{anderson_theres_2016}
\@writefile{toc}{\contentsline {section}{\numberline {9.10}Specifying a SESOI based on a cost-benefit analysis}{185}{section.9.10}\protected@file@percent }
\newlabel{specifying-a-sesoi-based-on-a-cost-benefit-analysis}{{9.10}{185}{Specifying a SESOI based on a cost-benefit analysis}{section.9.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.11}Specifying the SESOI using the small telescopes approach}{185}{section.9.11}\protected@file@percent }
\newlabel{specifying-the-sesoi-using-the-small-telescopes-approach}{{9.11}{185}{Specifying the SESOI using the small telescopes approach}{section.9.11}{}}
\citation{simonsohn_small_2015}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces Screenshot illustrating a sensitivity power analysis in G*Power to compute the effect size an original study had 33\% power to detect.\relax }}{188}{figure.caption.93}\protected@file@percent }
\newlabel{fig:smalltelpower}{{9.6}{188}{Screenshot illustrating a sensitivity power analysis in G*Power to compute the effect size an original study had 33\% power to detect.\relax }{figure.caption.93}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces Example used in Simonsohn 2015 of an original study and two replication studies.\relax }}{189}{figure.caption.94}\protected@file@percent }
\newlabel{fig:simonsohnexample}{{9.7}{189}{Example used in Simonsohn 2015 of an original study and two replication studies.\relax }{figure.caption.94}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }}{190}{figure.caption.95}\protected@file@percent }
\newlabel{fig:distpowerplot1}{{9.8}{190}{Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }{figure.caption.95}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.12}Setting the Smallest Effect Size of Interest to the Minimal Statistically Detectable Effect}{190}{section.9.12}\protected@file@percent }
\newlabel{setting-the-smallest-effect-size-of-interest-to-the-minimal-statistically-detectable-effect}{{9.12}{190}{Setting the Smallest Effect Size of Interest to the Minimal Statistically Detectable Effect}{section.9.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }}{191}{figure.caption.96}\protected@file@percent }
\newlabel{fig:distpowerplot2}{{9.9}{191}{Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }{figure.caption.96}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.13}Test Yourself}{192}{section.9.13}\protected@file@percent }
\newlabel{test-yourself-7}{{9.13}{192}{Test Yourself}{section.9.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.1}Questions about equivalence tests}{192}{subsection.9.13.1}\protected@file@percent }
\newlabel{questions-about-equivalence-tests}{{9.13.1}{192}{Questions about equivalence tests}{subsection.9.13.1}{}}
\citation{hyde_gender_2008}
\gdef \LT@ii {\LT@entry 
    {2}{45.1pt}\LT@entry 
    {2}{71.66pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.2}Questions about the small telescopes approach}{196}{subsection.9.13.2}\protected@file@percent }
\newlabel{questions-about-the-small-telescopes-approach}{{9.13.2}{196}{Questions about the small telescopes approach}{subsection.9.13.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.3}Questions about specifying the SESOI as the Minimal Statistically Detectable Effect}{197}{subsection.9.13.3}\protected@file@percent }
\newlabel{questions-about-specifying-the-sesoi-as-the-minimal-statistically-detectable-effect}{{9.13.3}{197}{Questions about specifying the SESOI as the Minimal Statistically Detectable Effect}{subsection.9.13.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces Illustration of the criticial F-value for two groups, 50 observations per group, and an alpha level of 0.05.\relax }}{199}{figure.caption.97}\protected@file@percent }
\newlabel{fig:critf}{{9.10}{199}{Illustration of the criticial F-value for two groups, 50 observations per group, and an alpha level of 0.05.\relax }{figure.caption.97}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.4}Open Questions}{199}{subsection.9.13.4}\protected@file@percent }
\newlabel{open-questions-7}{{9.13.4}{199}{Open Questions}{subsection.9.13.4}{}}
\citation{wassmer_group_2016}
\citation{dodge_method_1929}
\citation{wald_sequential_1945}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Sequential Analysis}{200}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sequential}{{10}{200}{Sequential Analysis}{chapter.10}{}}
\citation{proschan_statistical_2006,jennison_group_2000,wassmer_group_2016}
\citation{pocock_group_1977}
\citation{armitage_repeated_1969}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Screenshot of the planned interim analyses examining the safety and Efficacy of the BNT162b2 mRNA Covid-19 Vaccine.\relax }}{201}{figure.caption.98}\protected@file@percent }
\newlabel{fig:interim}{{10.1}{201}{Screenshot of the planned interim analyses examining the safety and Efficacy of the BNT162b2 mRNA Covid-19 Vaccine.\relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Choosing alpha levels for sequential analyses.}{201}{section.10.1}\protected@file@percent }
\newlabel{choosing-alpha-levels-for-sequential-analyses.}{{10.1}{201}{Choosing alpha levels for sequential analyses}{section.10.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}The Pocock correction}{202}{section.10.2}\protected@file@percent }
\newlabel{the-pocock-correction}{{10.2}{202}{The Pocock correction}{section.10.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Comparing Spending Functions}{203}{section.10.3}\protected@file@percent }
\newlabel{comparing-spending-functions}{{10.3}{203}{Comparing Spending Functions}{section.10.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Plot of critical boundaries at each look for a 2 look design with a Pocock correction.\relax }}{204}{figure.caption.99}\protected@file@percent }
\newlabel{fig:boundplot1}{{10.2}{204}{Plot of critical boundaries at each look for a 2 look design with a Pocock correction.\relax }{figure.caption.99}{}}
\citation{proschan_statistical_2006}
\citation{lan_discrete_1983}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Screenshot of rpact Shiny app.\relax }}{205}{figure.caption.100}\protected@file@percent }
\newlabel{fig:rpactshiny}{{10.3}{205}{Screenshot of rpact Shiny app.\relax }{figure.caption.100}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Alpha spending functions}{205}{section.10.4}\protected@file@percent }
\newlabel{alpha-spending-functions}{{10.4}{205}{Alpha spending functions}{section.10.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Four different alpha spending functions (O'Brien-Fleming, Pocock, Haybittle-Peto, Wang-Tsiatis) for 3 looks.\relax }}{206}{figure.caption.101}\protected@file@percent }
\newlabel{fig:fourspendingfunctions}{{10.4}{206}{Four different alpha spending functions (O'Brien-Fleming, Pocock, Haybittle-Peto, Wang-Tsiatis) for 3 looks.\relax }{figure.caption.101}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Updating boundaries during a study}{206}{section.10.5}\protected@file@percent }
\newlabel{updating-boundaries-during-a-study}{{10.5}{206}{Updating boundaries during a study}{section.10.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces Comparison of Pocock and O'Brien-Fleming correction, and Pocock-like and O'Brien-Fleming like alpha spending functions, for 5 looks.\relax }}{207}{figure.caption.102}\protected@file@percent }
\newlabel{fig:seq-comparison}{{10.5}{207}{Comparison of Pocock and O'Brien-Fleming correction, and Pocock-like and O'Brien-Fleming like alpha spending functions, for 5 looks.\relax }{figure.caption.102}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Sample Size for Sequential Designs}{209}{section.10.6}\protected@file@percent }
\newlabel{sample-size-for-sequential-designs}{{10.6}{209}{Sample Size for Sequential Designs}{section.10.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Power curve for a sequential design with 2 looks.\relax }}{213}{figure.caption.103}\protected@file@percent }
\newlabel{fig:powerseq}{{10.6}{213}{Power curve for a sequential design with 2 looks.\relax }{figure.caption.103}{}}
\citation{spiegelhalter_monitoring_1986}
\citation{wassmer_group_2016}
\@writefile{toc}{\contentsline {section}{\numberline {10.7}Stopping for futility}{214}{section.10.7}\protected@file@percent }
\newlabel{stopping-for-futility}{{10.7}{214}{Stopping for futility}{section.10.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) when the observed effect is in the opposite direction.\relax }}{215}{figure.caption.104}\protected@file@percent }
\newlabel{fig:futility1}{{10.7}{215}{Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) when the observed effect is in the opposite direction.\relax }{figure.caption.104}{}}
\citation{jennison_group_2000}
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) based on a Pocock-type beta-spending function.\relax }}{216}{figure.caption.105}\protected@file@percent }
\newlabel{fig:futility2}{{10.8}{216}{Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) based on a Pocock-type beta-spending function.\relax }{figure.caption.105}{}}
\citation{proschan_statistical_2006}
\citation{schonbrodt_sequential_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces Power curve for a sequential design with 2 looks with stopping for futility.\relax }}{217}{figure.caption.106}\protected@file@percent }
\newlabel{fig:powerseq2}{{10.9}{217}{Power curve for a sequential design with 2 looks with stopping for futility.\relax }{figure.caption.106}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.8}Reporting the results of a sequential analysis}{217}{section.10.8}\protected@file@percent }
\newlabel{reporting-the-results-of-a-sequential-analysis}{{10.8}{217}{Reporting the results of a sequential analysis}{section.10.8}{}}
\citation{cook_p-value_2002}
\citation{proschan_statistical_2006}
\citation{wassmer_group_2016}
\citation{dupont_sequential_1983}
\citation{lakens_why_2022}
\@writefile{toc}{\contentsline {section}{\numberline {10.9}Test Yourself}{220}{section.10.9}\protected@file@percent }
\newlabel{test-yourself-8}{{10.9}{220}{Test Yourself}{section.10.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.9.1}Open Questions}{223}{subsection.10.9.1}\protected@file@percent }
\newlabel{open-questions-8}{{10.9.1}{223}{Open Questions}{subsection.10.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces Example of O'Brien-Fleming-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) with a 5\% Type 1 and Type 2 error.\relax }}{224}{figure.caption.107}\protected@file@percent }
\newlabel{fig:futilityq13}{{10.10}{224}{Example of O'Brien-Fleming-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) with a 5\% Type 1 and Type 2 error.\relax }{figure.caption.107}{}}
\citation{cohen_earth_1994}
\citation{borenstein_introduction_2009}
\citation{viechtbauer_conducting_2010}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Meta-analysis}{225}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{meta}{{11}{225}{Meta-analysis}{chapter.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Random Variation}{225}{section.11.1}\protected@file@percent }
\newlabel{random-variation}{{11.1}{225}{Random Variation}{section.11.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Simulation of 10 random datapoints with mean = 100 and sd = 15 in the population.\relax }}{226}{figure.caption.108}\protected@file@percent }
\newlabel{fig:plot-hist-iq-1}{{11.1}{226}{Simulation of 10 random datapoints with mean = 100 and sd = 15 in the population.\relax }{figure.caption.108}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces 100 random datapoints with mean = 100 and sd = 15 in the population.\relax }}{228}{figure.caption.109}\protected@file@percent }
\newlabel{fig:plot-hist-iq-2}{{11.2}{228}{100 random datapoints with mean = 100 and sd = 15 in the population.\relax }{figure.caption.109}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces 1000 random datapoints with mean = 100 and sd = 15 in the population.\relax }}{228}{figure.caption.110}\protected@file@percent }
\newlabel{fig:plot-hist-iq-3}{{11.3}{228}{1000 random datapoints with mean = 100 and sd = 15 in the population.\relax }{figure.caption.110}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.4}{\ignorespaces Simulation of 10 observations in two independent groups.\relax }}{229}{figure.caption.111}\protected@file@percent }
\newlabel{fig:plot-group1}{{11.4}{229}{Simulation of 10 observations in two independent groups.\relax }{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.5}{\ignorespaces Four simulated samples of independent groups.\relax }}{230}{figure.caption.112}\protected@file@percent }
\newlabel{fig:plot-group2}{{11.5}{230}{Four simulated samples of independent groups.\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.6}{\ignorespaces Simulated sample of 250 independent observations\relax }}{230}{figure.caption.113}\protected@file@percent }
\newlabel{fig:plotgroup3}{{11.6}{230}{Simulated sample of 250 independent observations\relax }{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.7}{\ignorespaces Correlation based on 30 pairs.\relax }}{231}{figure.caption.114}\protected@file@percent }
\newlabel{fig:plot-cor1}{{11.7}{231}{Correlation based on 30 pairs.\relax }{figure.caption.114}{}}
\citation{maxwell_sample_2008}
\@writefile{lof}{\contentsline {figure}{\numberline {11.8}{\ignorespaces Correlation based on 300 pairs.\relax }}{232}{figure.caption.115}\protected@file@percent }
\newlabel{fig:plot-cor2}{{11.8}{232}{Correlation based on 300 pairs.\relax }{figure.caption.115}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}Introduction to Meta-Analysis}{232}{section.11.2}\protected@file@percent }
\newlabel{introduction-to-meta-analysis}{{11.2}{232}{Introduction to Meta-Analysis}{section.11.2}{}}
\citation{borenstein_introduction_2009}
\citation{viechtbauer_conducting_2010}
\citation{borenstein_introduction_2009}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}A single study meta-analysis}{233}{section.11.3}\protected@file@percent }
\newlabel{a-single-study-meta-analysis}{{11.3}{233}{A single study meta-analysis}{section.11.3}{}}
\citation{buchanan_mote_2017}
\citation{cooper_handbook_2009}
\citation{freiman_importance_1978}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Simulating meta-analyses of mean standardized differences}{235}{section.11.4}\protected@file@percent }
\newlabel{simulating-meta-analyses-of-mean-standardized-differences}{{11.4}{235}{Simulating meta-analyses of mean standardized differences}{section.11.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.9}{\ignorespaces First version of a forest plot by Freiman and colleagues, 1978 (image from \url  {https://www.jameslindlibrary.org/freiman-ja-chalmers-tc-smith-h-kuebler-rr-1978/})\relax }}{236}{figure.caption.116}\protected@file@percent }
\newlabel{fig:freiman1978}{{11.9}{236}{First version of a forest plot by Freiman and colleagues, 1978 (image from \url {https://www.jameslindlibrary.org/freiman-ja-chalmers-tc-smith-h-kuebler-rr-1978/})\relax }{figure.caption.116}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.10}{\ignorespaces Forest plot for a single study.\relax }}{237}{figure.caption.117}\protected@file@percent }
\newlabel{fig:metaforest}{{11.10}{237}{Forest plot for a single study.\relax }{figure.caption.117}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.11}{\ignorespaces Forest plot for 12 simulated studies.\relax }}{238}{figure.caption.118}\protected@file@percent }
\newlabel{fig:meta-sim}{{11.11}{238}{Forest plot for 12 simulated studies.\relax }{figure.caption.118}{}}
\citation{borenstein_introduction_2009}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Fixed Effect vs Random Effects}{239}{section.11.5}\protected@file@percent }
\newlabel{fixed-effect-vs-random-effects}{{11.5}{239}{Fixed Effect vs Random Effects}{section.11.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Simulating meta-analyses for dichotomous outcomes}{239}{section.11.6}\protected@file@percent }
\newlabel{simulating-meta-analyses-for-dichotomous-outcomes}{{11.6}{239}{Simulating meta-analyses for dichotomous outcomes}{section.11.6}{}}
\gdef \LT@iii {\LT@entry 
    {2}{63.79001pt}\LT@entry 
    {1}{42.32pt}\LT@entry 
    {1}{40.18001pt}\LT@entry 
    {2}{16.12999pt}}
\gdef \LT@iv {\LT@entry 
    {2}{63.79001pt}\LT@entry 
    {1}{42.32pt}\LT@entry 
    {1}{40.18001pt}\LT@entry 
    {2}{20.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Heterogeneity}{242}{section.11.7}\protected@file@percent }
\newlabel{heterogeneity}{{11.7}{242}{Heterogeneity}{section.11.7}{}}
\citation{huedo-medina_assessing_2006}
\citation{rucker_undue_2008}
\citation{harrer_doing_2021}
\citation{bryan_behavioural_2021}
\citation{kenny_unappreciated_2019}
\citation{olsson-collentine_heterogeneity_2020}
\citation{linden_heterogeneity_2021}
\citation{eysenck_exercise_1978}
\citation{goodyear-smith_analysis_2012,ferguson_comment_2014}
\@writefile{toc}{\contentsline {section}{\numberline {11.8}Strengths and weaknesses of meta-analysis}{245}{section.11.8}\protected@file@percent }
\newlabel{strengths-and-weaknesses-of-meta-analysis}{{11.8}{245}{Strengths and weaknesses of meta-analysis}{section.11.8}{}}
\citation{vosgerau_99_2019}
\citation{stewart_ipd_2002}
\citation{lawrence_lesson_2021}
\@writefile{toc}{\contentsline {section}{\numberline {11.9}Which results should you report to be included in a future meta-analysis?}{246}{section.11.9}\protected@file@percent }
\newlabel{which-results-should-you-report-to-be-included-in-a-future-meta-analysis}{{11.9}{246}{Which results should you report to be included in a future meta-analysis?}{section.11.9}{}}
\citation{lakens_reproducibility_2016}
\citation{polanin_transparency_2020}
\@writefile{toc}{\contentsline {section}{\numberline {11.10}Improving the reproducibility of meta-analyses}{247}{section.11.10}\protected@file@percent }
\newlabel{metareporting}{{11.10}{247}{Improving the reproducibility of meta-analyses}{section.11.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.11}Test Yourself}{247}{section.11.11}\protected@file@percent }
\newlabel{test-yourself-9}{{11.11}{247}{Test Yourself}{section.11.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11.3}{\ignorespaces Six practical recommendations to improve the quality and reproducibility of meta-analyses.\relax }}{248}{table.caption.119}\protected@file@percent }
\newlabel{tab:table-rec1}{{11.3}{248}{Six practical recommendations to improve the quality and reproducibility of meta-analyses.\relax }{table.caption.119}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.12}{\ignorespaces Simulated studies under a random effects model\relax }}{250}{figure.caption.120}\protected@file@percent }
\newlabel{fig:meta-sim-rand}{{11.12}{250}{Simulated studies under a random effects model\relax }{figure.caption.120}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.13}{\ignorespaces Simulated studies under a fixed effect model\relax }}{250}{figure.caption.121}\protected@file@percent }
\newlabel{fig:meta-sim-fixed}{{11.13}{250}{Simulated studies under a fixed effect model\relax }{figure.caption.121}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.11.1}Open Questions}{251}{subsection.11.11.1}\protected@file@percent }
\newlabel{open-questions-9}{{11.11.1}{251}{Open Questions}{subsection.11.11.1}{}}
\citation{mayo_statistical_2018}
\citation{rogers_how_1992}
\citation{fanelli_how_2009}
\citation{nuijten_prevalence_2015}
\citation{bishop_fallibility_2018}
\citation{brown_grim_2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Bias detection}{252}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{bias}{{12}{252}{Bias detection}{chapter.12}{}}
\citation{greenwald_consequences_1975}
\citation{chambers_past_2022,nosek_registered_2014}
\citation{scheel_excess_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Scene in The Dropout about the company Theranos that falsely claimed to have devices that could perform blood tests on very small amounts of blood. In the scene, two whistelblowers confront their bosses when they are pressured to remove datapoints that do not show the desired results.\relax }}{253}{figure.caption.122}\protected@file@percent }
\newlabel{fig:outliers}{{12.1}{253}{Scene in The Dropout about the company Theranos that falsely claimed to have devices that could perform blood tests on very small amounts of blood. In the scene, two whistelblowers confront their bosses when they are pressured to remove datapoints that do not show the desired results.\relax }{figure.caption.122}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Publication bias}{253}{section.12.1}\protected@file@percent }
\newlabel{publication-bias}{{12.1}{253}{Publication bias}{section.12.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces Screenshot of the table reporting the main results from Festinger and Carlsmith, 1959\relax }}{254}{figure.caption.123}\protected@file@percent }
\newlabel{fig:festinger}{{12.2}{254}{Screenshot of the table reporting the main results from Festinger and Carlsmith, 1959\relax }{figure.caption.123}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces Screenshot of the final sentences of Greenwald, A. G. (1975). Consequences of prejudice against the null hypothesis. Psychological Bulletin, 82(1), 1--20.\relax }}{254}{figure.caption.124}\protected@file@percent }
\newlabel{fig:greenwald}{{12.3}{254}{Screenshot of the final sentences of Greenwald, A. G. (1975). Consequences of prejudice against the null hypothesis. Psychological Bulletin, 82(1), 1--20.\relax }{figure.caption.124}{}}
\citation{franco_publication_2014,greenwald_consequences_1975,sterling_publication_1959}
\citation{polanin_transparency_2020}
\citation{ropovik_neglect_2021}
\citation{carter_correcting_2019}
\citation{francis_frequency_2014,schimmack_ironic_2012}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces Positive result rates for standard reports and Registered Reports. Error bars indicate 95\% confidence intervals around the observed positive result rate.\relax }}{255}{figure.caption.125}\protected@file@percent }
\newlabel{fig:scheel}{{12.4}{255}{Positive result rates for standard reports and Registered Reports. Error bars indicate 95\% confidence intervals around the observed positive result rate.\relax }{figure.caption.125}{}}
\citation{francis_frequency_2014}
\citation{ioannidis_exploratory_2007}
\citation{jostmann_weight_2009}
\citation{ebersole_many_2016}
\citation{jostmann_short_2016}
\citation{becker_failsafe_2005}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Bias detection in meta-analysis}{256}{section.12.2}\protected@file@percent }
\newlabel{bias-detection-in-meta-analysis}{{12.2}{256}{Bias detection in meta-analysis}{section.12.2}{}}
\citation{scheel_excess_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces Funnel plot of unbiased null results.\relax }}{259}{figure.caption.126}\protected@file@percent }
\newlabel{fig:funnel1}{{12.5}{259}{Funnel plot of unbiased null results.\relax }{figure.caption.126}{}}
\citation{carter_publication_2014}
\citation{hagger_multilab_2016}
\citation{vohs_multisite_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {12.6}{\ignorespaces Funnel plot of biased null results with mostly significant results.\relax }}{261}{figure.caption.127}\protected@file@percent }
\newlabel{fig:funnel2}{{12.6}{261}{Funnel plot of biased null results with mostly significant results.\relax }{figure.caption.127}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.7}{\ignorespaces Funnel plot from Carter and McCullough (2014) vizualizing bias in 198 published tests of the ego-depletion effect.\relax }}{261}{figure.caption.128}\protected@file@percent }
\newlabel{fig:carterbias}{{12.7}{261}{Funnel plot from Carter and McCullough (2014) vizualizing bias in 198 published tests of the ego-depletion effect.\relax }{figure.caption.128}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.8}{\ignorespaces Forest plot of unbiased meta-analysis (left) and biased meta-analysies (right).\relax }}{262}{figure.caption.129}\protected@file@percent }
\newlabel{fig:twoforestplot}{{12.8}{262}{Forest plot of unbiased meta-analysis (left) and biased meta-analysies (right).\relax }{figure.caption.129}{}}
\citation{peters_performance_2007,terrin_adjusting_2003}
\@writefile{lof}{\contentsline {figure}{\numberline {12.9}{\ignorespaces Funnel plot with assumed missing effects added through trim-and-fill.\relax }}{263}{figure.caption.130}\protected@file@percent }
\newlabel{fig:trimfill1}{{12.9}{263}{Funnel plot with assumed missing effects added through trim-and-fill.\relax }{figure.caption.130}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Trim and Fill}{263}{section.12.3}\protected@file@percent }
\newlabel{trim-and-fill}{{12.3}{263}{Trim and Fill}{section.12.3}{}}
\citation{stanley_meta-regression_2014,stanley_finding_2017}
\citation{stanley_meta-regression_2014}
\citation{stanley_finding_2017}
\@writefile{toc}{\contentsline {section}{\numberline {12.4}PET-PEESE}{264}{section.12.4}\protected@file@percent }
\newlabel{pet-peese}{{12.4}{264}{PET-PEESE}{section.12.4}{}}
\citation{simonsohn_p-curve_2014}
\citation{aert_correcting_2018}
\citation{iyengar_selection_1988}
\@writefile{lof}{\contentsline {figure}{\numberline {12.10}{\ignorespaces Funnel plot with PETPEESE regression lines.\relax }}{265}{figure.caption.131}\protected@file@percent }
\newlabel{fig:petpeese}{{12.10}{265}{Funnel plot with PETPEESE regression lines.\relax }{figure.caption.131}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.5}\emph  {P}-value meta-analysis}{265}{section.12.5}\protected@file@percent }
\newlabel{p-value-meta-analysis}{{12.5}{265}{\texorpdfstring {\emph {P}-value meta-analysis}{P-value meta-analysis}}{section.12.5}{}}
\citation{simonsohn_p-curve_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {12.11}{\ignorespaces Figure 3 from Simonsohn et al (2014) showing a \emph  {p}-curve with and without bias.\relax }}{266}{figure.caption.132}\protected@file@percent }
\newlabel{fig:pcurve}{{12.11}{266}{Figure 3 from Simonsohn et al (2014) showing a \emph {p}-curve with and without bias.\relax }{figure.caption.132}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.12}{\ignorespaces Result of the \emph  {p}-curve analysis of the biased studies.\relax }}{268}{figure.caption.133}\protected@file@percent }
\newlabel{fig:pcurveresult}{{12.12}{268}{Result of the \emph {p}-curve analysis of the biased studies.\relax }{figure.caption.133}{}}
\citation{bartos_z-curve20_2020,brunner_estimating_2020}
\citation{sotola_garbage_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {12.13}{\ignorespaces \emph  {Z}-curve analysis for 1000 studies with a true effect size of 0 without publication bias.\relax }}{269}{figure.caption.134}\protected@file@percent }
\newlabel{fig:zcurveunbiasednull}{{12.13}{269}{\emph {Z}-curve analysis for 1000 studies with a true effect size of 0 without publication bias.\relax }{figure.caption.134}{}}
\citation{bartos_z-curve20_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {12.14}{\ignorespaces \emph  {Z}-curve analysis for 1000 studies with a true effect size of \emph  {d} = 0.37 and \emph  {n} = 100 per condition in an independent \emph  {t}-test without publication bias.\relax }}{270}{figure.caption.135}\protected@file@percent }
\newlabel{fig:zcurveunbiasedalternative}{{12.14}{270}{\emph {Z}-curve analysis for 1000 studies with a true effect size of \emph {d} = 0.37 and \emph {n} = 100 per condition in an independent \emph {t}-test without publication bias.\relax }{figure.caption.135}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Conclusion}{272}{section.12.6}\protected@file@percent }
\newlabel{conclusion}{{12.6}{272}{Conclusion}{section.12.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.7}Test Yourself}{272}{section.12.7}\protected@file@percent }
\newlabel{test-yourself-10}{{12.7}{272}{Test Yourself}{section.12.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.15}{\ignorespaces Funnel plot with PETPEESE regression lines for the same studies as in Q2.\relax }}{274}{figure.caption.136}\protected@file@percent }
\newlabel{fig:petpeeseq4}{{12.15}{274}{Funnel plot with PETPEESE regression lines for the same studies as in Q2.\relax }{figure.caption.136}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.16}{\ignorespaces Result of the p-curve analysis of the biased studies in Q2.\relax }}{275}{figure.caption.137}\protected@file@percent }
\newlabel{fig:pcurveresultq5}{{12.16}{275}{Result of the p-curve analysis of the biased studies in Q2.\relax }{figure.caption.137}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.7.1}Open Questions}{277}{subsection.12.7.1}\protected@file@percent }
\newlabel{open-questions-10}{{12.7.1}{277}{Open Questions}{subsection.12.7.1}{}}
\citation{babbage_reflections_1830}
\citation{bem_feeling_2011}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Preregistration and Transparency}{278}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{prereg}{{13}{278}{Preregistration and Transparency}{chapter.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces Excerpt from Babbage, 1830.\relax }}{278}{figure.caption.138}\protected@file@percent }
\newlabel{fig:babbage}{{13.1}{278}{Excerpt from Babbage, 1830.\relax }{figure.caption.138}{}}
\citation{kerr_harking_1998}
\citation{bakan_test_1966}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces Screenshot from the Results and Discussion section of Bem, 2011.\relax }}{279}{figure.caption.139}\protected@file@percent }
\newlabel{fig:bem}{{13.2}{279}{Screenshot from the Results and Discussion section of Bem, 2011.\relax }{figure.caption.139}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}The value of preregistration}{279}{section.13.1}\protected@file@percent }
\newlabel{the-value-of-preregistration}{{13.1}{279}{The value of preregistration}{section.13.1}{}}
\citation{de_groot_methodology_1969}
\citation{lakens_value_2019}
\citation{lakens_value_2019}
\citation{van_t_veer_pre-registration_2016}
\citation{wicherts_degrees_2016}
\citation{appelbaum_journal_2018}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}How to preregister}{281}{section.13.2}\protected@file@percent }
\newlabel{how-to-preregister}{{13.2}{281}{How to preregister}{section.13.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces Screenshot Table 1, summarizing the checklist for preregistrations by Wicherts et al., 2016.\relax }}{282}{figure.caption.140}\protected@file@percent }
\newlabel{fig:preregcheclist}{{13.3}{282}{Screenshot Table 1, summarizing the checklist for preregistrations by Wicherts et al., 2016.\relax }{figure.caption.140}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Journal Article Reporting Standards}{282}{section.13.3}\protected@file@percent }
\newlabel{journal-article-reporting-standards}{{13.3}{282}{Journal Article Reporting Standards}{section.13.3}{}}
\citation{leys_how_2019}
\citation{cooper_reporting_2020}
\@writefile{toc}{\contentsline {section}{\numberline {13.4}What Does a Formalized Test of a Prediction Look Like?}{284}{section.13.4}\protected@file@percent }
\newlabel{what-does-a-formalized-test-of-a-prediction-look-like}{{13.4}{284}{What Does a Formalized Test of a Prediction Look Like?}{section.13.4}{}}
\citation{lakens_improving_2020}
\citation{uygun_tunc_falsificationist_2022}
\@writefile{toc}{\contentsline {section}{\numberline {13.5}Are you ready to preregister a hypothesis test?}{285}{section.13.5}\protected@file@percent }
\newlabel{are-you-ready-to-preregister-a-hypothesis-test}{{13.5}{285}{Are you ready to preregister a hypothesis test?}{section.13.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces Screenshot of a IMDB and metacritic rating.\relax }}{286}{figure.caption.141}\protected@file@percent }
\newlabel{fig:imdbrating}{{13.4}{286}{Screenshot of a IMDB and metacritic rating.\relax }{figure.caption.141}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.6}Test Yourself}{286}{section.13.6}\protected@file@percent }
\newlabel{test-yourself-11}{{13.6}{286}{Test Yourself}{section.13.6}{}}
\citation{wicherts_degrees_2016}
\@writefile{toc}{\contentsline {section}{\numberline {13.7}Pre-registering on AsPredicted}{288}{section.13.7}\protected@file@percent }
\newlabel{pre-registering-on-aspredicted}{{13.7}{288}{Pre-registering on AsPredicted}{section.13.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.8}Pre-registering on the Open Science Framework}{290}{section.13.8}\protected@file@percent }
\newlabel{pre-registering-on-the-open-science-framework}{{13.8}{290}{Pre-registering on the Open Science Framework}{section.13.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.9}Collecting Data}{292}{section.13.9}\protected@file@percent }
\newlabel{collecting-data}{{13.9}{292}{Collecting Data}{section.13.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.10}Analyzing the data}{293}{section.13.10}\protected@file@percent }
\newlabel{analyzing-the-data}{{13.10}{293}{Analyzing the data}{section.13.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.11}Sharing the report, data, and code}{293}{section.13.11}\protected@file@percent }
\newlabel{sharing-the-report-data-and-code}{{13.11}{293}{Sharing the report, data, and code}{section.13.11}{}}
\citation{spellman_short_2015}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Computational Reproducibility}{299}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{computationalreproducibility}{{14}{299}{Computational Reproducibility}{chapter.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Step 1: Setting up a GitHub repository}{300}{section.14.1}\protected@file@percent }
\newlabel{step-1-setting-up-a-github-repository}{{14.1}{300}{Step 1: Setting up a GitHub repository}{section.14.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Step 2: Cloning your GitHub repository into RStudio}{302}{section.14.2}\protected@file@percent }
\newlabel{step-2-cloning-your-github-repository-into-rstudio}{{14.2}{302}{Step 2: Cloning your GitHub repository into RStudio}{section.14.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Step 3: Creating an R Markdown file}{309}{section.14.3}\protected@file@percent }
\newlabel{step-3-creating-an-r-markdown-file}{{14.3}{309}{Step 3: Creating an R Markdown file}{section.14.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Step 4: Reproducible Data Analysis in R Studio}{313}{section.14.4}\protected@file@percent }
\newlabel{step-4-reproducible-data-analysis-in-r-studio}{{14.4}{313}{Step 4: Reproducible Data Analysis in R Studio}{section.14.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Step 5: Committing and Pushing to GitHub}{317}{section.14.5}\protected@file@percent }
\newlabel{step-5-committing-and-pushing-to-github}{{14.5}{317}{Step 5: Committing and Pushing to GitHub}{section.14.5}{}}
\citation{vuorre_curating_2018}
\@writefile{toc}{\contentsline {section}{\numberline {14.6}Step 6: Reproducible Data Analysis}{321}{section.14.6}\protected@file@percent }
\newlabel{step-6-reproducible-data-analysis}{{14.6}{321}{Step 6: Reproducible Data Analysis}{section.14.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.1}Extra: APA formatted manuscripts in papaja}{326}{subsection.14.6.1}\protected@file@percent }
\newlabel{extra-apa-formatted-manuscripts-in-papaja}{{14.6.1}{326}{Extra: APA formatted manuscripts in papaja}{subsection.14.6.1}{}}
\citation{arslan_how_2019}
\@writefile{toc}{\contentsline {section}{\numberline {14.7}Step 7: Organizing Your Data and Code}{328}{section.14.7}\protected@file@percent }
\newlabel{step-7-organizing-your-data-and-code}{{14.7}{328}{Step 7: Organizing Your Data and Code}{section.14.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.8}Step 8: Archiving Your Data and Code}{328}{section.14.8}\protected@file@percent }
\newlabel{step-8-archiving-your-data-and-code}{{14.8}{328}{Step 8: Archiving Your Data and Code}{section.14.8}{}}
\citation{wiebels_leveraging_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.8.1}EXTRA: Sharing Reproducible Code on Code Ocean}{333}{subsection.14.8.1}\protected@file@percent }
\newlabel{extra-sharing-reproducible-code-on-code-ocean}{{14.8.1}{333}{EXTRA: Sharing Reproducible Code on Code Ocean}{subsection.14.8.1}{}}
\citation{obels_analysis_2020}
\bibdata{include/book.bib,include/packages.bib}
\@writefile{toc}{\contentsline {section}{\numberline {14.9}Some points for improvement in computational reproducibility}{338}{section.14.9}\protected@file@percent }
\newlabel{some-points-for-improvement-in-computational-reproducibility}{{14.9}{338}{Some points for improvement in computational reproducibility}{section.14.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.10}Conclusion}{338}{section.14.10}\protected@file@percent }
\newlabel{conclusion-1}{{14.10}{338}{Conclusion}{section.14.10}{}}
\bibcite{abelson_value_2003}{{1}{2003}{{Abelson}}{{}}}
\bibcite{aberson_applied_2019}{{2}{2019}{{Aberson}}{{}}}
\bibcite{albers_credible_2018}{{3}{2018}{{Albers et~al.}}{{}}}
\bibcite{albers_when_2018}{{4}{2018}{{Albers and Lakens}}{{}}}
\bibcite{aldrich_r_1997}{{5}{1997}{{Aldrich}}{{}}}
\bibcite{allison_power_1997}{{6}{1997}{{Allison et~al.}}{{}}}
\bibcite{altman_statistics_1995}{{7}{1995}{{Altman and Bland}}{{}}}
\bibcite{anderson_sample-size_2017}{{8}{2017}{{Anderson et~al.}}{{}}}
\bibcite{anderson_theres_2016}{{9}{2016}{{Anderson and Maxwell}}{{}}}
\bibcite{anvari_not_2021}{{10}{2021}{{Anvari et~al.}}{{}}}
\bibcite{anvari_using_2021}{{11}{2021}{{Anvari and Lakens}}{{}}}
\bibcite{appelbaum_journal_2018}{{12}{2018}{{Appelbaum et~al.}}{{}}}
\bibcite{armitage_repeated_1969}{{13}{1969}{{Armitage et~al.}}{{}}}
\bibcite{arslan_how_2019}{{14}{2019}{{Arslan}}{{}}}
\bibcite{babbage_reflections_1830}{{15}{1830}{{Babbage}}{{}}}
\bibcite{bacchetti_current_2010}{{16}{2010}{{Bacchetti}}{{}}}
\bibcite{baguley_understanding_2004}{{17}{2004}{{Baguley}}{{}}}
\bibcite{baguley_standardized_2009}{{18}{2009}{{Baguley}}{{}}}
\@writefile{toc}{\contentsline {fm}{Bibliography}{339}{chapter*.142}\protected@file@percent }
\bibcite{baguley_serious_2012}{{19}{2012}{{Baguley}}{{}}}
\bibcite{bakan_test_1966}{{20}{1966}{{Bakan}}{{}}}
\bibcite{ball_effects_2002}{{21}{2002}{{Ball et~al.}}{{}}}
\bibcite{barber_pitfalls_1976}{{22}{1976}{{Barber}}{{}}}
\bibcite{bartos_z-curve20_2020}{{23}{2020}{{Barto{\v s} and Schimmack}}{{}}}
\bibcite{bauer_unifying_1996}{{24}{1996}{{Bauer and Kieser}}{{}}}
\bibcite{bausell_power_2002}{{25}{2002}{{Bausell and Li}}{{}}}
\bibcite{becker_failsafe_2005}{{26}{2005}{{Becker}}{{}}}
\bibcite{bem_feeling_2011}{{27}{2011}{{Bem}}{{}}}
\bibcite{ben-shachar_effectsize_2020}{{28}{2020}{{{Ben-Shachar} et~al.}}{{}}}
\bibcite{bender_adjusting_2001}{{29}{2001}{{Bender and Lange}}{{}}}
\bibcite{benjamini_its_2016}{{30}{2016}{{Benjamini}}{{}}}
\bibcite{benjamini_controlling_1995}{{31}{1995}{{Benjamini and Hochberg}}{{}}}
\bibcite{berger_interplay_2004}{{32}{2004}{{Berger and Bayarri}}{{}}}
\bibcite{berkeley_defence_1735}{{33}{1735}{{Berkeley}}{{}}}
\bibcite{bishop_fallibility_2018}{{34}{2018}{{Bishop}}{{}}}
\bibcite{bland_introduction_2015}{{35}{2015}{{Bland}}{{}}}
\bibcite{borenstein_introduction_2009}{{36}{2009}{{Borenstein}}{{}}}
\bibcite{bosco_correlational_2015}{{37}{2015}{{Bosco et~al.}}{{}}}
\bibcite{bretz_multiple_2011}{{38}{2011}{{Bretz et~al.}}{{}}}
\bibcite{brown_errors_1983}{{39}{1983}{{Brown}}{{}}}
\bibcite{brown_grim_2017}{{40}{2017}{{Brown and Heathers}}{{}}}
\bibcite{brunner_estimating_2020}{{41}{2020}{{Brunner and Schimmack}}{{}}}
\bibcite{bryan_behavioural_2021}{{42}{2021}{{Bryan et~al.}}{{}}}
\bibcite{brysbaert_how_2019}{{43}{2019}{{Brysbaert}}{{}}}
\bibcite{brysbaert_power_2018}{{44}{2018}{{Brysbaert and Stevens}}{{}}}
\bibcite{buchanan_mote_2017}{{45}{2017}{{Buchanan et~al.}}{{}}}
\bibcite{bulus_bound_2021}{{46}{2021}{{Bulus and Dong}}{{}}}
\bibcite{burriss_changes_2015}{{47}{2015}{{Burriss et~al.}}{{}}}
\bibcite{button_power_2013}{{48}{2013}{{Button et~al.}}{{}}}
\bibcite{button_minimal_2015}{{49}{2015}{{Button et~al.}}{{}}}
\bibcite{carter_publication_2014}{{50}{2014}{{Carter and McCullough}}{{}}}
\bibcite{carter_correcting_2019}{{51}{2019}{{Carter et~al.}}{{}}}
\bibcite{cascio_open_1983}{{52}{1983}{{Cascio and Zedeck}}{{}}}
\bibcite{chambers_past_2022}{{53}{2022}{{Chambers and Tzavella}}{{}}}
\bibcite{chang_adaptive_2016}{{54}{2016}{{Chang}}{{}}}
\bibcite{chatziathanasiou_beware_2022}{{55}{2022}{{Chatziathanasiou}}{{}}}
\bibcite{chin_questionable_2021}{{56}{2021}{{Chin et~al.}}{{}}}
\bibcite{cho_is_2013}{{57}{2013}{{Cho and Abe}}{{}}}
\bibcite{cohen_statistical_1988}{{58}{1988}{{Cohen}}{{}}}
\bibcite{cohen_things_1990}{{59}{1990}{{Cohen}}{{}}}
\bibcite{cohen_earth_1994}{{60}{1994}{{Cohen}}{{}}}
\bibcite{colling_registered_2020}{{61}{2020}{{Colling et~al.}}{{}}}
\bibcite{colquhoun_false_2019}{{62}{2019}{{Colquhoun}}{{}}}
\bibcite{cook_assessing_2014}{{63}{2014}{{Cook et~al.}}{{}}}
\bibcite{cook_p-value_2002}{{64}{2002}{{Cook}}{{}}}
\bibcite{cooper_reporting_2020}{{65}{2020}{{Cooper}}{{}}}
\bibcite{cooper_handbook_2009}{{66}{2009}{{Cooper et~al.}}{{}}}
\bibcite{copay_understanding_2007}{{67}{2007}{{Copay et~al.}}{{}}}
\bibcite{correll_avoid_2020}{{68}{2020}{{Correll et~al.}}{{}}}
\bibcite{cousineau_superb_2019}{{69}{2019}{{Cousineau and Chiasson}}{{}}}
\bibcite{cowles_origins_1982}{{70}{1982}{{Cowles and Davis}}{{}}}
\bibcite{cox_problems_1958}{{71}{1958}{{Cox}}{{}}}
\bibcite{cribbie_recommendations_2004}{{72}{2004}{{Cribbie et~al.}}{{}}}
\bibcite{cumming_replication_2008}{{73}{2008}{{Cumming}}{{}}}
\bibcite{cumming_understanding_2013}{{74}{2013}{{Cumming}}{{}}}
\bibcite{cumming_new_2014}{{75}{2014}{{Cumming}}{{}}}
\bibcite{cumming_introduction_2016}{{76}{2016}{{Cumming and {Calin-Jageman}}}{{}}}
\bibcite{cumming_confidence_2006}{{77}{2006}{{Cumming and Maillardet}}{{}}}
\bibcite{danziger_extraneous_2011}{{78}{2011}{{Danziger et~al.}}{{}}}
\bibcite{de_groot_methodology_1969}{{79}{1969}{{de Groot}}{{}}}
\bibcite{debruine_understanding_2021}{{80}{2021}{{DeBruine and Barr}}{{}}}
\bibcite{delacre_why_2021}{{81}{2021}{{Delacre et~al.}}{{}}}
\bibcite{delacre_why_2017}{{82}{2017}{{Delacre et~al.}}{{}}}
\bibcite{detsky_using_1990}{{83}{1990}{{Detsky}}{{}}}
\bibcite{dienes_understanding_2008}{{84}{2008}{{Dienes}}{{}}}
\bibcite{dienes_using_2014}{{85}{2014}{{Dienes}}{{}}}
\bibcite{dmitrienko_traditional_2013}{{86}{2013}{{Dmitrienko and D'Agostino~Sr}}{{}}}
\bibcite{dodge_method_1929}{{87}{1929}{{Dodge and Romig}}{{}}}
\bibcite{dubin_theory_1969}{{88}{1969}{{Dubin}}{{}}}
\bibcite{dunn_multiple_1961}{{89}{1961}{{Dunn}}{{}}}
\bibcite{dupont_sequential_1983}{{90}{1983}{{Dupont}}{{}}}
\bibcite{ebersole_many_2016}{{91}{2016}{{Ebersole et~al.}}{{}}}
\bibcite{eckermann_value_2010}{{92}{2010}{{Eckermann et~al.}}{{}}}
\bibcite{elson_press_2014}{{93}{2014}{{Elson et~al.}}{{}}}
\bibcite{erdfelder_gpower_1996}{{94}{1996}{{Erdfelder et~al.}}{{}}}
\bibcite{eysenck_exercise_1978}{{95}{1978}{{Eysenck}}{{}}}
\bibcite{fanelli_how_2009}{{96}{2009}{{Fanelli}}{{}}}
\bibcite{fanelli_positive_2010}{{97}{2010}{{Fanelli}}{{}}}
\bibcite{faul_gpower_2007}{{98}{2007}{{Faul et~al.}}{{}}}
\bibcite{ferguson_comment_2014}{{99}{2014}{{Ferguson}}{{}}}
\bibcite{ferguson_vast_2012}{{100}{2012}{{Ferguson and Heene}}{{}}}
\bibcite{ferguson_providing_2021}{{101}{2021}{{Ferguson and Heene}}{{}}}
\bibcite{ferron_power_1996}{{102}{1996}{{Ferron and Onghena}}{{}}}
\bibcite{fiedler_tools_2004}{{103}{2004}{{Fiedler}}{{}}}
\bibcite{fiedler_questionable_2015}{{104}{2015}{{Fiedler and Schwarz}}{{}}}
\bibcite{field_minimizing_2004}{{105}{2004}{{Field et~al.}}{{}}}
\bibcite{fisher_design_1935}{{106}{1935}{{Fisher}}{{}}}
\bibcite{fisher_statistical_1956}{{107}{1956}{{Fisher}}{{}}}
\bibcite{fraley_n-pact_2014}{{108}{2014}{{Fraley and Vazire}}{{}}}
\bibcite{francis_frequency_2014}{{109}{2014}{{Francis}}{{}}}
\bibcite{franco_publication_2014}{{110}{2014}{{Franco et~al.}}{{}}}
\bibcite{freiman_importance_1978}{{111}{1978}{{Freiman et~al.}}{{}}}
\bibcite{frick_appropriate_1996}{{112}{1996}{{Frick}}{{}}}
\bibcite{fricker_assessing_2019}{{113}{2019}{{Fricker et~al.}}{{}}}
\bibcite{fried_method_1993}{{114}{1993}{{Fried et~al.}}{{}}}
\bibcite{friede_sample_2006}{{115}{2006}{{Friede and Kieser}}{{}}}
\bibcite{fugard_supporting_2015}{{116}{2015}{{Fugard and Potts}}{{}}}
\bibcite{funder_evaluating_2019}{{117}{2019}{{Funder and Ozer}}{{}}}
\bibcite{gerring_mere_2012}{{118}{2012}{{Gerring}}{{}}}
\bibcite{glockner_irrational_2016}{{119}{2016}{{Gl{\"o}ckner}}{{}}}
\bibcite{glover_likelihood_2004}{{120}{2004}{{Glover and Dixon}}{{}}}
\bibcite{good_bayesnon-bayes_1992}{{121}{1992}{{Good}}{{}}}
\bibcite{goodyear-smith_analysis_2012}{{122}{2012}{{{Goodyear-Smith} et~al.}}{{}}}
\bibcite{gosset_application_1904}{{123}{1904}{{Gosset}}{{}}}
\bibcite{gotz_small_2022}{{124}{2022}{{G{\"o}tz et~al.}}{{}}}
\bibcite{green_simr_2016}{{125}{2016}{{Green and MacLeod}}{{}}}
\bibcite{green_how_1991}{{126}{1991}{{Green}}{{}}}
\bibcite{greenland_statistical_2016}{{127}{2016}{{Greenland et~al.}}{{}}}
\bibcite{greenwald_consequences_1975}{{128}{1975}{{Greenwald}}{{}}}
\bibcite{grunwald_safe_2019}{{129}{2019}{{Gr{\"u}nwald et~al.}}{{}}}
\bibcite{gupta_intention_2011}{{130}{2011}{{Gupta}}{{}}}
\bibcite{hacking_logic_1965}{{131}{1965}{{Hacking}}{{}}}
\bibcite{hagger_multilab_2016}{{132}{2016}{{Hagger et~al.}}{{}}}
\bibcite{hallahan_statistical_1996}{{133}{1996}{{Hallahan and Rosenthal}}{{}}}
\bibcite{halpern_sample_2001}{{134}{2001}{{Halpern et~al.}}{{}}}
\bibcite{halpern_continuing_2002}{{135}{2002}{{Halpern et~al.}}{{}}}
\bibcite{hand_deconstructing_1994}{{136}{1994}{{Hand}}{{}}}
\bibcite{harms_making_2018}{{137}{2018}{{Harms and Lakens}}{{}}}
\bibcite{harrer_doing_2021}{{138}{2021}{{Harrer et~al.}}{{}}}
\bibcite{hauck_new_1984}{{139}{1984}{{Hauck and Anderson}}{{}}}
\bibcite{hedges_power_2001}{{140}{2001}{{Hedges and Pigott}}{{}}}
\bibcite{hilgard_maximal_2021}{{141}{2021}{{Hilgard}}{{}}}
\bibcite{hill_empirical_2008}{{142}{2008}{{Hill et~al.}}{{}}}
\bibcite{hodges_testing_1954}{{143}{1954}{{Hodges and Lehmann}}{{}}}
\bibcite{hoenig_abuse_2001}{{144}{2001}{{Hoenig and Heisey}}{{}}}
\bibcite{huedo-medina_assessing_2006}{{145}{2006}{{{Huedo-Medina} et~al.}}{{}}}
\bibcite{hung_behavior_1997}{{146}{1997}{{Hung et~al.}}{{}}}
\bibcite{hyde_gender_2008}{{147}{2008}{{Hyde et~al.}}{{}}}
\bibcite{ioannidis_why_2005}{{148}{2005}{{Ioannidis}}{{}}}
\bibcite{ioannidis_exploratory_2007}{{149}{2007}{{Ioannidis and Trikalinos}}{{}}}
\bibcite{iyengar_selection_1988}{{150}{1988}{{Iyengar and Greenhouse}}{{}}}
\bibcite{jaeschke_measurement_1989}{{151}{1989}{{Jaeschke et~al.}}{{}}}
\bibcite{jeffreys_theory_1939}{{152}{1939}{{Jeffreys}}{{}}}
\bibcite{jennison_group_2000}{{153}{2000}{{Jennison and Turnbull}}{{}}}
\bibcite{john_measuring_2012}{{154}{2012}{{John et~al.}}{{}}}
\bibcite{johnson_revised_2013}{{155}{2013}{{Johnson}}{{}}}
\bibcite{jones_test_1952}{{156}{1952}{{Jones}}{{}}}
\bibcite{jostmann_weight_2009}{{157}{2009}{{Jostmann et~al.}}{{}}}
\bibcite{jostmann_short_2016}{{158}{2016}{{Jostmann et~al.}}{{}}}
\bibcite{julious_sample_2004}{{159}{2004}{{Julious}}{{}}}
\bibcite{kass_bayes_1995}{{160}{1995}{{Kass and Raftery}}{{}}}
\bibcite{keefe_defining_2013}{{161}{2013}{{Keefe et~al.}}{{}}}
\bibcite{kelley_confidence_2007}{{162}{2007}{{Kelley}}{{}}}
\bibcite{kelley_effect_2012}{{163}{2012}{{Kelley and Preacher}}{{}}}
\bibcite{kelley_sample_2006}{{164}{2006}{{Kelley and Rausch}}{{}}}
\bibcite{kenett_information_2016}{{165}{2016}{{Kenett et~al.}}{{}}}
\bibcite{kennedy-shaffer_before_2019}{{166}{2019}{{Kennedy-Shaffer}}{{}}}
\bibcite{kenny_unappreciated_2019}{{167}{2019}{{Kenny and Judd}}{{}}}
\bibcite{keppel_design_1991}{{168}{1991}{{Keppel}}{{}}}
\bibcite{kerr_harking_1998}{{169}{1998}{{Kerr}}{{}}}
\bibcite{king_point_2011}{{170}{2011}{{King}}{{}}}
\bibcite{kish_survey_1965}{{171}{1965}{{Kish}}{{}}}
\bibcite{kraft_interpreting_2020}{{172}{2020}{{Kraft}}{{}}}
\bibcite{kruschke_bayesian_2011}{{173}{2011}{{Kruschke}}{{}}}
\bibcite{kruschke_bayesian_2013}{{174}{2013}{{Kruschke}}{{}}}
\bibcite{kruschke_doing_2014}{{175}{2014}{{Kruschke}}{{}}}
\bibcite{kruschke_rejecting_2018}{{176}{2018}{{Kruschke}}{{}}}
\bibcite{kruschke_bayesian_2017}{{177}{2017}{{Kruschke and Liddell}}{{}}}
\bibcite{lakens_calculating_2013}{{178}{2013}{{Lakens}}{{}}}
\bibcite{lakens_performing_2014}{{179}{2014}{{Lakens}}{{}}}
\bibcite{lakens_equivalence_2017}{{180}{2017}{{Lakens}}{{}}}
\bibcite{lakens_value_2019}{{181}{2019}{{Lakens}}{{}}}
\bibcite{lakens_practical_2021}{{182}{2021}{{Lakens}}{{}}}
\bibcite{lakens_sample_2022}{{183}{2022a}{{Lakens}}{{}}}
\bibcite{lakens_why_2022}{{184}{2022b}{{Lakens}}{{}}}
\bibcite{lakens_justify_2018}{{185}{2018a}{{Lakens et~al.}}{{}}}
\bibcite{lakens_simulation-based_2021}{{186}{2021}{{Lakens and Caldwell}}{{}}}
\bibcite{lakens_too_2017}{{187}{2017}{{Lakens and Etz}}{{}}}
\bibcite{lakens_reproducibility_2016}{{188}{2016}{{Lakens et~al.}}{{}}}
\bibcite{lakens_improving_2020}{{189}{2020}{{Lakens et~al.}}{{}}}
\bibcite{lakens_equivalence_2018}{{190}{2018b}{{Lakens et~al.}}{{}}}
\bibcite{lan_discrete_1983}{{191}{1983}{{Lan and DeMets}}{{}}}
\bibcite{lawrence_lesson_2021}{{192}{2021}{{Lawrence et~al.}}{{}}}
\bibcite{leamer_specification_1978}{{193}{1978}{{Leamer}}{{}}}
\bibcite{lehmann_testing_2005}{{194}{2005}{{Lehmann and Romano}}{{}}}
\bibcite{lenth_practical_2001}{{195}{2001}{{Lenth}}{{}}}
\bibcite{lenth_post_2007}{{196}{2007}{{Lenth}}{{}}}
\bibcite{leon_role_2011}{{197}{2011}{{Leon et~al.}}{{}}}
\bibcite{levine_communication_2008}{{198}{2008}{{Levine et~al.}}{{}}}
\bibcite{leys_how_2019}{{199}{2019}{{Leys et~al.}}{{}}}
\bibcite{linden_heterogeneity_2021}{{200}{2021}{{Linden and H{\"o}nekopp}}{{}}}
\bibcite{lindley_statistical_1957}{{201}{1957}{{Lindley}}{{}}}
\bibcite{lindsay_replication_2015}{{202}{2015}{{Lindsay}}{{}}}
\bibcite{lovakov_empirically_2017}{{203}{2017}{{Lovakov and Agadullina}}{{}}}
\bibcite{maier_justify_2022}{{204}{2022}{{Maier and Lakens}}{{}}}
\bibcite{makel_both_2021}{{205}{2021}{{Makel et~al.}}{{}}}
\bibcite{marshall_does_2013}{{206}{2013}{{Marshall et~al.}}{{}}}
\bibcite{maxwell_designing_2004}{{207}{2004}{{Maxwell and Delaney}}{{}}}
\bibcite{maxwell_designing_2017}{{208}{2017}{{Maxwell et~al.}}{{}}}
\bibcite{maxwell_ethics_2011}{{209}{2011}{{Maxwell and Kelley}}{{}}}
\bibcite{maxwell_sample_2008}{{210}{2008}{{Maxwell et~al.}}{{}}}
\bibcite{mayo_statistical_2018}{{211}{2018}{{Mayo}}{{}}}
\bibcite{mazzolari_myths_2022}{{212}{2022}{{Mazzolari et~al.}}{{}}}
\bibcite{mccarthy_registered_2018}{{213}{2018}{{McCarthy et~al.}}{{}}}
\bibcite{mcelreath_statistical_2016}{{214}{2016}{{McElreath}}{{}}}
\bibcite{mcgrath_when_2006}{{215}{2006}{{McGrath and Meyer}}{{}}}
\bibcite{mcgraw_common_1992}{{216}{1992}{{McGraw and Wong}}{{}}}
\bibcite{mcintosh_power_2020}{{217}{2020}{{McIntosh and Rittmo}}{{}}}
\bibcite{meehl_theoretical_1978}{{218}{1978}{{Meehl}}{{}}}
\bibcite{meehl_appraising_1990}{{219}{1990}{{Meehl}}{{}}}
\bibcite{meyners_equivalence_2012}{{220}{2012}{{Meyners}}{{}}}
\bibcite{meyvis_increasing_2018}{{221}{2018}{{Meyvis and Van~Osselaer}}{{}}}
\bibcite{millar_maximum_2011}{{222}{2011}{{Millar}}{{}}}
\bibcite{miller_what_2009}{{223}{2009}{{Miller}}{{}}}
\bibcite{miller_quest_2019}{{224}{2019}{{Miller and Ulrich}}{{}}}
\bibcite{morey_power_2020}{{225}{2020}{{Morey}}{{}}}
\bibcite{morey_pre-registered_2021}{{226}{2021}{{Morey et~al.}}{{}}}
\bibcite{morris_using_2019}{{227}{2019}{{Morris et~al.}}{{}}}
\bibcite{morse_significance_1995}{{228}{1995}{{Morse}}{{}}}
\bibcite{moshontz_psychological_2018}{{229}{2018}{{Moshontz et~al.}}{{}}}
\bibcite{mrozek_what_2002}{{230}{2002}{{Mrozek and Taylor}}{{}}}
\bibcite{mudge_setting_2012}{{231}{2012}{{Mudge et~al.}}{{}}}
\bibcite{mullan_town_1985}{{232}{1985}{{Mullan and Jacoby}}{{}}}
\bibcite{murphy_testing_1999}{{233}{1999}{{Murphy and Myors}}{{}}}
\bibcite{murphy_statistical_2014}{{234}{2014}{{Murphy et~al.}}{{}}}
\bibcite{neyman_inductive_1957}{{235}{1957}{{Neyman}}{{}}}
\bibcite{neyman_problem_1933}{{236}{1933}{{Neyman and Pearson}}{{}}}
\bibcite{nickerson_null_2000}{{237}{2000}{{Nickerson}}{{}}}
\bibcite{niiniluoto_verisimilitude_1998}{{238}{1998}{{Niiniluoto}}{{}}}
\bibcite{norman_truly_2004}{{239}{2004}{{Norman et~al.}}{{}}}
\bibcite{nosek_registered_2014}{{240}{2014}{{Nosek and Lakens}}{{}}}
\bibcite{nuijten_prevalence_2015}{{241}{2015}{{Nuijten et~al.}}{{}}}
\bibcite{nunnally_place_1960}{{242}{1960}{{Nunnally}}{{}}}
\bibcite{obels_analysis_2020}{{243}{2020}{{Obels et~al.}}{{}}}
\bibcite{odonnell_registered_2018}{{244}{2018}{{O'Donnell et~al.}}{{}}}
\bibcite{okada_is_2013}{{245}{2013}{{Okada}}{{}}}
\bibcite{olejnik_generalized_2003}{{246}{2003}{{Olejnik and Algina}}{{}}}
\bibcite{olsson-collentine_heterogeneity_2020}{{247}{2020}{{{Olsson-Collentine} et~al.}}{{}}}
\bibcite{open_science_collaboration_estimating_2015}{{248}{2015}{{Open Science Collaboration}}{{}}}
\bibcite{orben_crud_2020}{{249}{2020}{{Orben and Lakens}}{{}}}
\bibcite{parker_sample_2003}{{250}{2003}{{Parker and Berman}}{{}}}
\bibcite{parkhurst_statistical_2001}{{251}{2001}{{Parkhurst}}{{}}}
\bibcite{parsons_psychological_2019}{{252}{2019}{{Parsons et~al.}}{{}}}
\bibcite{pawitan_all_2001}{{253}{2001}{{Pawitan}}{{}}}
\bibcite{perneger_whats_1998}{{254}{1998}{{Perneger}}{{}}}
\bibcite{perugini_safeguard_2014}{{255}{2014}{{Perugini et~al.}}{{}}}
\bibcite{perugini_practical_2018}{{256}{2018}{{Perugini et~al.}}{{}}}
\bibcite{peters_performance_2007}{{257}{2007}{{Peters et~al.}}{{}}}
\bibcite{phillips_statistical_2001}{{258}{2001}{{Phillips et~al.}}{{}}}
\bibcite{pocock_group_1977}{{259}{1977}{{Pocock}}{{}}}
\bibcite{polanin_transparency_2020}{{260}{2020}{{Polanin et~al.}}{{}}}
\bibcite{popper_logic_2002}{{261}{2002}{{Popper}}{{}}}
\bibcite{primbs_are_2022}{{262}{2022}{{Primbs et~al.}}{{}}}
\bibcite{proschan_two-stage_2005}{{263}{2005}{{Proschan}}{{}}}
\bibcite{proschan_statistical_2006}{{264}{2006}{{Proschan et~al.}}{{}}}
\bibcite{quertemont_how_2011}{{265}{2011}{{Quertemont}}{{}}}
\bibcite{rice_heads_1994}{{266}{1994}{{Rice and Gaines}}{{}}}
\bibcite{richard_one_2003}{{267}{2003}{{Richard et~al.}}{{}}}
\bibcite{richardson_eta_2011}{{268}{2011}{{Richardson}}{{}}}
\bibcite{rogers_using_1993}{{269}{1993}{{Rogers et~al.}}{{}}}
\bibcite{rogers_how_1992}{{270}{1992}{{Rogers}}{{}}}
\bibcite{ropovik_neglect_2021}{{271}{2021}{{Ropovik et~al.}}{{}}}
\bibcite{rosenthal_contrasts_2000}{{272}{2000}{{Rosenthal et~al.}}{{}}}
\bibcite{rouder_bayesian_2009}{{273}{2009}{{Rouder et~al.}}{{}}}
\bibcite{royall_statistical_1997}{{274}{1997}{{Royall}}{{}}}
\bibcite{rozeboom_fallacy_1960}{{275}{1960}{{Rozeboom}}{{}}}
\bibcite{rucker_undue_2008}{{276}{2008}{{R{\"u}cker et~al.}}{{}}}
\bibcite{scheel_excess_2021}{{277}{2021a}{{Scheel et~al.}}{{}}}
\bibcite{scheel_why_2021}{{278}{2021b}{{Scheel et~al.}}{{}}}
\bibcite{schimmack_ironic_2012}{{279}{2012}{{Schimmack}}{{}}}
\bibcite{schnuerch_controlling_2020}{{280}{2020}{{Schnuerch and Erdfelder}}{{}}}
\bibcite{schoemann_determining_2017}{{281}{2017}{{Schoemann et~al.}}{{}}}
\bibcite{schonbrodt_sequential_2017}{{282}{2017}{{Sch{\"o}nbrodt et~al.}}{{}}}
\bibcite{schuirmann_comparison_1987}{{283}{1987}{{Schuirmann}}{{}}}
\bibcite{schulz_sample_2005}{{284}{2005}{{Schulz and Grimes}}{{}}}
\bibcite{schumi_through_2011}{{285}{2011}{{Schumi and Wittes}}{{}}}
\bibcite{schweder_confidence_2016}{{286}{2016}{{Schweder and Hjort}}{{}}}
\bibcite{seaman_equivalence_1998}{{287}{1998}{{Seaman and Serlin}}{{}}}
\bibcite{sedlmeier_studies_1989}{{288}{1989}{{Sedlmeier and Gigerenzer}}{{}}}
\bibcite{shmueli_explain_2010}{{289}{2010}{{Shmueli}}{{}}}
\bibcite{simmons_false-positive_2011}{{290}{2011}{{Simmons et~al.}}{{}}}
\bibcite{simmons_life_2013}{{291}{2013}{{Simmons et~al.}}{{}}}
\bibcite{simonsohn_small_2015}{{292}{2015}{{Simonsohn}}{{}}}
\bibcite{simonsohn_p-curve_2014}{{293}{2014}{{Simonsohn et~al.}}{{}}}
\bibcite{smithson_confidence_2003}{{294}{2003}{{Smithson}}{{}}}
\bibcite{sotola_garbage_2022}{{295}{2022}{{Sotola}}{{}}}
\bibcite{spanos_who_2013}{{296}{2013}{{Spanos}}{{}}}
\bibcite{spellman_short_2015}{{297}{2015}{{Spellman}}{{}}}
\bibcite{spiegelhalter_art_2019}{{298}{2019}{{Spiegelhalter}}{{}}}
\bibcite{spiegelhalter_monitoring_1986}{{299}{1986}{{Spiegelhalter et~al.}}{{}}}
\bibcite{stanley_meta-regression_2014}{{300}{2014}{{Stanley and Doucouliagos}}{{}}}
\bibcite{stanley_finding_2017}{{301}{2017}{{Stanley et~al.}}{{}}}
\bibcite{steiger_beyond_2004}{{302}{2004}{{Steiger}}{{}}}
\bibcite{sterling_publication_1959}{{303}{1959}{{Sterling}}{{}}}
\bibcite{stewart_ipd_2002}{{304}{2002}{{Stewart and Tierney}}{{}}}
\bibcite{taper_philosophy_2011}{{305}{2011}{{Taper and Lele}}{{}}}
\bibcite{taylor_bias_1996}{{306}{1996}{{Taylor and Muller}}{{}}}
\bibcite{teare_sample_2014}{{307}{2014}{{Teare et~al.}}{{}}}
\bibcite{tendeiro_review_2019}{{308}{2019}{{Tendeiro and Kiers}}{{}}}
\bibcite{ter_schure_accumulation_2019}{{309}{2019}{{{ter Schure} and Gr{\"u}nwald}}{{}}}
\bibcite{terrin_adjusting_2003}{{310}{2003}{{Terrin et~al.}}{{}}}
\bibcite{thompson_effect_2007}{{311}{2007}{{Thompson}}{{}}}
\bibcite{tversky_features_1977}{{312}{1977}{{Tversky}}{{}}}
\bibcite{tversky_belief_1971}{{313}{1971}{{Tversky and Kahneman}}{{}}}
\bibcite{ulrich_properties_2018}{{314}{2018}{{Ulrich and Miller}}{{}}}
\bibcite{uygun_tunc_falsificationist_2022}{{315}{2022}{{Uygun~Tun{\c c} and Tun{\c c}}}{{}}}
\bibcite{uygun_tunc_epistemic_2021}{{316}{2021}{{Uygun~Tun{\c c} et~al.}}{{}}}
\bibcite{valentine_how_2010}{{317}{2010}{{Valentine et~al.}}{{}}}
\bibcite{aert_correcting_2018}{{318}{2018}{{van Aert and van Assen}}{{}}}
\bibcite{van_de_schoot_use_2021}{{319}{2021}{{{van de Schoot} et~al.}}{{}}}
\bibcite{dongen_multiple_2019}{{320}{2019}{{van Dongen et~al.}}{{}}}
\bibcite{rijnsoever_i_2017}{{321}{2017}{{van Rijnsoever}}{{}}}
\bibcite{van_t_veer_pre-registration_2016}{{322}{2016}{{{van 't Veer} and {Giner-Sorolla}}}{{}}}
\bibcite{verschuere_registered_2018}{{323}{2018}{{Verschuere et~al.}}{{}}}
\bibcite{viamonte_cost-benefit_2006}{{324}{2006}{{Viamonte et~al.}}{{}}}
\bibcite{viechtbauer_conducting_2010}{{325}{2010}{{Viechtbauer}}{{}}}
\bibcite{vohs_multisite_2021}{{326}{2021}{{Vohs et~al.}}{{}}}
\bibcite{vosgerau_99_2019}{{327}{2019}{{Vosgerau et~al.}}{{}}}
\bibcite{vuorre_curating_2018}{{328}{2018}{{Vuorre and Curley}}{{}}}
\bibcite{wacholder_assessing_2004}{{329}{2004}{{Wacholder et~al.}}{{}}}
\bibcite{wagenmakers_practical_2007}{{330}{2007}{{Wagenmakers}}{{}}}
\bibcite{wagenmakers_registered_2016}{{331}{2016}{{Wagenmakers et~al.}}{{}}}
\bibcite{wald_sequential_1945}{{332}{1945}{{Wald}}{{}}}
\bibcite{wassmer_group_2016}{{333}{2016}{{Wassmer and Brannath}}{{}}}
\bibcite{weinshall-margel_overlooked_2011}{{334}{2011}{{{Weinshall-Margel} and Shapard}}{{}}}
\bibcite{wellek_testing_2010}{{335}{2010}{{Wellek}}{{}}}
\bibcite{westberg_combining_1985}{{336}{1985}{{Westberg}}{{}}}
\bibcite{westfall_statistical_2014}{{337}{2014}{{Westfall et~al.}}{{}}}
\bibcite{westlake_use_1972}{{338}{1972}{{Westlake}}{{}}}
\bibcite{wicherts_degrees_2016}{{339}{2016}{{Wicherts et~al.}}{{}}}
\bibcite{wiebels_leveraging_2021}{{340}{2021}{{Wiebels and Moreau}}{{}}}
\bibcite{williams_impact_1995}{{341}{1995}{{Williams et~al.}}{{}}}
\bibcite{wilson_practical_2015}{{342}{2015}{{Wilson}}{{}}}
\bibcite{wilson_vanvoorhis_understanding_2007}{{343}{2007}{{Wilson~VanVoorhis and Morgan}}{{}}}
\bibcite{winer_statistical_1962}{{344}{1962}{{Winer}}{{}}}
\bibcite{wittes_role_1990}{{345}{1990}{{Wittes and Brittain}}{{}}}
\bibcite{wong_potential_2021}{{346}{2021}{{Wong et~al.}}{{}}}
\bibcite{wynants_prediction_2020}{{347}{2020}{{Wynants et~al.}}{{}}}
\bibcite{yarkoni_choosing_2017}{{348}{2017}{{Yarkoni and Westfall}}{{}}}
\bibcite{yuan_post_2005}{{349}{2005}{{Yuan and Maxwell}}{{}}}
\bibcite{zabell_r_1992}{{350}{1992}{{Zabell}}{{}}}
\bibcite{zumbo_note_1998}{{351}{1998}{{Zumbo and Hubley}}{{}}}
\gdef \@abspage@last{372}
