\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{apalike}
\HyPL@Entry{0<</S/r>>}
\HyPL@Entry{1<</S/r>>}
\@writefile{toc}{\contentsline {fm}{List of Figures}{viii}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {fm}{List of Tables}{xiv}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {fm}{Introduction}{xv}{chapter*.3}\protected@file@percent }
\newlabel{introduction}{{}{xv}{Introduction}{chapter*.3}{}}
\citation{gosset_application_1904}
\citation{benjamini_its_2016}
\citation{fricker_assessing_2019}
\HyPL@Entry{16<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Using \emph  {p}-values to test a hypothesis}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{pvalue}{{1}{1}{\texorpdfstring {Using \emph {p}-values to test a hypothesis}{Using p-values to test a hypothesis}}{chapter.1}{}}
\citation{greenland_statistical_2016}
\citation{fisher_statistical_1956}
\citation{zabell_r_1992}
\citation{schweder_confidence_2016}
\citation{neyman_problem_1933}
\citation{dienes_understanding_2008}
\citation{neyman_inductive_1957}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Philosophical approaches to \emph  {p}-values}{2}{section.1.1}\protected@file@percent }
\newlabel{philosophical-approaches-to-p-values}{{1.1}{2}{\texorpdfstring {Philosophical approaches to \emph {p}-values}{Philosophical approaches to p-values}}{section.1.1}{}}
\citation{cox_problems_1958}
\citation{hempel_philosophy_1966}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Creating a null model}{3}{section.1.2}\protected@file@percent }
\newlabel{creating-a-null-model}{{1.2}{3}{Creating a null model}{section.1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces Ratings for the Lord of the Rings extended trilogy by two groups of friends.\relax }}{4}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:friends}{{1.1}{4}{Ratings for the Lord of the Rings extended trilogy by two groups of friends.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Calculating a \emph  {p}-value}{5}{section.1.3}\protected@file@percent }
\newlabel{calculating-a-p-value}{{1.3}{5}{\texorpdfstring {Calculating a \emph {p}-value}{Calculating a p-value}}{section.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces A \emph  {t}-distribution with 18 degrees of freedom.\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:tdist}{{1.1}{6}{A \emph {t}-distribution with 18 degrees of freedom.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Which \emph  {p}-values can you expect?}{6}{section.1.4}\protected@file@percent }
\newlabel{whichpexpect}{{1.4}{6}{\texorpdfstring {Which \emph {p}-values can you expect?}{Which p-values can you expect?}}{section.1.4}{}}
\citation{hung_behavior_1997,ulrich_properties_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Distribution of \emph  {p}-values when power = 50\%.\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:pdistr1}{{1.2}{7}{Distribution of \emph {p}-values when power = 50\%.\relax }{figure.caption.6}{}}
\citation{lindley_statistical_1957}
\citation{spanos_who_2013}
\citation{cumming_replication_2008}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Probability density function for \emph  {p}-values from a two-sided \emph  {t}-test.\relax }}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:pdft}{{1.3}{8}{Probability density function for \emph {p}-values from a two-sided \emph {t}-test.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Lindley's paradox}{8}{section.1.5}\protected@file@percent }
\newlabel{lindley}{{1.5}{8}{Lindley's paradox}{section.1.5}{}}
\citation{leamer_specification_1978,maier_justify_2022,good_bayesnon-bayes_1992}
\citation{appelbaum_journal_2018}
\citation{lehmann_testing_2005}
\citation{fisher_design_1935}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Distribution of \emph  {p}-values when the null hypothesis is true.\relax }}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:pdistr2}{{1.4}{9}{Distribution of \emph {p}-values when the null hypothesis is true.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Correctly reporting and interpreting \emph  {p}-values}{9}{section.1.6}\protected@file@percent }
\newlabel{correctlyinterpreting}{{1.6}{9}{\texorpdfstring {Correctly reporting and interpreting \emph {p}-values}{Correctly reporting and interpreting p-values}}{section.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces \emph  {P}-value distribution for 0 (grey horizontal line, 50 percent power (black solid curve), and 99 percent power (black dotted curve, where \emph  {p}-values just below 0.05 are more likely when \(H_0\) is true than when \(H_1\) is true).\relax }}{10}{figure.caption.9}\protected@file@percent }
\newlabel{fig:paradox}{{1.5}{10}{\emph {P}-value distribution for 0 (grey horizontal line, 50 percent power (black solid curve), and 99 percent power (black dotted curve, where \emph {p}-values just below 0.05 are more likely when \(H_0\) is true than when \(H_1\) is true).\relax }{figure.caption.9}{}}
\citation{niiniluoto_verisimilitude_1998,popper_logic_2002}
\citation{popper_logic_2002}
\citation{hacking_logic_1965}
\citation{neyman_inductive_1957}
\citation{bland_introduction_2015}
\citation{johansson_hail_2011,lakens_why_2022}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Preventing common misconceptions about \emph  {p}-values}{11}{section.1.7}\protected@file@percent }
\newlabel{misconceptions}{{1.7}{11}{\texorpdfstring {Preventing common misconceptions about \emph {p}-values}{Preventing common misconceptions about p-values}}{section.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent \emph  {t}-test.\relax }}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig:fig131}{{1.6}{12}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent \emph {t}-test.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 5000 observations per group in an independent \emph  {t}-test when \emph  {d} = 0.\relax }}{13}{figure.caption.11}\protected@file@percent }
\newlabel{fig:fig132}{{1.7}{13}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 5000 observations per group in an independent \emph {t}-test when \emph {d} = 0.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Screenshot from G*Power software visualizing the null model (red distribution) and alternative model (blue distribution) and the critical \emph  {t}-value (1.66055) that is the threshold distinguishing significant and non-significant results.\relax }}{14}{figure.caption.12}\protected@file@percent }
\newlabel{fig:gpowerscreenshot}{{1.8}{14}{Screenshot from G*Power software visualizing the null model (red distribution) and alternative model (blue distribution) and the critical \emph {t}-value (1.66055) that is the threshold distinguishing significant and non-significant results.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent \emph  {t}-test when \emph  {d} = 0.\relax }}{15}{figure.caption.13}\protected@file@percent }
\newlabel{fig:fig134}{{1.9}{15}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent \emph {t}-test when \emph {d} = 0.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.1}Misunderstanding 1: A non-significant \emph  {p}-value means that the null hypothesis is true.}{16}{subsection.1.7.1}\protected@file@percent }
\newlabel{misconception1}{{1.7.1}{16}{\texorpdfstring {Misunderstanding 1: A non-significant \emph {p}-value means that the null hypothesis is true.}{Misunderstanding 1: A non-significant p-value means that the null hypothesis is true.}}{subsection.1.7.1}{}}
\citation{harms_making_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent \emph  {t}-test for \emph  {d} = 0 and \emph  {d} = 0.5 when observing \emph  {d} = 0.35.\relax }}{17}{figure.caption.14}\protected@file@percent }
\newlabel{fig:fig136}{{1.10}{17}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent \emph {t}-test for \emph {d} = 0 and \emph {d} = 0.5 when observing \emph {d} = 0.35.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.2}Misunderstanding 2: A significant \emph  {p}-value means that the null hypothesis is false.}{18}{subsection.1.7.2}\protected@file@percent }
\newlabel{misunderstanding-2-a-significant-p-value-means-that-the-null-hypothesis-is-false.}{{1.7.2}{18}{\texorpdfstring {Misunderstanding 2: A significant \emph {p}-value means that the null hypothesis is false.}{Misunderstanding 2: A significant p-value means that the null hypothesis is false.}}{subsection.1.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.11}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 50 observations per group in an independent \emph  {t}-test when \emph  {d} = 0 and observing \emph  {d} = 0.5.\relax }}{19}{figure.caption.15}\protected@file@percent }
\newlabel{fig:fig137}{{1.11}{19}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 50 observations per group in an independent \emph {t}-test when \emph {d} = 0 and observing \emph {d} = 0.5.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.3}Misunderstanding 3: A significant \emph  {p}-value means that a practically important effect has been discovered.}{19}{subsection.1.7.3}\protected@file@percent }
\newlabel{misunderstanding-3-a-significant-p-value-means-that-a-practically-important-effect-has-been-discovered.}{{1.7.3}{19}{\texorpdfstring {Misunderstanding 3: A significant \emph {p}-value means that a practically important effect has been discovered.}{Misunderstanding 3: A significant p-value means that a practically important effect has been discovered.}}{subsection.1.7.3}{}}
\citation{anvari_not_2021}
\citation{miller_what_2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.4}Misunderstanding 4: If you have observed a significant finding, the probability that you have made a Type 1 error (a false positive) is 5\%.}{20}{subsection.1.7.4}\protected@file@percent }
\newlabel{misconception4}{{1.7.4}{20}{Misunderstanding 4: If you have observed a significant finding, the probability that you have made a Type 1 error (a false positive) is 5\%}{subsection.1.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.7.5}Misunderstanding 5: One minus the \emph  {p}-value is the probability that the effect will replicate when repeated.}{20}{subsection.1.7.5}\protected@file@percent }
\newlabel{misunderstanding-5-one-minus-the-p-value-is-the-probability-that-the-effect-will-replicate-when-repeated.}{{1.7.5}{20}{\texorpdfstring {Misunderstanding 5: One minus the \emph {p}-value is the probability that the effect will replicate when repeated.}{Misunderstanding 5: One minus the p-value is the probability that the effect will replicate when repeated.}}{subsection.1.7.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.12}{\ignorespaces Distribution of observed Cohen's \emph  {d} effect sizes when collecting 20 observations per group in an independent \emph  {t}-test when \emph  {d} = 0.\relax }}{21}{figure.caption.16}\protected@file@percent }
\newlabel{fig:fig138}{{1.12}{21}{Distribution of observed Cohen's \emph {d} effect sizes when collecting 20 observations per group in an independent \emph {t}-test when \emph {d} = 0.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Test Yourself}{22}{section.1.8}\protected@file@percent }
\newlabel{test-yourself}{{1.8}{22}{Test Yourself}{section.1.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Questions about which \emph  {p}-values you can expect}{22}{subsection.1.8.1}\protected@file@percent }
\newlabel{questions-about-which-p-values-you-can-expect}{{1.8.1}{22}{\texorpdfstring {Questions about which \emph {p}-values you can expect}{Questions about which p-values you can expect}}{subsection.1.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Questions about \emph  {p}-value misconceptions}{26}{subsection.1.8.2}\protected@file@percent }
\newlabel{questions-about-p-value-misconceptions}{{1.8.2}{26}{\texorpdfstring {Questions about \emph {p}-value misconceptions}{Questions about p-value misconceptions}}{subsection.1.8.2}{}}
\citation{tversky_belief_1971}
\citation{miller_what_2009}
\@writefile{lof}{\contentsline {figure}{\numberline {1.13}{\ignorespaces Screenshot of first paragraph in Tversky and Kahneman, 1971.\relax }}{29}{figure.caption.17}\protected@file@percent }
\newlabel{fig:smallnumbers}{{1.13}{29}{Screenshot of first paragraph in Tversky and Kahneman, 1971.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.3}Open Questions}{30}{subsection.1.8.3}\protected@file@percent }
\newlabel{open-questions}{{1.8.3}{30}{Open Questions}{subsection.1.8.3}{}}
\citation{neyman_problem_1933}
\citation{mayo_statistical_2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Error control}{31}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{errorcontrol}{{2}{31}{Error control}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Which outcome can you expect if you perform a study?}{31}{section.2.1}\protected@file@percent }
\newlabel{which-outcome-can-you-expect-if-you-perform-a-study}{{2.1}{31}{Which outcome can you expect if you perform a study?}{section.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Difference between Type 1 and Type 2 errors. Figure made by <a href="https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/">Paul Ellis</a>\relax }}{32}{figure.caption.18}\protected@file@percent }
\newlabel{fig:errortypes}{{2.1}{32}{Difference between Type 1 and Type 2 errors. Figure made by <a href="https://effectsizefaq.com/2010/05/31/i-always-get-confused-about-type-i-and-ii-errors-can-you-show-me-something-to-help-me-remember-the-difference/">Paul Ellis</a>\relax }{figure.caption.18}{}}
\gdef \LT@i {\LT@entry 
    {1}{181.39241pt}\LT@entry 
    {1}{148.16707pt}\LT@entry 
    {1}{140.24356pt}}
\citation{ioannidis_why_2005}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Positive predictive value}{33}{section.2.2}\protected@file@percent }
\newlabel{ppv}{{2.2}{33}{Positive predictive value}{section.2.2}{}}
\citation{wacholder_assessing_2004}
\citation{colquhoun_false_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The positive predictive value can be used to explain why there are more vaccinated people in the hospital than unvaccinated people.\relax }}{34}{figure.caption.19}\protected@file@percent }
\newlabel{fig:ppvhospital}{{2.2}{34}{The positive predictive value can be used to explain why there are more vaccinated people in the hospital than unvaccinated people.\relax }{figure.caption.19}{}}
\citation{dunn_multiple_1961}
\citation{babbage_reflections_1830}
\citation{barber_pitfalls_1976}
\citation{kerr_harking_1998}
\citation{jostmann_short_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Screenshot of the output of the results of the PPV Shiny app by <a href="http://shinyapps.org/apps/PPV/">Michael Zehetleitner and Felix Schönbrodt </a>\relax }}{35}{figure.caption.20}\protected@file@percent }
\newlabel{fig:ppvexample}{{2.3}{35}{Screenshot of the output of the results of the PPV Shiny app by <a href="http://shinyapps.org/apps/PPV/">Michael Zehetleitner and Felix Schönbrodt </a>\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Type 1 error inflation}{35}{section.2.3}\protected@file@percent }
\newlabel{type-1-error-inflation}{{2.3}{35}{Type 1 error inflation}{section.2.3}{}}
\citation{elson_press_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Quote from the 1830 book by Babbage Reflections on the Decline of Science in England And on Some of Its Causes.\relax }}{36}{figure.caption.21}\protected@file@percent }
\newlabel{fig:cooking}{{2.4}{36}{Quote from the 1830 book by Babbage Reflections on the Decline of Science in England And on Some of Its Causes.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Plot of publications using CRTT (blue) and unique quantifications of the measure (red). Figure from FlexibleMeasures.com by Malte Elson\relax }}{37}{figure.caption.22}\protected@file@percent }
\newlabel{fig:flexiblemeasure}{{2.5}{37}{Plot of publications using CRTT (blue) and unique quantifications of the measure (red). Figure from FlexibleMeasures.com by Malte Elson\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Screenshot a scientific paper explicitly admitting to using optional stopping.\relax }}{37}{figure.caption.23}\protected@file@percent }
\newlabel{fig:optionalstoppingexample}{{2.6}{37}{Screenshot a scientific paper explicitly admitting to using optional stopping.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Optional stopping}{37}{section.2.4}\protected@file@percent }
\newlabel{optionalstopping}{{2.4}{37}{Optional stopping}{section.2.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Simulated \emph  {p}-values for each additional observation when the null is true.\relax }}{39}{figure.caption.24}\protected@file@percent }
\newlabel{fig:animatep}{{2.7}{39}{Simulated \emph {p}-values for each additional observation when the null is true.\relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Simulated \emph  {p}-values for each additional observation when d = 0.3.\relax }}{39}{figure.caption.25}\protected@file@percent }
\newlabel{fig:animatep2}{{2.8}{39}{Simulated \emph {p}-values for each additional observation when d = 0.3.\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Simulation of 500000 studies performing 5 interim analyses at an alpha level of 5\%.\relax }}{41}{figure.caption.26}\protected@file@percent }
\newlabel{fig:optionalstopfig}{{2.9}{41}{Simulation of 500000 studies performing 5 interim analyses at an alpha level of 5\%.\relax }{figure.caption.26}{}}
\citation{neyman_problem_1933}
\citation{cowles_origins_1982,kennedy-shaffer_before_2019}
\citation{cohen_statistical_1988}
\citation{bross_critical_1971}
\citation{uygun_tunc_epistemic_2021}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Justifying Error Rates}{42}{section.2.5}\protected@file@percent }
\newlabel{justifyerrorrate}{{2.5}{42}{Justifying Error Rates}{section.2.5}{}}
\citation{johnson_revised_2013}
\citation{lakens_justify_2018}
\citation{mudge_setting_2012,gannon_blending_2019}
\citation{maier_justify_2022}
\citation{maier_justify_2022}
\citation{leamer_specification_1978}
\citation{perneger_whats_1998}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Weighted combined error rate, minimized at alpha = 0.037.\relax }}{44}{figure.caption.27}\protected@file@percent }
\newlabel{fig:minimizeerror}{{2.10}{44}{Weighted combined error rate, minimized at alpha = 0.037.\relax }{figure.caption.27}{}}
\citation{neyman_inductive_1957}
\citation{mayo_statistical_2018}
\citation{dmitrienko_traditional_2013}
\citation{bretz_multiple_2011}
\citation{bender_adjusting_2001}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Why you don't need to adjust your alpha level for all tests you'll do in your lifetime.}{45}{section.2.6}\protected@file@percent }
\newlabel{why-you-dont-need-to-adjust-your-alpha-level-for-all-tests-youll-do-in-your-lifetime.}{{2.6}{45}{Why you don't need to adjust your alpha level for all tests you'll do in your lifetime}{section.2.6}{}}
\citation{benjamini_controlling_1995}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Power Analysis}{46}{section.2.7}\protected@file@percent }
\newlabel{power-analysis}{{2.7}{46}{Power Analysis}{section.2.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Distribution of \emph  {d} = 0 and \emph  {d} = 0.5 for an independent \emph  {t}-test with \emph  {n} = 50.\relax }}{47}{figure.caption.28}\protected@file@percent }
\newlabel{fig:powerd}{{2.11}{47}{Distribution of \emph {d} = 0 and \emph {d} = 0.5 for an independent \emph {t}-test with \emph {n} = 50.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Test Yourself}{47}{section.2.8}\protected@file@percent }
\newlabel{test-yourself-1}{{2.8}{47}{Test Yourself}{section.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Questions about the positive predictive value}{47}{subsection.2.8.1}\protected@file@percent }
\newlabel{questions-about-the-positive-predictive-value}{{2.8.1}{47}{Questions about the positive predictive value}{subsection.2.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Questions about optional stopping}{48}{subsection.2.8.2}\protected@file@percent }
\newlabel{questions-about-optional-stopping}{{2.8.2}{48}{Questions about optional stopping}{subsection.2.8.2}{}}
\citation{wagenmakers_practical_2007}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.3}Open Questions}{52}{subsection.2.8.3}\protected@file@percent }
\newlabel{open-questions-1}{{2.8.3}{52}{Open Questions}{subsection.2.8.3}{}}
\citation{pawitan_all_2001,dienes_understanding_2008}
\citation{taper_philosophy_2011}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Likelihoods}{54}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{likelihoods}{{3}{54}{Likelihoods}{chapter.3}{}}
\citation{aldrich_r_1997}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Binomial likelihood function for 8 successes in 10 trials.\relax }}{55}{figure.caption.29}\protected@file@percent }
\newlabel{fig:like1}{{3.1}{55}{Binomial likelihood function for 8 successes in 10 trials.\relax }{figure.caption.29}{}}
\citation{millar_maximum_2011}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Binomial likelihood function for 0 successes in 10 trials.\relax }}{56}{figure.caption.30}\protected@file@percent }
\newlabel{fig:like2}{{3.2}{56}{Binomial likelihood function for 0 successes in 10 trials.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Combining likelihoods.\relax }}{57}{figure.caption.31}\protected@file@percent }
\newlabel{fig:like3}{{3.3}{57}{Combining likelihoods.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Likelihood ratios}{57}{section.3.1}\protected@file@percent }
\newlabel{likelihood-ratios}{{3.1}{57}{Likelihood ratios}{section.3.1}{}}
\citation{royall_statistical_1997}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Likelihood function for 5/10, 50/100 and 500/1000 heads in coin flips.\relax }}{58}{figure.caption.32}\protected@file@percent }
\newlabel{fig:like4}{{3.4}{58}{Likelihood function for 5/10, 50/100 and 500/1000 heads in coin flips.\relax }{figure.caption.32}{}}
\citation{franco_publication_2014,fanelli_positive_2010}
\citation{schimmack_ironic_2012,francis_frequency_2014}
\citation{lakens_too_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Computing a likelihood ratio for \emph  {p} = 0.5 relative to \emph  {p} = 0.8 when observing \emph  {p} = 0.8.\relax }}{59}{figure.caption.33}\protected@file@percent }
\newlabel{fig:like5}{{3.5}{59}{Computing a likelihood ratio for \emph {p} = 0.5 relative to \emph {p} = 0.8 when observing \emph {p} = 0.8.\relax }{figure.caption.33}{}}
\citation{wacholder_assessing_2004}
\citation{ioannidis_exploratory_2007}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Computing a likelihood ratio for \emph  {p} = 0.5 relative to \emph  {p} = 0.8 when observing \emph  {p} = 0.4.\relax }}{60}{figure.caption.34}\protected@file@percent }
\newlabel{fig:like6}{{3.6}{60}{Computing a likelihood ratio for \emph {p} = 0.5 relative to \emph {p} = 0.8 when observing \emph {p} = 0.4.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Likelihood of mixed results in sets of studies}{60}{section.3.2}\protected@file@percent }
\newlabel{mixedresults}{{3.2}{60}{Likelihood of mixed results in sets of studies}{section.3.2}{}}
\citation{royall_statistical_1997}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Computing a likelihood ratio for \emph  {p} = 0.3 relative to \emph  {p} = 0.8 when observing \emph  {p} = 0.5 in 100 coin flips.\relax }}{61}{figure.caption.35}\protected@file@percent }
\newlabel{fig:like7}{{3.7}{61}{Computing a likelihood ratio for \emph {p} = 0.3 relative to \emph {p} = 0.8 when observing \emph {p} = 0.5 in 100 coin flips.\relax }{figure.caption.35}{}}
\citation{scheel_excess_2021}
\citation{glover_likelihood_2004,pawitan_all_2001}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Computing a likelihood ratio for two out of three significant results, assuming an alpha of 5\% and 80\% power.\relax }}{62}{figure.caption.36}\protected@file@percent }
\newlabel{fig:like8}{{3.8}{62}{Computing a likelihood ratio for two out of three significant results, assuming an alpha of 5\% and 80\% power.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces Likelihood ratio for observed \emph  {t}-value under \(H_0\) and \(H_1\).\relax }}{63}{figure.caption.37}\protected@file@percent }
\newlabel{fig:like9}{{3.9}{63}{Likelihood ratio for observed \emph {t}-value under \(H_0\) and \(H_1\).\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Likelihoods for \emph  {t}-tests}{63}{section.3.3}\protected@file@percent }
\newlabel{likettest}{{3.3}{63}{\texorpdfstring {Likelihoods for \emph {t}-tests}{Likelihoods for t-tests}}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Test Yourself}{63}{section.3.4}\protected@file@percent }
\newlabel{test-yourself-2}{{3.4}{63}{Test Yourself}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Questions about likelihoods}{63}{subsection.3.4.1}\protected@file@percent }
\newlabel{questions-about-likelihoods}{{3.4.1}{63}{Questions about likelihoods}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Questions about mixed results}{65}{subsection.3.4.2}\protected@file@percent }
\newlabel{questions-about-mixed-results}{{3.4.2}{65}{Questions about mixed results}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Open Questions}{67}{subsection.3.4.3}\protected@file@percent }
\newlabel{open-questions-2}{{3.4.3}{67}{Open Questions}{subsection.3.4.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Bayesian statistics}{68}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{bayes}{{4}{68}{Bayesian statistics}{chapter.4}{}}
\citation{dienes_understanding_2008,kass_bayes_1995}
\citation{kruschke_doing_2014}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Bayes factors}{69}{section.4.1}\protected@file@percent }
\newlabel{bayes-factors}{{4.1}{69}{Bayes factors}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Four examples of Bayesian priors.\relax }}{70}{figure.caption.38}\protected@file@percent }
\newlabel{fig:bayes1}{{4.1}{70}{Four examples of Bayesian priors.\relax }{figure.caption.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Four examples of how different priors are updated based on data to the posterior.\relax }}{71}{figure.caption.39}\protected@file@percent }
\newlabel{fig:bayes2}{{4.2}{71}{Four examples of how different priors are updated based on data to the posterior.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Updating our belief}{71}{section.4.2}\protected@file@percent }
\newlabel{updating-our-belief}{{4.2}{71}{Updating our belief}{section.4.2}{}}
\citation{jeffreys_theory_1939}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Plot for the prior, likelihood, and posterior.\relax }}{72}{figure.caption.40}\protected@file@percent }
\newlabel{fig:bayes4}{{4.3}{72}{Plot for the prior, likelihood, and posterior.\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Plot for the prior, likelihood, and posterior.\relax }}{73}{figure.caption.41}\protected@file@percent }
\newlabel{fig:bayes6}{{4.4}{73}{Plot for the prior, likelihood, and posterior.\relax }{figure.caption.41}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Plot for the prior, likelihood, and posterior.\relax }}{73}{figure.caption.42}\protected@file@percent }
\newlabel{fig:bayes7}{{4.5}{73}{Plot for the prior, likelihood, and posterior.\relax }{figure.caption.42}{}}
\citation{dienes_using_2014}
\citation{lakens_improving_2020}
\citation{wong_potential_2022}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Bayesian Estimation}{74}{section.4.3}\protected@file@percent }
\newlabel{bayesest}{{4.3}{74}{Bayesian Estimation}{section.4.3}{}}
\citation{albers_credible_2018}
\citation{mcelreath_statistical_2016}
\citation{berger_interplay_2004}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Plot for the mean of the posterior when 10 out of 20 heads are observed given a uniform prior.\relax }}{75}{figure.caption.43}\protected@file@percent }
\newlabel{fig:bayes8}{{4.6}{75}{Plot for the mean of the posterior when 10 out of 20 heads are observed given a uniform prior.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Test Yourself}{76}{section.4.4}\protected@file@percent }
\newlabel{test-yourself-3}{{4.4}{76}{Test Yourself}{section.4.4}{}}
\citation{rozeboom_fallacy_1960}
\citation{frick_appropriate_1996}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Open Questions}{80}{subsection.4.4.1}\protected@file@percent }
\newlabel{open-questions-3}{{4.4.1}{80}{Open Questions}{subsection.4.4.1}{}}
\citation{kenett_information_2016}
\citation{shmueli_explain_2010}
\citation{gerring_mere_2012}
\citation{scheel_why_2021}
\citation{shmueli_explain_2010}
\citation{wynants_prediction_2020}
\citation{yarkoni_choosing_2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Asking Statistical Questions}{82}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{questions}{{5}{82}{Asking Statistical Questions}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Description}{82}{section.5.1}\protected@file@percent }
\newlabel{description}{{5.1}{82}{Description}{section.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Prediction}{82}{section.5.2}\protected@file@percent }
\newlabel{prediction}{{5.2}{82}{Prediction}{section.5.2}{}}
\citation{meehl_appraising_1990}
\citation{platt_strong_1964}
\citation{hempel_philosophy_1966}
\citation{uygun_tunc_falsificationist_2022}
\citation{fiedler_tools_2004}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Explanation}{83}{section.5.3}\protected@file@percent }
\newlabel{explanation}{{5.3}{83}{Explanation}{section.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Loosening and Tightening}{83}{section.5.4}\protected@file@percent }
\newlabel{looseningtightening}{{5.4}{83}{Loosening and Tightening}{section.5.4}{}}
\citation{scheel_why_2021}
\citation{dubin_theory_1969}
\citation{royall_statistical_1997}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Distinction between a theoretical hypothesis, a statistical hypothesis, and observations. Figure based on Meehl, 1990.\relax }}{84}{figure.caption.44}\protected@file@percent }
\newlabel{fig:meehl1990}{{5.1}{84}{Distinction between a theoretical hypothesis, a statistical hypothesis, and observations. Figure based on Meehl, 1990.\relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Three Statistical Philosophies}{84}{section.5.5}\protected@file@percent }
\newlabel{three-statistical-philosophies}{{5.5}{84}{Three Statistical Philosophies}{section.5.5}{}}
\citation{dongen_multiple_2019,lakens_improving_2020,tendeiro_review_2019}
\citation{jeffreys_theory_1939}
\citation{lakens_practical_2021}
\citation{cohen_earth_1994}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Four phases of clinical research. <a href="https://clinicalinfo.hiv.gov/en/glossary/phase-1-trial">Source</a>.\relax }}{85}{figure.caption.45}\protected@file@percent }
\newlabel{fig:trialphase}{{5.2}{85}{Four phases of clinical research. <a href="https://clinicalinfo.hiv.gov/en/glossary/phase-1-trial">Source</a>.\relax }{figure.caption.45}{}}
\citation{hand_deconstructing_1994}
\citation{lakatos_methodology_1978}
\citation{popper_logic_2002}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Falsification}{86}{section.5.6}\protected@file@percent }
\newlabel{falsification}{{5.6}{86}{Falsification}{section.5.6}{}}
\citation{kuhn_structure_1962}
\citation{meehl_cliometric_2004}
\citation{mayo_statistical_2018}
\citation{feynman_cargo_1974}
\citation{meehl_appraising_1990}
\citation{kerr_harking_1998}
\citation{mayo_statistical_2018}
\citation{lakens_value_2019}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Severe Tests}{88}{section.5.7}\protected@file@percent }
\newlabel{severity}{{5.7}{88}{Severe Tests}{section.5.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Three circles vizualizing predictions that exclude different parts of the world.\relax }}{89}{figure.caption.46}\protected@file@percent }
\newlabel{fig:risky1}{{5.3}{89}{Three circles vizualizing predictions that exclude different parts of the world.\relax }{figure.caption.46}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Risky Predictions}{89}{section.5.8}\protected@file@percent }
\newlabel{risky}{{5.8}{89}{Risky Predictions}{section.5.8}{}}
\citation{meehl-theory-testing_1967}
\citation{meehl_appraising_1990}
\citation{meehl_appraising_1990}
\@writefile{toc}{\contentsline {section}{\numberline {5.9}Do You Really Want to Test a Hypothesis?}{90}{section.5.9}\protected@file@percent }
\newlabel{reallytest}{{5.9}{90}{Do You Really Want to Test a Hypothesis?}{section.5.9}{}}
\citation{de_groot_methodology_1969}
\citation{mayo_statistical_2018}
\citation{baguley_serious_2012}
\citation{jones_test_1952}
\citation{cho_is_2013}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Some fields make black and white predictions about the presence or absence of observables, but in many sciences, predictions are probabilistic, and shades of grey.\relax }}{92}{figure.caption.47}\protected@file@percent }
\newlabel{fig:blackwhite}{{5.4}{92}{Some fields make black and white predictions about the presence or absence of observables, but in many sciences, predictions are probabilistic, and shades of grey.\relax }{figure.caption.47}{}}
\citation{schulz_sample_2005}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Ratio of the required sample size for a one-sample \emph  {t}-test for a non-directional/directional test to achieve 50\%, 80\% or 95\% power.\relax }}{93}{figure.caption.48}\protected@file@percent }
\newlabel{fig:onesidedtwosidedratio}{{5.5}{93}{Ratio of the required sample size for a one-sample \emph {t}-test for a non-directional/directional test to achieve 50\%, 80\% or 95\% power.\relax }{figure.caption.48}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.10}Directional (One-Sided) versus Non-Directional (Two-Sided) Tests}{93}{section.5.10}\protected@file@percent }
\newlabel{onesided}{{5.10}{93}{Directional (One-Sided) versus Non-Directional (Two-Sided) Tests}{section.5.10}{}}
\citation{baguley_serious_2012}
\citation{de_groot_methodology_1969}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Distribution and rejection areas for a two-sided \emph  {t}-test and the corresponding \emph  {F}-test with df1 = 1 and df2 = 100.\relax }}{94}{figure.caption.49}\protected@file@percent }
\newlabel{fig:fandt}{{5.6}{94}{Distribution and rejection areas for a two-sided \emph {t}-test and the corresponding \emph {F}-test with df1 = 1 and df2 = 100.\relax }{figure.caption.49}{}}
\citation{meehl_theoretical_1978}
\citation{meehl_appraising_1990}
\citation{orben_crud_2020}
\@writefile{toc}{\contentsline {section}{\numberline {5.11}Systematic Noise, or the Crud Factor}{95}{section.5.11}\protected@file@percent }
\newlabel{crud}{{5.11}{95}{Systematic Noise, or the Crud Factor}{section.5.11}{}}
\citation{ferguson_providing_2021}
\citation{morey_pre-registered_2021}
\citation{odonnell_registered_2018}
\citation{verschuere_registered_2018}
\citation{wagenmakers_registered_2016}
\citation{hagger_multilab_2016}
\citation{colling_registered_2020}
\citation{mccarthy_registered_2018}
\citation{kuhn_structure_1962}
\citation{laudan_science_1986}
\citation{popper_logic_2002}
\@writefile{toc}{\contentsline {section}{\numberline {5.12}Dealing with Inconsistencies in Science}{97}{section.5.12}\protected@file@percent }
\newlabel{inconsistencies}{{5.12}{97}{Dealing with Inconsistencies in Science}{section.5.12}{}}
\citation{kaiser_directional_1960}
\citation{altoe_enhancing_2020,gelman_beyond_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces The interrelationship between the methdological level, theories that explain factual observation, and the aims of science according to Laudan's reticulated model of scientific rationality.\relax }}{98}{figure.caption.50}\protected@file@percent }
\newlabel{fig:laudan}{{5.7}{98}{The interrelationship between the methdological level, theories that explain factual observation, and the aims of science according to Laudan's reticulated model of scientific rationality.\relax }{figure.caption.50}{}}
\citation{mcguire_perspectivist_2004}
\citation{stroebe_alleged_2014}
\citation{luttrell_replicating_2017}
\citation{mellers_frequency_2001}
\citation{uygun_tunc_falsificationist_2022}
\citation{duhem_aim_1954}
\citation{laudan_science_1981}
\citation{van_fraassen_scientific_1980}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Path model of a moderation effect where the effect of X on Y depends on Z, where the effect sizes a and b differ from each other depending on the level of Z.\relax }}{100}{figure.caption.51}\protected@file@percent }
\newlabel{fig:moderation}{{5.8}{100}{Path model of a moderation effect where the effect of X on Y depends on Z, where the effect sizes a and b differ from each other depending on the level of Z.\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.13}Verisimilitude and Progress in Science}{100}{section.5.13}\protected@file@percent }
\newlabel{verisimilitude-and-progress-in-science}{{5.13}{100}{Verisimilitude and Progress in Science}{section.5.13}{}}
\citation{feyerabend_against_1993}
\citation{meehl_theoretical_1978}
\citation{niiniluoto_verisimilitude_1998}
\citation{meehl_theoretical_1978,meehl_appraising_1990}
\citation{kuipers_models_2016}
\citation{niiniluoto_critical_1999}
\citation{stroop_studies_1935}
\citation{melara_driven_2003}
\gdef \LT@ii {\LT@entry 
    {2}{40.04001pt}\LT@entry 
    {1}{119.21pt}\LT@entry 
    {1}{114.22002pt}}
\citation{meehl_why_1990}
\citation{cevolani_verisimilitude_2011,niiniluoto_verisimilitude_1998,oddie_content_2013}
\citation{psillos_scientific_1999}
\citation{baguley_standardized_2009}
\citation{cohen_things_1990}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Effect Sizes}{102}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{effectsize}{{6}{102}{Effect Sizes}{chapter.6}{}}
\citation{kelley_effect_2012}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Effect sizes}{103}{section.6.1}\protected@file@percent }
\newlabel{effect-sizes}{{6.1}{103}{Effect sizes}{section.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}The Facebook experiment}{103}{section.6.2}\protected@file@percent }
\newlabel{the-facebook-experiment}{{6.2}{103}{The Facebook experiment}{section.6.2}{}}
\citation{danziger_extraneous_2011}
\citation{glockner_irrational_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Proportion of rulings in favor of the prisoners by ordinal position. Circled points indicate the first decision in each of the three decision sessions; tick marks on x axis denote every third case; dotted line denotes food break. From Danziger, S., Levav, J., Avnaim-Pesso, L. (2011). Extraneous factors in judicial decisions. Proceedings of the National Academy of Sciences, 108(17), 6889--6892. \url  {https://doi.org/10.1073/PNAS.1018033108}\relax }}{105}{figure.caption.52}\protected@file@percent }
\newlabel{fig:hungryjudges}{{6.1}{105}{Proportion of rulings in favor of the prisoners by ordinal position. Circled points indicate the first decision in each of the three decision sessions; tick marks on x axis denote every third case; dotted line denotes food break. From Danziger, S., Levav, J., Avnaim-Pesso, L. (2011). Extraneous factors in judicial decisions. Proceedings of the National Academy of Sciences, 108(17), 6889--6892. \url {https://doi.org/10.1073/PNAS.1018033108}\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}The Hungry Judges study}{105}{section.6.3}\protected@file@percent }
\newlabel{the-hungry-judges-study}{{6.3}{105}{The Hungry Judges study}{section.6.3}{}}
\citation{richard_one_2003}
\citation{weinshall-margel_overlooked_2011,chatziathanasiou_beware_2022}
\citation{hilgard_maximal_2021}
\citation{rosenthal_contrasts_2000}
\citation{cohen_statistical_1988}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Standardised Mean Differences}{106}{section.6.4}\protected@file@percent }
\newlabel{cohend}{{6.4}{106}{Standardised Mean Differences}{section.6.4}{}}
\citation{lakens_calculating_2013}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces A vizualization of 2 groups (although the difference is hardly visible) representing d = 0.001.\relax }}{107}{figure.caption.53}\protected@file@percent }
\newlabel{fig:rpsychd1}{{6.2}{107}{A vizualization of 2 groups (although the difference is hardly visible) representing d = 0.001.\relax }{figure.caption.53}{}}
\citation{richard_one_2003}
\citation{mcgraw_common_1992}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces A vizualization of 2 groups representing d = 0.43.\relax }}{108}{figure.caption.54}\protected@file@percent }
\newlabel{fig:rpsychd2}{{6.3}{108}{A vizualization of 2 groups representing d = 0.43.\relax }{figure.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces A vizualization of 2 groups representing d = 2.\relax }}{109}{figure.caption.55}\protected@file@percent }
\newlabel{fig:rpsychd3}{{6.4}{109}{A vizualization of 2 groups representing d = 2.\relax }{figure.caption.55}{}}
\citation{maxwell_designing_2004}
\citation{cumming_understanding_2013}
\citation{mcgrath_when_2006}
\citation{chambers_past_2022,nosek_registered_2014}
\citation{open_science_collaboration_estimating_2015}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Interpreting effect sizes}{110}{section.6.5}\protected@file@percent }
\newlabel{interpreting-effect-sizes}{{6.5}{110}{Interpreting effect sizes}{section.6.5}{}}
\citation{primbs_are_2022,anvari_not_2021}
\citation{gotz_small_2022}
\citation{baguley_standardized_2009,funder_evaluating_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Screenshot from Guess the Correlation game (the correct answer is r = 0.24).\relax }}{111}{figure.caption.56}\protected@file@percent }
\newlabel{fig:guesscorrelation}{{6.5}{111}{Screenshot from Guess the Correlation game (the correct answer is r = 0.24).\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Correlations and Variance Explained}{111}{section.6.6}\protected@file@percent }
\newlabel{correlations-and-variance-explained}{{6.6}{111}{Correlations and Variance Explained}{section.6.6}{}}
\citation{funder_evaluating_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Screenshot from correlation effect size vizualization by Kristoffer Magnusson for r = 0.21.\relax }}{112}{figure.caption.57}\protected@file@percent }
\newlabel{fig:sharedvariance}{{6.6}{112}{Screenshot from correlation effect size vizualization by Kristoffer Magnusson for r = 0.21.\relax }{figure.caption.57}{}}
\citation{keppel_design_1991}
\citation{cohen_statistical_1988}
\citation{thompson_effect_2007}
\citation{okada_is_2013,albers_when_2018}
\citation{olejnik_generalized_2003}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Correcting for Bias}{114}{section.6.7}\protected@file@percent }
\newlabel{correcting-for-bias}{{6.7}{114}{Correcting for Bias}{section.6.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Effect Sizes for Interactions}{114}{section.6.8}\protected@file@percent }
\newlabel{effect-sizes-for-interactions}{{6.8}{114}{Effect Sizes for Interactions}{section.6.8}{}}
\citation{maxwell_designing_2004}
\citation{lakens_simulation-based_2021}
\citation{debruine_understanding_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Schematic illustration of a disordinal (or cross-over) and ordinal interaction.\relax }}{116}{figure.caption.58}\protected@file@percent }
\newlabel{fig:interactions}{{6.7}{116}{Schematic illustration of a disordinal (or cross-over) and ordinal interaction.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Disordinal (or cross-over) and ordinal interaction with means of 0 and 1, n = 50 per group, and an sd of 2.\relax }}{117}{figure.caption.59}\protected@file@percent }
\newlabel{fig:interactionplots}{{6.8}{117}{Disordinal (or cross-over) and ordinal interaction with means of 0 and 1, n = 50 per group, and an sd of 2.\relax }{figure.caption.59}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Test Yourself}{117}{section.6.9}\protected@file@percent }
\newlabel{test-yourself-4}{{6.9}{117}{Test Yourself}{section.6.9}{}}
\citation{richard_one_2003}
\citation{mcgrath_when_2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.1}Open Questions}{120}{subsection.6.9.1}\protected@file@percent }
\newlabel{open-questions-4}{{6.9.1}{120}{Open Questions}{subsection.6.9.1}{}}
\citation{spiegelhalter_art_2019}
\citation{kish_survey_1965}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Confidence Intervals}{121}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{confint}{{7}{121}{Confidence Intervals}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Population vs.\nobreakspace  {}Sample}{121}{section.7.1}\protected@file@percent }
\newlabel{population-vs.-sample}{{7.1}{121}{Population vs.~Sample}{section.7.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Example of a registry-based study in which the entire population was included in the study. From \url  {https://doi.org/10.1093/ije/dyab066}\relax }}{121}{figure.caption.60}\protected@file@percent }
\newlabel{fig:population}{{7.1}{121}{Example of a registry-based study in which the entire population was included in the study. From \url {https://doi.org/10.1093/ije/dyab066}\relax }{figure.caption.60}{}}
\citation{cousineau_superb_2019}
\citation{cumming_new_2014}
\citation{morey_fallacy_2016}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}What is a Confidence Interval?}{122}{section.7.2}\protected@file@percent }
\newlabel{what-is-a-confidence-interval}{{7.2}{122}{What is a Confidence Interval?}{section.7.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Interpreting a single confidence interval}{122}{section.7.3}\protected@file@percent }
\newlabel{singleCI}{{7.3}{122}{Interpreting a single confidence interval}{section.7.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Series of simulated point estimates and confidence intervals.\relax }}{123}{figure.caption.61}\protected@file@percent }
\newlabel{fig:cisim}{{7.2}{123}{Series of simulated point estimates and confidence intervals.\relax }{figure.caption.61}{}}
\citation{louis_effective_2009}
\citation{albers_credible_2018}
\citation{morey_fallacy_2016}
\citation{appelbaum_journal_2018}
\citation{lehmann_testing_2005}
\citation{steiger_beyond_2004}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}The relation between confidence intervals and \emph  {p}-values}{124}{section.7.4}\protected@file@percent }
\newlabel{relatCIp}{{7.4}{124}{\texorpdfstring {The relation between confidence intervals and \emph {p}-values}{The relation between confidence intervals and p-values}}{section.7.4}{}}
\citation{bauer_unifying_1996}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Meta-analysis of 4 studies.\relax }}{125}{figure.caption.62}\protected@file@percent }
\newlabel{fig:meta}{{7.3}{125}{Meta-analysis of 4 studies.\relax }{figure.caption.62}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}The Standard Error and 95\% Confidence Intervals}{126}{section.7.5}\protected@file@percent }
\newlabel{the-standard-error-and-95-confidence-intervals}{{7.5}{126}{The Standard Error and 95\% Confidence Intervals}{section.7.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Overlapping Confidence Intervals}{126}{section.7.6}\protected@file@percent }
\newlabel{overlapping-confidence-intervals}{{7.6}{126}{Overlapping Confidence Intervals}{section.7.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Means and 95\% confidence intervals of two independent groups and the mean difference between the two groups and its 95\% confidence interval.\relax }}{127}{figure.caption.63}\protected@file@percent }
\newlabel{fig:cioverlap}{{7.4}{127}{Means and 95\% confidence intervals of two independent groups and the mean difference between the two groups and its 95\% confidence interval.\relax }{figure.caption.63}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}Prediction Intervals}{127}{section.7.7}\protected@file@percent }
\newlabel{prediction-intervals}{{7.7}{127}{Prediction Intervals}{section.7.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces A comparison of a 95\% confidence interval (orange) and 95\% prediction interval (yellow).\relax }}{128}{figure.caption.64}\protected@file@percent }
\newlabel{fig:predictioninterval}{{7.5}{128}{A comparison of a 95\% confidence interval (orange) and 95\% prediction interval (yellow).\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}Capture Percentages}{128}{section.7.8}\protected@file@percent }
\newlabel{capture-percentages}{{7.8}{128}{Capture Percentages}{section.7.8}{}}
\citation{cumming_confidence_2006}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Meta-analysis of two simulated studies from the same population.\relax }}{129}{figure.caption.65}\protected@file@percent }
\newlabel{fig:metaci}{{7.6}{129}{Meta-analysis of two simulated studies from the same population.\relax }{figure.caption.65}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.9}Calculating Confidence Intervals around Standard Deviations.}{129}{section.7.9}\protected@file@percent }
\newlabel{calculating-confidence-intervals-around-standard-deviations.}{{7.9}{129}{Calculating Confidence Intervals around Standard Deviations}{section.7.9}{}}
\citation{cohen_earth_1994}
\citation{buchanan_mote_2017}
\citation{kelley_confidence_2007}
\citation{ben-shachar_effectsize_2020}
\@writefile{toc}{\contentsline {section}{\numberline {7.10}Computing Confidence Intervals around Effect Sizes}{130}{section.7.10}\protected@file@percent }
\newlabel{computing-confidence-intervals-around-effect-sizes}{{7.10}{130}{Computing Confidence Intervals around Effect Sizes}{section.7.10}{}}
\citation{delacre_why_2017}
\citation{delacre_why_2021}
\citation{cumming_introduction_2016}
\citation{okada_is_2013,albers_when_2018}
\@writefile{toc}{\contentsline {section}{\numberline {7.11}Test Yourself}{131}{section.7.11}\protected@file@percent }
\newlabel{test-yourself-5}{{7.11}{131}{Test Yourself}{section.7.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.7}{\ignorespaces Output from ESCI module in jamovi.\relax }}{132}{figure.caption.66}\protected@file@percent }
\newlabel{fig:escijamovi}{{7.7}{132}{Output from ESCI module in jamovi.\relax }{figure.caption.66}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.8}{\ignorespaces JASP menu option allows you to select Cohen's d and a CI around it.\relax }}{133}{figure.caption.67}\protected@file@percent }
\newlabel{fig:jasp1}{{7.8}{133}{JASP menu option allows you to select Cohen's d and a CI around it.\relax }{figure.caption.67}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.9}{\ignorespaces JASP output returns Cohen's d and the confidence interval around it.\relax }}{133}{figure.caption.68}\protected@file@percent }
\newlabel{fig:jasp2}{{7.9}{133}{JASP output returns Cohen's d and the confidence interval around it.\relax }{figure.caption.68}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.10}{\ignorespaces Meta-analysis of 4 studies.\relax }}{134}{figure.caption.69}\protected@file@percent }
\newlabel{fig:metaQ}{{7.10}{134}{Meta-analysis of 4 studies.\relax }{figure.caption.69}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.11.1}Open Questions}{140}{subsection.7.11.1}\protected@file@percent }
\newlabel{open-questions-5}{{7.11.1}{140}{Open Questions}{subsection.7.11.1}{}}
\citation{lakens_sample_2022}
\citation{hedges_power_2001}
\citation{valentine_how_2010}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Sample Size Justification}{141}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{power}{{8}{141}{Sample Size Justification}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Six Approaches to Justify Sample Sizes}{141}{section.8.1}\protected@file@percent }
\newlabel{six-approaches-to-justify-sample-sizes}{{8.1}{141}{Six Approaches to Justify Sample Sizes}{section.8.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Overview of possible justifications for the sample size in a study.\relax }}{141}{table.caption.70}\protected@file@percent }
\newlabel{tab:table-pow-just}{{8.1}{141}{Overview of possible justifications for the sample size in a study.\relax }{table.caption.70}{}}
\citation{lakens_sample_2022}
\citation{eckermann_value_2010}
\citation{detsky_using_1990}
\citation{wilson_practical_2015,halpern_sample_2001}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Six Ways to Evaluate Which Effect Sizes are Interesting}{142}{section.8.2}\protected@file@percent }
\newlabel{six-ways-to-evaluate-which-effect-sizes-are-interesting}{{8.2}{142}{Six Ways to Evaluate Which Effect Sizes are Interesting}{section.8.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.2}{\ignorespaces Overview of possible ways to evaluate which effect sizes are interesting.\relax }}{143}{table.caption.71}\protected@file@percent }
\newlabel{tab:table-effect-eval}{{8.2}{143}{Overview of possible ways to evaluate which effect sizes are interesting.\relax }{table.caption.71}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}The Value of Information}{143}{section.8.3}\protected@file@percent }
\newlabel{the-value-of-information}{{8.3}{143}{The Value of Information}{section.8.3}{}}
\citation{lenth_practical_2001}
\citation{bulus_bound_2021}
\citation{parker_sample_2003}
\citation{maxwell_ethics_2011}
\citation{halpern_continuing_2002}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}Measuring (Almost) the Entire Population}{144}{section.8.4}\protected@file@percent }
\newlabel{measuring-almost-the-entire-population}{{8.4}{144}{Measuring (Almost) the Entire Population}{section.8.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}Resource Constraints}{144}{section.8.5}\protected@file@percent }
\newlabel{resource-constraints}{{8.5}{144}{Resource Constraints}{section.8.5}{}}
\citation{cumming_new_2014}
\citation{ter_schure_accumulation_2019}
\@writefile{lot}{\contentsline {table}{\numberline {8.3}{\ignorespaces Overview of recommendations when reporting a sample size justification based on resource constraints.\relax }}{145}{table.caption.72}\protected@file@percent }
\newlabel{tab:table-pow-rec}{{8.3}{145}{Overview of recommendations when reporting a sample size justification based on resource constraints.\relax }{table.caption.72}{}}
\citation{westfall_statistical_2014}
\citation{ferron_power_1996,mcintosh_power_2021}
\citation{lakens_justify_2018}
\citation{lakens_too_2017}
\@writefile{toc}{\contentsline {section}{\numberline {8.6}A-priori Power Analysis}{146}{section.8.6}\protected@file@percent }
\newlabel{aprioripower}{{8.6}{146}{A-priori Power Analysis}{section.8.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Power curve for an independent \emph  {t} test with an effect of \emph  {d} = 0.5 and α = 0.05 as a function of the sample size.\relax }}{147}{figure.caption.73}\protected@file@percent }
\newlabel{fig:power-2}{{8.1}{147}{Power curve for an independent \emph {t} test with an effect of \emph {d} = 0.5 and α = 0.05 as a function of the sample size.\relax }{figure.caption.73}{}}
\citation{meyners_equivalence_2012,lakens_equivalence_2017,rogers_using_1993}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Null (\emph  {d} = 0, grey dashed line) and alternative (\emph  {d} = 0.5, solid black line) hypothesis, with α = 0.05 and n = 80 per group.\relax }}{148}{figure.caption.74}\protected@file@percent }
\newlabel{fig:power-3}{{8.2}{148}{Null (\emph {d} = 0, grey dashed line) and alternative (\emph {d} = 0.5, solid black line) hypothesis, with α = 0.05 and n = 80 per group.\relax }{figure.caption.74}{}}
\citation{morris_using_2019}
\citation{aberson_applied_2019,cohen_statistical_1988,murphy_statistical_2014,julious_sample_2004}
\citation{maxwell_sample_2008,brysbaert_how_2019,perugini_practical_2018,faul_gpower_2007,baguley_understanding_2004}
\citation{debruine_understanding_2021,lakens_simulation-based_2021,green_simr_2016,brysbaert_power_2018,westfall_statistical_2014,schoemann_determining_2017,kruschke_bayesian_2013}
\citation{lakens_equivalence_2018}
\citation{cumming_introduction_2016,maxwell_sample_2008,kruschke_rejecting_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces All details about the power analysis that is performed can be exported in G*Power.\relax }}{150}{figure.caption.75}\protected@file@percent }
\newlabel{fig:gpowprotocol}{{8.3}{150}{All details about the power analysis that is performed can be exported in G*Power.\relax }{figure.caption.75}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.4}{\ignorespaces Overview of recommendations when reporting an a-priori power analysis.\relax }}{150}{table.caption.76}\protected@file@percent }
\newlabel{tab:table-pow-rec-2}{{8.4}{150}{Overview of recommendations when reporting an a-priori power analysis.\relax }{table.caption.76}{}}
\citation{maxwell_sample_2008}
\citation{kelley_sample_2006}
\citation{kelley_confidence_2007}
\citation{morey_power_2020}
\citation{kruschke_rejecting_2018}
\citation{hilgard_maximal_2021}
\citation{berkeley_defence_1735}
\@writefile{toc}{\contentsline {section}{\numberline {8.7}Planning for Precision}{151}{section.8.7}\protected@file@percent }
\newlabel{planprecision}{{8.7}{151}{Planning for Precision}{section.8.7}{}}
\citation{wilson_vanvoorhis_understanding_2007}
\citation{green_how_1991}
\citation{simmons_false-positive_2011}
\citation{simmons_life_2013}
\citation{simonsohn_small_2015}
\@writefile{toc}{\contentsline {section}{\numberline {8.8}Heuristics}{152}{section.8.8}\protected@file@percent }
\newlabel{heuristics}{{8.8}{152}{Heuristics}{section.8.8}{}}
\citation{cook_assessing_2014}
\citation{keefe_defining_2013}
\citation{king_point_2011}
\citation{copay_understanding_2007}
\citation{lakens_equivalence_2018}
\@writefile{toc}{\contentsline {section}{\numberline {8.9}No Justification}{153}{section.8.9}\protected@file@percent }
\newlabel{no-justification}{{8.9}{153}{No Justification}{section.8.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.10}What is Your Inferential Goal?}{153}{section.8.10}\protected@file@percent }
\newlabel{what-is-your-inferential-goal}{{8.10}{153}{What is Your Inferential Goal?}{section.8.10}{}}
\citation{murphy_statistical_2014}
\citation{kelley_effect_2012}
\citation{brown_errors_1983,aberson_applied_2019,albers_when_2018,cascio_open_1983,dienes_using_2014,lenth_practical_2001}
\citation{cook_assessing_2014}
\citation{phillips_statistical_2001}
\@writefile{toc}{\contentsline {section}{\numberline {8.11}What is the Smallest Effect Size of Interest?}{154}{section.8.11}\protected@file@percent }
\newlabel{what-is-the-smallest-effect-size-of-interest}{{8.11}{154}{What is the Smallest Effect Size of Interest?}{section.8.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.12}The Minimal Statistically Detectable Effect}{154}{section.8.12}\protected@file@percent }
\newlabel{minimaldetectable}{{8.12}{154}{The Minimal Statistically Detectable Effect}{section.8.12}{}}
\citation{lakens_equivalence_2018}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces Critical effect size for an independent \emph  {t} test with n = 15 per group and \(\mitalpha \) = 0.05.\relax }}{155}{figure.caption.77}\protected@file@percent }
\newlabel{fig:power-effect1}{{8.4}{155}{Critical effect size for an independent \emph {t} test with n = 15 per group and \(\alpha \) = 0.05.\relax }{figure.caption.77}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces The critical correlation of a test based on a total sample size of 30 and α = 0.05 calculated in G*Power.\relax }}{156}{figure.caption.78}\protected@file@percent }
\newlabel{fig:gcrit2}{{8.5}{156}{The critical correlation of a test based on a total sample size of 30 and α = 0.05 calculated in G*Power.\relax }{figure.caption.78}{}}
\citation{kenny_unappreciated_2019,olsson-collentine_heterogeneity_2020}
\@writefile{toc}{\contentsline {section}{\numberline {8.13}What is the Expected Effect Size?}{157}{section.8.13}\protected@file@percent }
\newlabel{what-is-the-expected-effect-size}{{8.13}{157}{What is the Expected Effect Size?}{section.8.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.14}Using an Estimate from a Meta-Analysis}{157}{section.8.14}\protected@file@percent }
\newlabel{using-an-estimate-from-a-meta-analysis}{{8.14}{157}{Using an Estimate from a Meta-Analysis}{section.8.14}{}}
\citation{carter_correcting_2019}
\citation{lakens_simulation-based_2021}
\citation{leon_role_2011}
\@writefile{lot}{\contentsline {table}{\numberline {8.5}{\ignorespaces Overview of recommendations when justifying the use of a meta-analytic effect size estimate for a power analysis.\relax }}{158}{table.caption.79}\protected@file@percent }
\newlabel{tab:tablemetajust}{{8.5}{158}{Overview of recommendations when justifying the use of a meta-analytic effect size estimate for a power analysis.\relax }{table.caption.79}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.15}Using an Estimate from a Previous Study}{158}{section.8.15}\protected@file@percent }
\newlabel{using-an-estimate-from-a-previous-study}{{8.15}{158}{Using an Estimate from a Previous Study}{section.8.15}{}}
\citation{richardson_eta_2011}
\citation{albers_when_2018}
\citation{taylor_bias_1996}
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces Distribution of partial eta squared under the null hypothesis (dotted grey curve) and a medium true effect of 0.0588 (solid black curve) for 3 groups with 25 observations.\relax }}{159}{figure.caption.80}\protected@file@percent }
\newlabel{fig:followupbias}{{8.6}{159}{Distribution of partial eta squared under the null hypothesis (dotted grey curve) and a medium true effect of 0.0588 (solid black curve) for 3 groups with 25 observations.\relax }{figure.caption.80}{}}
\citation{anderson_sample-size_2017}
\citation{perugini_safeguard_2014}
\citation{teare_sample_2014}
\citation{tversky_features_1977}
\@writefile{lot}{\contentsline {table}{\numberline {8.6}{\ignorespaces Overview of recommendations when justifying the use of an effect size estimate from a single study.\relax }}{160}{table.caption.81}\protected@file@percent }
\newlabel{tab:table-es-just}{{8.6}{160}{Overview of recommendations when justifying the use of an effect size estimate from a single study.\relax }{table.caption.81}{}}
\citation{kelley_confidence_2007}
\citation{cumming_understanding_2013}
\citation{smithson_confidence_2003}
\citation{albers_credible_2018,kruschke_bayesian_2011}
\citation{richard_one_2003}
\@writefile{toc}{\contentsline {section}{\numberline {8.16}Using an Estimate from a Theoretical Model}{161}{section.8.16}\protected@file@percent }
\newlabel{using-an-estimate-from-a-theoretical-model}{{8.16}{161}{Using an Estimate from a Theoretical Model}{section.8.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.17}Compute the Width of the Confidence Interval around the Effect Size}{161}{section.8.17}\protected@file@percent }
\newlabel{compute-the-width-of-the-confidence-interval-around-the-effect-size}{{8.17}{161}{Compute the Width of the Confidence Interval around the Effect Size}{section.8.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces Central (black dashed line) and 2 non-central (dark grey and light grey dashed lines) \emph  {t} distributions; ncp = noncentrality parameter.\relax }}{162}{figure.caption.82}\protected@file@percent }
\newlabel{fig:noncentralt}{{8.7}{162}{Central (black dashed line) and 2 non-central (dark grey and light grey dashed lines) \emph {t} distributions; ncp = noncentrality parameter.\relax }{figure.caption.82}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.18}Plot a Sensitivity Power Analysis}{162}{section.8.18}\protected@file@percent }
\newlabel{plot-a-sensitivity-power-analysis}{{8.18}{162}{Plot a Sensitivity Power Analysis}{section.8.18}{}}
\citation{bacchetti_current_2010}
\citation{cook_assessing_2014,correll_avoid_2020}
\citation{funder_evaluating_2019}
\citation{brysbaert_how_2019}
\citation{bosco_correlational_2015,hill_empirical_2008,kraft_interpreting_2020,lovakov_empirically_2021,funder_evaluating_2019}
\@writefile{toc}{\contentsline {section}{\numberline {8.19}The Distribution of Effect Sizes in a Research Area}{163}{section.8.19}\protected@file@percent }
\newlabel{the-distribution-of-effect-sizes-in-a-research-area}{{8.19}{163}{The Distribution of Effect Sizes in a Research Area}{section.8.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.8}{\ignorespaces Sensitivity power analysis in G*Power software.\relax }}{164}{figure.caption.83}\protected@file@percent }
\newlabel{fig:gsens0}{{8.8}{164}{Sensitivity power analysis in G*Power software.\relax }{figure.caption.83}{}}
\citation{scheel_why_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {8.9}{\ignorespaces Plot of the effect size against the desired power when n = 15 per group and alpha = 0.05.\relax }}{165}{figure.caption.84}\protected@file@percent }
\newlabel{fig:gsens1}{{8.9}{165}{Plot of the effect size against the desired power when n = 15 per group and alpha = 0.05.\relax }{figure.caption.84}{}}
\citation{zumbo_note_1998}
\citation{lenth_post_2007}
\citation{jaeschke_measurement_1989}
\citation{neyman_problem_1933}
\citation{cohen_statistical_1988}
\@writefile{toc}{\contentsline {section}{\numberline {8.20}Additional Considerations When Designing an Informative Study}{166}{section.8.20}\protected@file@percent }
\newlabel{additional-considerations-when-designing-an-informative-study}{{8.20}{166}{Additional Considerations When Designing an Informative Study}{section.8.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.21}Compromise Power Analysis}{166}{section.8.21}\protected@file@percent }
\newlabel{compromise-power-analysis}{{8.21}{166}{Compromise Power Analysis}{section.8.21}{}}
\citation{cascio_open_1983}
\citation{erdfelder_gpower_1996}
\citation{faul_gpower_2007}
\citation{winer_statistical_1962}
\citation{maier_justify_2022,murphy_statistical_2014,miller_quest_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {8.10}{\ignorespaces Compromise power analysis in G*Power.\relax }}{168}{figure.caption.85}\protected@file@percent }
\newlabel{fig:gpowcompromise}{{8.10}{168}{Compromise power analysis in G*Power.\relax }{figure.caption.85}{}}
\citation{jeffreys_theory_1939,good_bayesnon-bayes_1992}
\citation{maier_justify_2022}
\citation{zumbo_note_1998,lenth_post_2007}
\citation{hoenig_abuse_2001}
\@writefile{lot}{\contentsline {table}{\numberline {8.7}{\ignorespaces Overview of recommendations when justifying error rates based on a compromise power analysis.\relax }}{169}{table.caption.86}\protected@file@percent }
\newlabel{tab:table-compromise-just}{{8.7}{169}{Overview of recommendations when justifying error rates based on a compromise power analysis.\relax }{table.caption.86}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.22}What to do if Your Editor Asks for Post-hoc Power?}{169}{section.8.22}\protected@file@percent }
\newlabel{posthocpower}{{8.22}{169}{What to do if Your Editor Asks for Post-hoc Power?}{section.8.22}{}}
\citation{lenth_post_2007}
\citation{hoenig_abuse_2001,lenth_post_2007,yuan_post_2005,schulz_sample_2005}
\@writefile{lof}{\contentsline {figure}{\numberline {8.11}{\ignorespaces Relationship between \emph  {p} values and power for an independent \emph  {t} test with α = 0.05 and n = 10.\relax }}{170}{figure.caption.87}\protected@file@percent }
\newlabel{fig:obs-power-plot-2}{{8.11}{170}{Relationship between \emph {p} values and power for an independent \emph {t} test with α = 0.05 and n = 10.\relax }{figure.caption.87}{}}
\citation{wassmer_group_2016,proschan_statistical_2006}
\citation{dodge_method_1929}
\citation{wald_sequential_1945}
\citation{westberg_combining_1985}
\citation{jennison_group_2000}
\citation{schonbrodt_sequential_2017}
\citation{grunwald_safe_2019}
\citation{schnuerch_controlling_2020}
\citation{wassmer_group_2016}
\citation{ter_schure_accumulation_2019}
\citation{lakens_performing_2014}
\citation{cho_is_2013}
\citation{rice_heads_1994}
\@writefile{toc}{\contentsline {section}{\numberline {8.23}Sequential Analyses}{171}{section.8.23}\protected@file@percent }
\newlabel{sequentialsamplesize}{{8.23}{171}{Sequential Analyses}{section.8.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.24}Increasing Power Without Increasing the Sample Size}{171}{section.8.24}\protected@file@percent }
\newlabel{increasing-power-without-increasing-the-sample-size}{{8.24}{171}{Increasing Power Without Increasing the Sample Size}{section.8.24}{}}
\citation{cascio_open_1983,mudge_setting_2012,murphy_statistical_2014,miller_quest_2019}
\citation{field_minimizing_2004,baguley_understanding_2004}
\citation{maxwell_designing_2017}
\citation{maxwell_designing_2017}
\citation{allison_power_1997,bausell_power_2002,hallahan_statistical_1996}
\citation{williams_impact_1995}
\citation{meyvis_increasing_2018}
\citation{gupta_intention_2011}
\@writefile{lof}{\contentsline {figure}{\numberline {8.12}{\ignorespaces Distributions of two dependent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.\relax }}{173}{figure.caption.88}\protected@file@percent }
\newlabel{fig:plot-1}{{8.12}{173}{Distributions of two dependent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.\relax }{figure.caption.88}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.13}{\ignorespaces Distributions of two independent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.7.\relax }}{173}{figure.caption.89}\protected@file@percent }
\newlabel{fig:plot-4}{{8.13}{173}{Distributions of two independent groups with means 100 and 106 and a standard deviation of 15, distribution of the differences, and correlation of 0.7.\relax }{figure.caption.89}{}}
\citation{baguley_standardized_2009,lenth_practical_2001}
\citation{westfall_statistical_2014,debruine_understanding_2021}
\citation{parsons_psychological_2019}
\citation{smithson_confidence_2003}
\citation{wittes_role_1990}
\citation{friede_sample_2006,proschan_two-stage_2005}
\citation{chang_adaptive_2016}
\@writefile{toc}{\contentsline {section}{\numberline {8.25}Know Your Measure}{174}{section.8.25}\protected@file@percent }
\newlabel{knowyourmeasure}{{8.25}{174}{Know Your Measure}{section.8.25}{}}
\citation{johnson_revised_2013}
\citation{mullan_town_1985}
\citation{fried_method_1993}
\citation{morse_significance_1995}
\citation{marshall_does_2013}
\@writefile{toc}{\contentsline {section}{\numberline {8.26}Conventions as meta-heuristics}{175}{section.8.26}\protected@file@percent }
\newlabel{conventions-as-meta-heuristics}{{8.26}{175}{Conventions as meta-heuristics}{section.8.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.27}Sample Size Justification in Qualitative Research}{175}{section.8.27}\protected@file@percent }
\newlabel{sample-size-justification-in-qualitative-research}{{8.27}{175}{Sample Size Justification in Qualitative Research}{section.8.27}{}}
\citation{fugard_supporting_2015}
\citation{rijnsoever_i_2017}
\citation{button_power_2013,brown_errors_1983,halpern_continuing_2002}
\citation{lindsay_replication_2015,sedlmeier_studies_1989,fraley_n-pact_2014,button_power_2013}
\citation{moshontz_psychological_2018}
\@writefile{toc}{\contentsline {section}{\numberline {8.28}Discussion}{176}{section.8.28}\protected@file@percent }
\newlabel{discussion}{{8.28}{176}{Discussion}{section.8.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.29}Test Yourself}{177}{section.8.29}\protected@file@percent }
\newlabel{test-yourself-6}{{8.29}{177}{Test Yourself}{section.8.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.29.1}Open Questions}{179}{subsection.8.29.1}\protected@file@percent }
\newlabel{open-questions-6}{{8.29.1}{179}{Open Questions}{subsection.8.29.1}{}}
\citation{altman_statistics_1995}
\citation{dienes_using_2014}
\citation{hodges_testing_1954}
\citation{nunnally_place_1960}
\citation{bauer_unifying_1996}
\citation{kruschke_bayesian_2013}
\citation{cribbie_recommendations_2004,levine_communication_2008,hoenig_abuse_2001,rogers_using_1993,quertemont_how_2011}
\citation{bem_feeling_2011}
\citation{anderson_theres_2016,lakens_equivalence_2017,simonsohn_small_2015}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Equivalence Testing and Interval Hypotheses}{180}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{equivalencetest}{{9}{180}{Equivalence Testing and Interval Hypotheses}{chapter.9}{}}
\citation{nickerson_null_2000}
\citation{lakens_practical_2021}
\citation{murphy_testing_1999}
\citation{murphy_statistical_2014}
\citation{meehl_appraising_1990,orben_crud_2020}
\citation{ferguson_providing_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Two-sided null hypothesis test (A), interval hypothesis test (B), equivalence test (C) and minimum effect test (D).\relax }}{182}{figure.caption.90}\protected@file@percent }
\newlabel{fig:intervaltest}{{9.1}{182}{Two-sided null hypothesis test (A), interval hypothesis test (B), equivalence test (C) and minimum effect test (D).\relax }{figure.caption.90}{}}
\citation{schumi_through_2011,mazzolari_myths_2022}
\citation{hauck_new_1984,westlake_use_1972}
\citation{schuirmann_comparison_1987,seaman_equivalence_1998,wellek_testing_2010}
\citation{parkhurst_statistical_2001}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Equivalence tests}{183}{section.9.1}\protected@file@percent }
\newlabel{equivalence-tests}{{9.1}{183}{Equivalence tests}{section.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces The mean difference and its confidence interval plotted below the \emph  {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5.\relax }}{184}{figure.caption.91}\protected@file@percent }
\newlabel{fig:tdistequivalence}{{9.2}{184}{The mean difference and its confidence interval plotted below the \emph {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5.\relax }{figure.caption.91}{}}
\citation{delacre_why_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }}{186}{figure.caption.92}\protected@file@percent }
\newlabel{fig:ciequivalence1}{{9.3}{186}{The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }{figure.caption.92}{}}
\citation{schweder_confidence_2016}
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }}{187}{figure.caption.93}\protected@file@percent }
\newlabel{fig:ciequivalence2}{{9.4}{187}{The mean difference and its confidence interval for an equivalence test with an equivalence range of -0.5 and 0.5.\relax }{figure.caption.93}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Reporting Equivalence Tests}{188}{section.9.2}\protected@file@percent }
\newlabel{reporting-equivalence-tests}{{9.2}{188}{Reporting Equivalence Tests}{section.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces The mean difference and its confidence interval plotted below the \emph  {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5 when performing a minimum effect test.\relax }}{189}{figure.caption.94}\protected@file@percent }
\newlabel{fig:tmet}{{9.5}{189}{The mean difference and its confidence interval plotted below the \emph {t}-distributions used to perform the two-one-sided tests against -0.5 and 0.5 when performing a minimum effect test.\relax }{figure.caption.94}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Minimum Effect Tests}{189}{section.9.3}\protected@file@percent }
\newlabel{MET}{{9.3}{189}{Minimum Effect Tests}{section.9.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Power Analysis for Interval Hypothesis Tests}{190}{section.9.4}\protected@file@percent }
\newlabel{power-analysis-for-interval-hypothesis-tests}{{9.4}{190}{Power Analysis for Interval Hypothesis Tests}{section.9.4}{}}
\citation{kruschke_bayesian_2013}
\citation{kruschke_bayesian_2017}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}The Bayesian ROPE procedure}{192}{section.9.5}\protected@file@percent }
\newlabel{ROPE}{{9.5}{192}{The Bayesian ROPE procedure}{section.9.5}{}}
\citation{kruschke_doing_2014}
\citation{mcelreath_statistical_2016}
\citation{gosset_application_1904}
\citation{king_point_2011}
\citation{popper_logic_2002}
\@writefile{toc}{\contentsline {section}{\numberline {9.6}Which interval width should be used?}{194}{section.9.6}\protected@file@percent }
\newlabel{whichinterval}{{9.6}{194}{Which interval width should be used?}{section.9.6}{}}
\citation{ferguson_vast_2012}
\citation{burriss_changes_2015}
\@writefile{toc}{\contentsline {section}{\numberline {9.7}Setting the Smallest Effect Size of Interest}{195}{section.9.7}\protected@file@percent }
\newlabel{sesoi}{{9.7}{195}{Setting the Smallest Effect Size of Interest}{section.9.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.8}Specifying a SESOI based on theory}{195}{section.9.8}\protected@file@percent }
\newlabel{specifying-a-sesoi-based-on-theory}{{9.8}{195}{Specifying a SESOI based on theory}{section.9.8}{}}
\citation{jaeschke_measurement_1989,norman_truly_2004,king_point_2011}
\citation{button_minimal_2015}
\citation{anvari_using_2021}
\citation{ball_effects_2002}
\citation{viamonte_cost-benefit_2006}
\citation{mrozek_what_2002}
\citation{abelson_value_2003}
\@writefile{toc}{\contentsline {section}{\numberline {9.9}Anchor based methods to set a SESOI}{196}{section.9.9}\protected@file@percent }
\newlabel{anchor-based-methods-to-set-a-sesoi}{{9.9}{196}{Anchor based methods to set a SESOI}{section.9.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.10}Specifying a SESOI based on a cost-benefit analysis}{196}{section.9.10}\protected@file@percent }
\newlabel{specifying-a-sesoi-based-on-a-cost-benefit-analysis}{{9.10}{196}{Specifying a SESOI based on a cost-benefit analysis}{section.9.10}{}}
\citation{anderson_theres_2016}
\citation{simonsohn_small_2015}
\@writefile{toc}{\contentsline {section}{\numberline {9.11}Specifying the SESOI using the small telescopes approach}{197}{section.9.11}\protected@file@percent }
\newlabel{specifying-the-sesoi-using-the-small-telescopes-approach}{{9.11}{197}{Specifying the SESOI using the small telescopes approach}{section.9.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces Screenshot illustrating a sensitivity power analysis in G*Power to compute the effect size an original study had 33\% power to detect.\relax }}{199}{figure.caption.95}\protected@file@percent }
\newlabel{fig:smalltelpower}{{9.6}{199}{Screenshot illustrating a sensitivity power analysis in G*Power to compute the effect size an original study had 33\% power to detect.\relax }{figure.caption.95}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces Example used in Simonsohn (2015) of an original study and two replication studies.\relax }}{201}{figure.caption.96}\protected@file@percent }
\newlabel{fig:simonsohnexample}{{9.7}{201}{Example used in Simonsohn (2015) of an original study and two replication studies.\relax }{figure.caption.96}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.12}Setting the Smallest Effect Size of Interest to the Minimal Statistically Detectable Effect}{201}{section.9.12}\protected@file@percent }
\newlabel{setting-the-smallest-effect-size-of-interest-to-the-minimal-statistically-detectable-effect}{{9.12}{201}{Setting the Smallest Effect Size of Interest to the Minimal Statistically Detectable Effect}{section.9.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }}{202}{figure.caption.97}\protected@file@percent }
\newlabel{fig:distpowerplot1}{{9.8}{202}{Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }{figure.caption.97}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }}{202}{figure.caption.98}\protected@file@percent }
\newlabel{fig:distpowerplot2}{{9.9}{202}{Null and alternative distribution with Type 1 and Type 2 error indicating the smallest effect size that will be statistically significant with n = 50 per condition.\relax }{figure.caption.98}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.13}Test Yourself}{204}{section.9.13}\protected@file@percent }
\newlabel{test-yourself-7}{{9.13}{204}{Test Yourself}{section.9.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.1}Questions about equivalence tests}{204}{subsection.9.13.1}\protected@file@percent }
\newlabel{questions-about-equivalence-tests}{{9.13.1}{204}{Questions about equivalence tests}{subsection.9.13.1}{}}
\citation{hyde_gender_2008}
\gdef \LT@iii {\LT@entry 
    {2}{45.1pt}\LT@entry 
    {2}{71.66pt}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.2}Questions about the small telescopes approach}{208}{subsection.9.13.2}\protected@file@percent }
\newlabel{questions-about-the-small-telescopes-approach}{{9.13.2}{208}{Questions about the small telescopes approach}{subsection.9.13.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.3}Questions about specifying the SESOI as the Minimal Statistically Detectable Effect}{209}{subsection.9.13.3}\protected@file@percent }
\newlabel{questions-about-specifying-the-sesoi-as-the-minimal-statistically-detectable-effect}{{9.13.3}{209}{Questions about specifying the SESOI as the Minimal Statistically Detectable Effect}{subsection.9.13.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces Illustration of the criticial \emph  {F}-value for two groups, 50 observations per group, and an alpha level of 0.05.\relax }}{210}{figure.caption.99}\protected@file@percent }
\newlabel{fig:critf}{{9.10}{210}{Illustration of the criticial \emph {F}-value for two groups, 50 observations per group, and an alpha level of 0.05.\relax }{figure.caption.99}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.13.4}Open Questions}{211}{subsection.9.13.4}\protected@file@percent }
\newlabel{open-questions-7}{{9.13.4}{211}{Open Questions}{subsection.9.13.4}{}}
\citation{wassmer_group_2016}
\citation{dodge_method_1929}
\citation{wald_sequential_1945}
\citation{proschan_statistical_2006,jennison_group_2000,wassmer_group_2016}
\citation{pocock_group_1977}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Sequential Analysis}{212}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{sequential}{{10}{212}{Sequential Analysis}{chapter.10}{}}
\citation{armitage_repeated_1969}
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces Screenshot of the planned interim analyses examining the safety and Efficacy of the BNT162b2 mRNA Covid-19 Vaccine.\relax }}{213}{figure.caption.100}\protected@file@percent }
\newlabel{fig:interim}{{10.1}{213}{Screenshot of the planned interim analyses examining the safety and Efficacy of the BNT162b2 mRNA Covid-19 Vaccine.\relax }{figure.caption.100}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Choosing alpha levels for sequential analyses.}{213}{section.10.1}\protected@file@percent }
\newlabel{choosing-alpha-levels-for-sequential-analyses.}{{10.1}{213}{Choosing alpha levels for sequential analyses}{section.10.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}The Pocock correction}{214}{section.10.2}\protected@file@percent }
\newlabel{the-pocock-correction}{{10.2}{214}{The Pocock correction}{section.10.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.3}Comparing Spending Functions}{215}{section.10.3}\protected@file@percent }
\newlabel{comparing-spending-functions}{{10.3}{215}{Comparing Spending Functions}{section.10.3}{}}
\citation{proschan_statistical_2006}
\citation{lan_discrete_1983}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces Plot of critical boundaries at each look for a 2 look design with a Pocock correction.\relax }}{216}{figure.caption.101}\protected@file@percent }
\newlabel{fig:boundplot1}{{10.2}{216}{Plot of critical boundaries at each look for a 2 look design with a Pocock correction.\relax }{figure.caption.101}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces Screenshot of rpact Shiny app.\relax }}{217}{figure.caption.102}\protected@file@percent }
\newlabel{fig:rpactshiny}{{10.3}{217}{Screenshot of rpact Shiny app.\relax }{figure.caption.102}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.4}Alpha spending functions}{217}{section.10.4}\protected@file@percent }
\newlabel{alpha-spending-functions}{{10.4}{217}{Alpha spending functions}{section.10.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.4}{\ignorespaces Four different spending functions for 3 looks: O'Brien-Fleming (OF), Pocock (P), Haybittle-Peto (HP), Wang-Tsiatis (WT).\relax }}{218}{figure.caption.103}\protected@file@percent }
\newlabel{fig:fourspendingfunctions}{{10.4}{218}{Four different spending functions for 3 looks: O'Brien-Fleming (OF), Pocock (P), Haybittle-Peto (HP), Wang-Tsiatis (WT).\relax }{figure.caption.103}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.5}Updating boundaries during a study}{218}{section.10.5}\protected@file@percent }
\newlabel{updating-boundaries-during-a-study}{{10.5}{218}{Updating boundaries during a study}{section.10.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.5}{\ignorespaces Comparison of Pocock (P) and O'Brien-Fleming correction (OF), Pocock-like (asP) and O'Brien-Fleming like (asOF) alpha spending functions, for 5 looks.\relax }}{219}{figure.caption.104}\protected@file@percent }
\newlabel{fig:seq-comparison}{{10.5}{219}{Comparison of Pocock (P) and O'Brien-Fleming correction (OF), Pocock-like (asP) and O'Brien-Fleming like (asOF) alpha spending functions, for 5 looks.\relax }{figure.caption.104}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.6}Sample Size for Sequential Designs}{221}{section.10.6}\protected@file@percent }
\newlabel{sample-size-for-sequential-designs}{{10.6}{221}{Sample Size for Sequential Designs}{section.10.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.6}{\ignorespaces Power curve for a sequential design with 2 looks.\relax }}{224}{figure.caption.105}\protected@file@percent }
\newlabel{fig:powerseq}{{10.6}{224}{Power curve for a sequential design with 2 looks.\relax }{figure.caption.105}{}}
\citation{spiegelhalter_monitoring_1986}
\citation{wassmer_group_2016}
\@writefile{toc}{\contentsline {section}{\numberline {10.7}Stopping for futility}{226}{section.10.7}\protected@file@percent }
\newlabel{stopping-for-futility}{{10.7}{226}{Stopping for futility}{section.10.7}{}}
\citation{jennison_group_2000}
\@writefile{lof}{\contentsline {figure}{\numberline {10.7}{\ignorespaces Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) when the observed effect is in the opposite direction.\relax }}{227}{figure.caption.106}\protected@file@percent }
\newlabel{fig:futility1}{{10.7}{227}{Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) when the observed effect is in the opposite direction.\relax }{figure.caption.106}{}}
\citation{proschan_statistical_2006}
\citation{schonbrodt_sequential_2017}
\@writefile{toc}{\contentsline {section}{\numberline {10.8}Reporting the results of a sequential analysis}{228}{section.10.8}\protected@file@percent }
\newlabel{reporting-the-results-of-a-sequential-analysis}{{10.8}{228}{Reporting the results of a sequential analysis}{section.10.8}{}}
\citation{cook_p-value_2002}
\citation{proschan_statistical_2006}
\citation{wassmer_group_2016}
\citation{dupont_sequential_1983}
\citation{lakens_why_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {10.8}{\ignorespaces Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) based on a Pocock-type beta-spending function.\relax }}{229}{figure.caption.107}\protected@file@percent }
\newlabel{fig:futility2}{{10.8}{229}{Pocock-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) based on a Pocock-type beta-spending function.\relax }{figure.caption.107}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.9}{\ignorespaces Power curve for a sequential design with 2 looks with stopping for futility.\relax }}{230}{figure.caption.108}\protected@file@percent }
\newlabel{fig:powerseq2}{{10.9}{230}{Power curve for a sequential design with 2 looks with stopping for futility.\relax }{figure.caption.108}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10.9}Test Yourself}{232}{section.10.9}\protected@file@percent }
\newlabel{test-yourself-8}{{10.9}{232}{Test Yourself}{section.10.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.9.1}Open Questions}{235}{subsection.10.9.1}\protected@file@percent }
\newlabel{open-questions-8}{{10.9.1}{235}{Open Questions}{subsection.10.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10.10}{\ignorespaces Example of O'Brien-Fleming-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) with a 5\% Type 1 and Type 2 error.\relax }}{236}{figure.caption.109}\protected@file@percent }
\newlabel{fig:futilityq13}{{10.10}{236}{Example of O'Brien-Fleming-type boundaries for 3 looks to stop when rejecting \(H_0\) (red line) or to stop for futility (blue line) with a 5\% Type 1 and Type 2 error.\relax }{figure.caption.109}{}}
\citation{cohen_earth_1994}
\citation{borenstein_introduction_2009}
\citation{viechtbauer_conducting_2010}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Meta-analysis}{237}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{meta}{{11}{237}{Meta-analysis}{chapter.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.1}Random Variation}{237}{section.11.1}\protected@file@percent }
\newlabel{random-variation}{{11.1}{237}{Random Variation}{section.11.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces Simulation of 10 random datapoints with mean = 100 and sd = 15 in the population.\relax }}{238}{figure.caption.110}\protected@file@percent }
\newlabel{fig:plot-hist-iq-1}{{11.1}{238}{Simulation of 10 random datapoints with mean = 100 and sd = 15 in the population.\relax }{figure.caption.110}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces 100 random datapoints with mean = 100 and sd = 15 in the population.\relax }}{240}{figure.caption.111}\protected@file@percent }
\newlabel{fig:plot-hist-iq-2}{{11.2}{240}{100 random datapoints with mean = 100 and sd = 15 in the population.\relax }{figure.caption.111}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces 1000 random datapoints with mean = 100 and sd = 15 in the population.\relax }}{240}{figure.caption.112}\protected@file@percent }
\newlabel{fig:plot-hist-iq-3}{{11.3}{240}{1000 random datapoints with mean = 100 and sd = 15 in the population.\relax }{figure.caption.112}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.4}{\ignorespaces Simulation of 10 observations in two independent groups.\relax }}{241}{figure.caption.113}\protected@file@percent }
\newlabel{fig:plot-group1}{{11.4}{241}{Simulation of 10 observations in two independent groups.\relax }{figure.caption.113}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.5}{\ignorespaces Four simulated samples of independent groups.\relax }}{242}{figure.caption.114}\protected@file@percent }
\newlabel{fig:plot-group2}{{11.5}{242}{Four simulated samples of independent groups.\relax }{figure.caption.114}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.6}{\ignorespaces Simulated sample of 250 independent observations.\relax }}{242}{figure.caption.115}\protected@file@percent }
\newlabel{fig:plotgroup3}{{11.6}{242}{Simulated sample of 250 independent observations.\relax }{figure.caption.115}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.7}{\ignorespaces Correlation based on 30 pairs.\relax }}{243}{figure.caption.116}\protected@file@percent }
\newlabel{fig:plot-cor1}{{11.7}{243}{Correlation based on 30 pairs.\relax }{figure.caption.116}{}}
\citation{maxwell_sample_2008}
\@writefile{lof}{\contentsline {figure}{\numberline {11.8}{\ignorespaces Correlation based on 300 pairs.\relax }}{244}{figure.caption.117}\protected@file@percent }
\newlabel{fig:plot-cor2}{{11.8}{244}{Correlation based on 300 pairs.\relax }{figure.caption.117}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.2}A single study meta-analysis}{244}{section.11.2}\protected@file@percent }
\newlabel{a-single-study-meta-analysis}{{11.2}{244}{A single study meta-analysis}{section.11.2}{}}
\citation{borenstein_introduction_2009}
\citation{buchanan_mote_2017}
\citation{cooper_handbook_2009}
\citation{freiman_importance_1978}
\@writefile{lof}{\contentsline {figure}{\numberline {11.9}{\ignorespaces First version of a forest plot by Freiman and colleagues, 1978 (image from \url  {https://www.jameslindlibrary.org/freiman-ja-chalmers-tc-smith-h-kuebler-rr-1978/}).\relax }}{247}{figure.caption.118}\protected@file@percent }
\newlabel{fig:freiman1978}{{11.9}{247}{First version of a forest plot by Freiman and colleagues, 1978 (image from \url {https://www.jameslindlibrary.org/freiman-ja-chalmers-tc-smith-h-kuebler-rr-1978/}).\relax }{figure.caption.118}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.10}{\ignorespaces Forest plot for a single study.\relax }}{248}{figure.caption.119}\protected@file@percent }
\newlabel{fig:metaforest}{{11.10}{248}{Forest plot for a single study.\relax }{figure.caption.119}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.3}Simulating meta-analyses of mean standardized differences}{248}{section.11.3}\protected@file@percent }
\newlabel{simulating-meta-analyses-of-mean-standardized-differences}{{11.3}{248}{Simulating meta-analyses of mean standardized differences}{section.11.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.11}{\ignorespaces Forest plot for 12 simulated studies.\relax }}{249}{figure.caption.120}\protected@file@percent }
\newlabel{fig:meta-sim}{{11.11}{249}{Forest plot for 12 simulated studies.\relax }{figure.caption.120}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.4}Fixed Effect vs Random Effects}{250}{section.11.4}\protected@file@percent }
\newlabel{fixed-effect-vs-random-effects}{{11.4}{250}{Fixed Effect vs Random Effects}{section.11.4}{}}
\citation{borenstein_introduction_2009}
\gdef \LT@iv {\LT@entry 
    {2}{63.79001pt}\LT@entry 
    {1}{42.32pt}\LT@entry 
    {1}{40.18001pt}\LT@entry 
    {2}{16.12999pt}}
\gdef \LT@v {\LT@entry 
    {2}{63.79001pt}\LT@entry 
    {1}{42.32pt}\LT@entry 
    {1}{40.18001pt}\LT@entry 
    {2}{20.0pt}}
\@writefile{toc}{\contentsline {section}{\numberline {11.5}Simulating meta-analyses for dichotomous outcomes}{251}{section.11.5}\protected@file@percent }
\newlabel{simulating-meta-analyses-for-dichotomous-outcomes}{{11.5}{251}{Simulating meta-analyses for dichotomous outcomes}{section.11.5}{}}
\citation{huedo-medina_assessing_2006}
\citation{rucker_undue_2008}
\citation{harrer_doing_2021}
\@writefile{toc}{\contentsline {section}{\numberline {11.6}Heterogeneity}{254}{section.11.6}\protected@file@percent }
\newlabel{heterogeneity}{{11.6}{254}{Heterogeneity}{section.11.6}{}}
\citation{bryan_behavioural_2021}
\citation{kenny_unappreciated_2019}
\citation{olsson-collentine_heterogeneity_2020}
\citation{linden_heterogeneity_2021}
\citation{eysenck_exercise_1978}
\@writefile{toc}{\contentsline {section}{\numberline {11.7}Strengths and weaknesses of meta-analysis}{256}{section.11.7}\protected@file@percent }
\newlabel{strengths-and-weaknesses-of-meta-analysis}{{11.7}{256}{Strengths and weaknesses of meta-analysis}{section.11.7}{}}
\citation{goodyear-smith_analysis_2012,ferguson_comment_2014}
\citation{vosgerau_99_2019}
\citation{stewart_ipd_2002}
\citation{lawrence_lesson_2021}
\@writefile{toc}{\contentsline {section}{\numberline {11.8}Which results should you report to be included in a future meta-analysis?}{257}{section.11.8}\protected@file@percent }
\newlabel{reportmeta}{{11.8}{257}{Which results should you report to be included in a future meta-analysis?}{section.11.8}{}}
\citation{lakens_reproducibility_2016}
\citation{polanin_transparency_2020}
\@writefile{toc}{\contentsline {section}{\numberline {11.9}Improving the reproducibility of meta-analyses}{258}{section.11.9}\protected@file@percent }
\newlabel{metareporting}{{11.9}{258}{Improving the reproducibility of meta-analyses}{section.11.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11.3}{\ignorespaces Six practical recommendations to improve the quality and reproducibility of meta-analyses.\relax }}{259}{table.caption.121}\protected@file@percent }
\newlabel{tab:table-rec1}{{11.3}{259}{Six practical recommendations to improve the quality and reproducibility of meta-analyses.\relax }{table.caption.121}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11.10}Test Yourself}{260}{section.11.10}\protected@file@percent }
\newlabel{test-yourself-9}{{11.10}{260}{Test Yourself}{section.11.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.12}{\ignorespaces Simulated studies under a random effects model.\relax }}{261}{figure.caption.122}\protected@file@percent }
\newlabel{fig:meta-sim-rand}{{11.12}{261}{Simulated studies under a random effects model.\relax }{figure.caption.122}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.13}{\ignorespaces Simulated studies under a fixed effect model.\relax }}{261}{figure.caption.123}\protected@file@percent }
\newlabel{fig:meta-sim-fixed}{{11.13}{261}{Simulated studies under a fixed effect model.\relax }{figure.caption.123}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.10.1}Open Questions}{262}{subsection.11.10.1}\protected@file@percent }
\newlabel{open-questions-9}{{11.10.1}{262}{Open Questions}{subsection.11.10.1}{}}
\citation{mayo_statistical_2018}
\citation{rogers_how_1992}
\citation{nuijten_prevalence_2015}
\citation{bishop_fallibility_2018}
\citation{brown_grim_2017}
\citation{greenwald_consequences_1975}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Bias detection}{264}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{bias}{{12}{264}{Bias detection}{chapter.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.1}{\ignorespaces Scene in The Dropout about the company Theranos that falsely claimed to have devices that could perform blood tests on very small amounts of blood. In the scene, two whistelblowers confront their bosses when they are pressured to remove datapoints that do not show the desired results.\relax }}{265}{figure.caption.124}\protected@file@percent }
\newlabel{fig:outliers}{{12.1}{265}{Scene in The Dropout about the company Theranos that falsely claimed to have devices that could perform blood tests on very small amounts of blood. In the scene, two whistelblowers confront their bosses when they are pressured to remove datapoints that do not show the desired results.\relax }{figure.caption.124}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.2}{\ignorespaces Screenshot of the table reporting the main results from Festinger and Carlsmith, 1959.\relax }}{265}{figure.caption.125}\protected@file@percent }
\newlabel{fig:festinger}{{12.2}{265}{Screenshot of the table reporting the main results from Festinger and Carlsmith, 1959.\relax }{figure.caption.125}{}}
\citation{chambers_past_2022,nosek_registered_2014}
\citation{scheel_excess_2021}
\citation{franco_publication_2014,greenwald_consequences_1975,sterling_publication_1959}
\citation{polanin_transparency_2020}
\citation{ropovik_neglect_2021}
\citation{carter_correcting_2019}
\@writefile{lof}{\contentsline {figure}{\numberline {12.3}{\ignorespaces Screenshot of the final sentences of Greenwald, A. G. (1975). Consequences of prejudice against the null hypothesis. Psychological Bulletin, 82(1), 1--20.\relax }}{266}{figure.caption.126}\protected@file@percent }
\newlabel{fig:greenwald}{{12.3}{266}{Screenshot of the final sentences of Greenwald, A. G. (1975). Consequences of prejudice against the null hypothesis. Psychological Bulletin, 82(1), 1--20.\relax }{figure.caption.126}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.1}Publication bias}{266}{section.12.1}\protected@file@percent }
\newlabel{publicationbias}{{12.1}{266}{Publication bias}{section.12.1}{}}
\citation{francis_frequency_2014,schimmack_ironic_2012}
\citation{francis_frequency_2014}
\citation{ioannidis_exploratory_2007}
\@writefile{lof}{\contentsline {figure}{\numberline {12.4}{\ignorespaces Positive result rates for standard reports and Registered Reports. Error bars indicate 95\% confidence intervals around the observed positive result rate.\relax }}{267}{figure.caption.127}\protected@file@percent }
\newlabel{fig:scheel}{{12.4}{267}{Positive result rates for standard reports and Registered Reports. Error bars indicate 95\% confidence intervals around the observed positive result rate.\relax }{figure.caption.127}{}}
\citation{jostmann_weight_2009}
\citation{ebersole_many_2016}
\citation{jostmann_short_2016}
\citation{becker_failsafe_2005}
\@writefile{toc}{\contentsline {section}{\numberline {12.2}Bias detection in meta-analysis}{268}{section.12.2}\protected@file@percent }
\newlabel{bias-detection-in-meta-analysis}{{12.2}{268}{Bias detection in meta-analysis}{section.12.2}{}}
\citation{scheel_excess_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {12.5}{\ignorespaces Funnel plot of unbiased null results.\relax }}{271}{figure.caption.128}\protected@file@percent }
\newlabel{fig:funnel1}{{12.5}{271}{Funnel plot of unbiased null results.\relax }{figure.caption.128}{}}
\citation{carter_publication_2014}
\citation{hagger_multilab_2016}
\citation{vohs_multisite_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {12.6}{\ignorespaces Funnel plot of biased null results with mostly significant results.\relax }}{272}{figure.caption.129}\protected@file@percent }
\newlabel{fig:funnel2}{{12.6}{272}{Funnel plot of biased null results with mostly significant results.\relax }{figure.caption.129}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.7}{\ignorespaces Funnel plot from Carter and McCullough (2014) vizualizing bias in 198 published tests of the ego-depletion effect.\relax }}{273}{figure.caption.130}\protected@file@percent }
\newlabel{fig:carterbias}{{12.7}{273}{Funnel plot from Carter and McCullough (2014) vizualizing bias in 198 published tests of the ego-depletion effect.\relax }{figure.caption.130}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.3}Trim and Fill}{273}{section.12.3}\protected@file@percent }
\newlabel{trim-and-fill}{{12.3}{273}{Trim and Fill}{section.12.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.8}{\ignorespaces Forest plot of unbiased meta-analysis (left) and biased meta-analysies (right).\relax }}{274}{figure.caption.131}\protected@file@percent }
\newlabel{fig:twoforestplot}{{12.8}{274}{Forest plot of unbiased meta-analysis (left) and biased meta-analysies (right).\relax }{figure.caption.131}{}}
\citation{peters_performance_2007,terrin_adjusting_2003}
\@writefile{lof}{\contentsline {figure}{\numberline {12.9}{\ignorespaces Funnel plot with assumed missing effects added through trim-and-fill.\relax }}{275}{figure.caption.132}\protected@file@percent }
\newlabel{fig:trimfill1}{{12.9}{275}{Funnel plot with assumed missing effects added through trim-and-fill.\relax }{figure.caption.132}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.4}PET-PEESE}{275}{section.12.4}\protected@file@percent }
\newlabel{pet-peese}{{12.4}{275}{PET-PEESE}{section.12.4}{}}
\citation{stanley_meta-regression_2014,stanley_finding_2017}
\citation{stanley_meta-regression_2014}
\citation{stanley_finding_2017}
\citation{simonsohn_p-curve_2014}
\citation{aert_correcting_2018}
\citation{iyengar_selection_1988}
\@writefile{toc}{\contentsline {section}{\numberline {12.5}\emph  {P}-value meta-analysis}{276}{section.12.5}\protected@file@percent }
\newlabel{p-value-meta-analysis}{{12.5}{276}{\texorpdfstring {\emph {P}-value meta-analysis}{P-value meta-analysis}}{section.12.5}{}}
\citation{simonsohn_p-curve_2014}
\@writefile{lof}{\contentsline {figure}{\numberline {12.10}{\ignorespaces Funnel plot with PETPEESE regression lines.\relax }}{277}{figure.caption.133}\protected@file@percent }
\newlabel{fig:petpeese}{{12.10}{277}{Funnel plot with PETPEESE regression lines.\relax }{figure.caption.133}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.11}{\ignorespaces Figure 3 from Simonsohn et al (2014) showing a \emph  {p}-curve with and without bias.\relax }}{278}{figure.caption.134}\protected@file@percent }
\newlabel{fig:pcurve}{{12.11}{278}{Figure 3 from Simonsohn et al (2014) showing a \emph {p}-curve with and without bias.\relax }{figure.caption.134}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.12}{\ignorespaces Result of the \emph  {p}-curve analysis of the biased studies.\relax }}{279}{figure.caption.135}\protected@file@percent }
\newlabel{fig:pcurveresult}{{12.12}{279}{Result of the \emph {p}-curve analysis of the biased studies.\relax }{figure.caption.135}{}}
\citation{bartos_z-curve20_2020,brunner_estimating_2020}
\citation{sotola_garbage_2022}
\citation{bartos_z-curve20_2020}
\@writefile{lof}{\contentsline {figure}{\numberline {12.13}{\ignorespaces \emph  {Z}-curve analysis for 1000 studies with a true effect size of 0 without publication bias.\relax }}{281}{figure.caption.136}\protected@file@percent }
\newlabel{fig:zcurveunbiasednull}{{12.13}{281}{\emph {Z}-curve analysis for 1000 studies with a true effect size of 0 without publication bias.\relax }{figure.caption.136}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.14}{\ignorespaces \emph  {Z}-curve analysis for 1000 studies with a true effect size of \emph  {d} = 0.37 and \emph  {n} = 100 per condition in an independent \emph  {t}-test without publication bias.\relax }}{282}{figure.caption.137}\protected@file@percent }
\newlabel{fig:zcurveunbiasedalternative}{{12.14}{282}{\emph {Z}-curve analysis for 1000 studies with a true effect size of \emph {d} = 0.37 and \emph {n} = 100 per condition in an independent \emph {t}-test without publication bias.\relax }{figure.caption.137}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.6}Conclusion}{283}{section.12.6}\protected@file@percent }
\newlabel{conclusion}{{12.6}{283}{Conclusion}{section.12.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12.7}Test Yourself}{284}{section.12.7}\protected@file@percent }
\newlabel{test-yourself-10}{{12.7}{284}{Test Yourself}{section.12.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.15}{\ignorespaces Funnel plot with PETPEESE regression lines for the same studies as in Q2.\relax }}{286}{figure.caption.138}\protected@file@percent }
\newlabel{fig:petpeeseq4}{{12.15}{286}{Funnel plot with PETPEESE regression lines for the same studies as in Q2.\relax }{figure.caption.138}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12.16}{\ignorespaces Result of the p-curve analysis of the biased studies in Q2.\relax }}{287}{figure.caption.139}\protected@file@percent }
\newlabel{fig:pcurveresultq5}{{12.16}{287}{Result of the p-curve analysis of the biased studies in Q2.\relax }{figure.caption.139}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.7.1}Open Questions}{289}{subsection.12.7.1}\protected@file@percent }
\newlabel{open-questions-10}{{12.7.1}{289}{Open Questions}{subsection.12.7.1}{}}
\citation{bem_feeling_2011}
\citation{kerr_harking_1998}
\citation{bakan_test_1966}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Preregistration and Transparency}{290}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{prereg}{{13}{290}{Preregistration and Transparency}{chapter.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces Screenshot from the Results and Discussion section of Bem, 2011.\relax }}{290}{figure.caption.140}\protected@file@percent }
\newlabel{fig:bem}{{13.1}{290}{Screenshot from the Results and Discussion section of Bem, 2011.\relax }{figure.caption.140}{}}
\citation{de_groot_methodology_1969}
\citation{goldacre_compliance_2018}
\citation{kaplan_likelihood_2015}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Preregistration of the Statistical Analysis Plan}{291}{section.13.1}\protected@file@percent }
\newlabel{preregistration-of-the-statistical-analysis-plan}{{13.1}{291}{Preregistration of the Statistical Analysis Plan}{section.13.1}{}}
\citation{chambers_past_2022,nosek_registered_2014}
\citation{wiseman_registered_2019}
\citation{scheel_excess_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {13.2}{\ignorespaces Figure from Kaplan and Irvin (2015) showing the substantial drop in statistically significant results after the registration of primary outcomes was required on ClinicalTrials.gov.\relax }}{292}{figure.caption.141}\protected@file@percent }
\newlabel{fig:kaplan2015}{{13.2}{292}{Figure from Kaplan and Irvin (2015) showing the substantial drop in statistically significant results after the registration of primary outcomes was required on ClinicalTrials.gov.\relax }{figure.caption.141}{}}
\citation{lakens_pandemic_2020}
\citation{lakens_is_2023}
\citation{lakens_value_2019}
\citation{lakens_value_2019}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}The value of preregistration}{293}{section.13.2}\protected@file@percent }
\newlabel{the-value-of-preregistration}{{13.2}{293}{The value of preregistration}{section.13.2}{}}
\citation{sarafoglou_survey_2022}
\citation{van_t_veer_pre-registration_2016}
\citation{wicherts_degrees_2016}
\citation{appelbaum_journal_2018}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}How to preregister}{294}{section.13.3}\protected@file@percent }
\newlabel{how-to-preregister}{{13.3}{294}{How to preregister}{section.13.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.3}{\ignorespaces Screenshot of Table 1 in Wicherts et al., 2016, which depicts the checklist for preregistrations.\relax }}{295}{figure.caption.142}\protected@file@percent }
\newlabel{fig:preregcheclist}{{13.3}{295}{Screenshot of Table 1 in Wicherts et al., 2016, which depicts the checklist for preregistrations.\relax }{figure.caption.142}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Journal Article Reporting Standards}{295}{section.13.4}\protected@file@percent }
\newlabel{journal-article-reporting-standards}{{13.4}{295}{Journal Article Reporting Standards}{section.13.4}{}}
\citation{leys_how_2019}
\citation{cooper_reporting_2020}
\citation{waldron_not_2022}
\@writefile{lof}{\contentsline {figure}{\numberline {13.4}{\ignorespaces Different study types plotted on a dimension from fully exploratory to fully confirmatory (from Waldron \& Allen, 2022).\relax }}{298}{figure.caption.143}\protected@file@percent }
\newlabel{fig:expconf}{{13.4}{298}{Different study types plotted on a dimension from fully exploratory to fully confirmatory (from Waldron \& Allen, 2022).\relax }{figure.caption.143}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.5}What Does a Formalized Analytic Strategy Look Like?}{298}{section.13.5}\protected@file@percent }
\newlabel{what-does-a-formalized-analytic-strategy-look-like}{{13.5}{298}{What Does a Formalized Analytic Strategy Look Like?}{section.13.5}{}}
\citation{lakens_improving_2020-2}
\citation{uygun_tunc_falsificationist_2022}
\@writefile{toc}{\contentsline {section}{\numberline {13.6}Are you ready to preregister a hypothesis test?}{299}{section.13.6}\protected@file@percent }
\newlabel{readytopreregister}{{13.6}{299}{Are you ready to preregister a hypothesis test?}{section.13.6}{}}
\citation{scheel_why_2021}
\@writefile{lof}{\contentsline {figure}{\numberline {13.5}{\ignorespaces Screenshot of a IMDB and metacritic rating.\relax }}{300}{figure.caption.144}\protected@file@percent }
\newlabel{fig:imdbrating}{{13.5}{300}{Screenshot of a IMDB and metacritic rating.\relax }{figure.caption.144}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.7}Test Yourself}{300}{section.13.7}\protected@file@percent }
\newlabel{test-yourself-11}{{13.7}{300}{Test Yourself}{section.13.7}{}}
\citation{maier_justify_2022}
\citation{wicherts_degrees_2016}
\citation{delacre_why_2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.7.1}Practical Aspects of an Online Preregistration}{303}{subsection.13.7.1}\protected@file@percent }
\newlabel{practical-aspects-of-an-online-preregistration}{{13.7.1}{303}{Practical Aspects of an Online Preregistration}{subsection.13.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.7.2}Pre-registering on PsychArchives by ZPID}{304}{subsection.13.7.2}\protected@file@percent }
\newlabel{pre-registering-on-psycharchives-by-zpid}{{13.7.2}{304}{Pre-registering on PsychArchives by ZPID}{subsection.13.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.7.3}Pre-registering on the Open Science Framework}{306}{subsection.13.7.3}\protected@file@percent }
\newlabel{pre-registering-on-the-open-science-framework}{{13.7.3}{306}{Pre-registering on the Open Science Framework}{subsection.13.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.7.4}Pre-registering on AsPredicted}{308}{subsection.13.7.4}\protected@file@percent }
\newlabel{pre-registering-on-aspredicted}{{13.7.4}{308}{Pre-registering on AsPredicted}{subsection.13.7.4}{}}
\citation{spellman_short_2015}
\citation{stodden_empirical_2018,obels_analysis_2020,hardwicke_data_2018,cruwell_whats_2023}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Computational Reproducibility}{310}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{computationalreproducibility}{{14}{310}{Computational Reproducibility}{chapter.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Step 1: Setting up a GitHub repository}{311}{section.14.1}\protected@file@percent }
\newlabel{step-1-setting-up-a-github-repository}{{14.1}{311}{Step 1: Setting up a GitHub repository}{section.14.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Step 2: Cloning your GitHub repository into RStudio}{313}{section.14.2}\protected@file@percent }
\newlabel{step-2-cloning-your-github-repository-into-rstudio}{{14.2}{313}{Step 2: Cloning your GitHub repository into RStudio}{section.14.2}{}}
\citation{bishop_fallibility_2018}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}Step 3: Creating an R Markdown file}{320}{section.14.3}\protected@file@percent }
\newlabel{step-3-creating-an-r-markdown-file}{{14.3}{320}{Step 3: Creating an R Markdown file}{section.14.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Step 4: Reproducible Data Analysis in R Studio}{324}{section.14.4}\protected@file@percent }
\newlabel{step-4-reproducible-data-analysis-in-r-studio}{{14.4}{324}{Step 4: Reproducible Data Analysis in R Studio}{section.14.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Step 5: Committing and Pushing to GitHub}{328}{section.14.5}\protected@file@percent }
\newlabel{step-5-committing-and-pushing-to-github}{{14.5}{328}{Step 5: Committing and Pushing to GitHub}{section.14.5}{}}
\citation{vuorre_curating_2018}
\@writefile{toc}{\contentsline {section}{\numberline {14.6}Step 6: Reproducible Data Analysis}{332}{section.14.6}\protected@file@percent }
\newlabel{step-6-reproducible-data-analysis}{{14.6}{332}{Step 6: Reproducible Data Analysis}{section.14.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6.1}Extra: APA formatted manuscripts in papaja}{337}{subsection.14.6.1}\protected@file@percent }
\newlabel{extra-apa-formatted-manuscripts-in-papaja}{{14.6.1}{337}{Extra: APA formatted manuscripts in papaja}{subsection.14.6.1}{}}
\citation{arslan_how_2019}
\@writefile{toc}{\contentsline {section}{\numberline {14.7}Step 7: Organizing Your Data and Code}{339}{section.14.7}\protected@file@percent }
\newlabel{step-7-organizing-your-data-and-code}{{14.7}{339}{Step 7: Organizing Your Data and Code}{section.14.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.8}Step 8: Archiving Your Data and Code}{339}{section.14.8}\protected@file@percent }
\newlabel{step-8-archiving-your-data-and-code}{{14.8}{339}{Step 8: Archiving Your Data and Code}{section.14.8}{}}
\citation{wiebels_leveraging_2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.8.1}EXTRA: Sharing Reproducible Code on Code Ocean}{344}{subsection.14.8.1}\protected@file@percent }
\newlabel{extra-sharing-reproducible-code-on-code-ocean}{{14.8.1}{344}{EXTRA: Sharing Reproducible Code on Code Ocean}{subsection.14.8.1}{}}
\citation{obels_analysis_2020}
\@writefile{toc}{\contentsline {section}{\numberline {14.9}Some points for improvement in computational reproducibility}{349}{section.14.9}\protected@file@percent }
\newlabel{some-points-for-improvement-in-computational-reproducibility}{{14.9}{349}{Some points for improvement in computational reproducibility}{section.14.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.10}Conclusion}{349}{section.14.10}\protected@file@percent }
\newlabel{conclusion-1}{{14.10}{349}{Conclusion}{section.14.10}{}}
\citation{gillon_medical_1994}
\citation{varkey_principles_2021}
\citation{komic_research_2015}
\citation{chalmers_avoidable_2009}
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Research Integrity}{350}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{integrity}{{15}{350}{Research Integrity}{chapter.15}{}}
\citation{van_de_schoot_use_2021}
\citation{edwards_academic_2017,anderson_perverse_2007}
\citation{wingen_no_2020,anvari_replicability_2018}
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Questionable Research Practices}{351}{section.15.1}\protected@file@percent }
\newlabel{QRP}{{15.1}{351}{Questionable Research Practices}{section.15.1}{}}
\citation{latan_crossing_2021,swift_questionable_2022,moran_i_2022,agnoli_questionable_2017,makel_both_2021,chin_questionable_2021,bakker_questionable_2021,motyl_state_2017,fiedler_questionable_2016,fraser_questionable_2018,john_measuring_2012,rabelo_questionable_2020}
\citation{motyl_state_2017}
\citation{lakens_value_2019}
\citation{wigboldus_encourage_2016}
\citation{scull_rosenhan_2023}
\citation{gopalakrishna_prevalence_2022}
\citation{bishop_fallibility_2018}
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Fabrication, Falsification, and Plagiarism}{352}{section.15.2}\protected@file@percent }
\newlabel{fabrication-falsification-and-plagiarism}{{15.2}{352}{Fabrication, Falsification, and Plagiarism}{section.15.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces Self-admittance of engaging in a questionable research practices at least once from 14 surveys among a variety of samples of researchers .\relax }}{353}{figure.caption.145}\protected@file@percent }
\newlabel{fig:qrp}{{15.1}{353}{Self-admittance of engaging in a questionable research practices at least once from 14 surveys among a variety of samples of researchers .\relax }{figure.caption.145}{}}
\citation{bird_self-plagiarism_2008}
\citation{pemberton_text_2019}
\citation{gopalakrishna_prevalence_2022}
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Informed consent and data privacy}{354}{section.15.3}\protected@file@percent }
\newlabel{informed-consent-and-data-privacy}{{15.3}{354}{Informed consent and data privacy}{section.15.3}{}}
\citation{hallinan_information_2023}
\citation{whitney_balanced_2016}
\@writefile{toc}{\contentsline {section}{\numberline {15.4}Conflicts of Interest}{355}{section.15.4}\protected@file@percent }
\newlabel{conflicts-of-interest}{{15.4}{355}{Conflicts of Interest}{section.15.4}{}}
\citation{caplan_how_2021}
\citation{moe_should_1984}
\@writefile{toc}{\contentsline {section}{\numberline {15.5}Research ethics}{356}{section.15.5}\protected@file@percent }
\newlabel{ethics}{{15.5}{356}{Research ethics}{section.15.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.6}Test Yourself}{356}{section.15.6}\protected@file@percent }
\newlabel{test-yourself-12}{{15.6}{356}{Test Yourself}{section.15.6}{}}
\citation{franco_publication_2014}
\citation{pickett_questionable_2017}
\@writefile{lof}{\contentsline {figure}{\numberline {15.2}{\ignorespaces Table from Pickett and Roche (2017) showing judgments of how moral selective reporting1 and data fraud are in the eyes of members of the general public.\relax }}{358}{figure.caption.146}\protected@file@percent }
\newlabel{fig:pickettroche}{{15.2}{358}{Table from Pickett and Roche (2017) showing judgments of how moral selective reporting1 and data fraud are in the eyes of members of the general public.\relax }{figure.caption.146}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.7}Grade Yourself}{358}{section.15.7}\protected@file@percent }
\newlabel{grade-yourself}{{15.7}{358}{Grade Yourself}{section.15.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {16}Glossary}{360}{chapter.16}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{glossary}{{16}{360}{Glossary}{chapter.16}{}}
\bibdata{include/book.bib,include/packages.bib}
\bibcite{abelson_value_2003}{{1}{2003}{{Abelson}}{{}}}
\bibcite{aberson_applied_2019}{{2}{2019}{{Aberson}}{{}}}
\bibcite{agnoli_questionable_2017}{{3}{2017}{{Agnoli et~al.}}{{}}}
\bibcite{albers_credible_2018}{{4}{2018}{{Albers et~al.}}{{}}}
\bibcite{albers_when_2018}{{5}{2018}{{Albers and Lakens}}{{}}}
\bibcite{aldrich_r_1997}{{6}{1997}{{Aldrich}}{{}}}
\bibcite{allison_power_1997}{{7}{1997}{{Allison et~al.}}{{}}}
\bibcite{altman_statistics_1995}{{8}{1995}{{Altman and Bland}}{{}}}
\bibcite{altoe_enhancing_2020}{{9}{2020}{{Alto{\`e} et~al.}}{{}}}
\bibcite{anderson_perverse_2007}{{10}{2007}{{Anderson et~al.}}{{}}}
\bibcite{anderson_sample-size_2017}{{11}{2017}{{Anderson et~al.}}{{}}}
\bibcite{anderson_theres_2016}{{12}{2016}{{Anderson and Maxwell}}{{}}}
\bibcite{anvari_not_2021}{{13}{2021}{{Anvari et~al.}}{{}}}
\bibcite{anvari_replicability_2018}{{14}{2018}{{Anvari and Lakens}}{{}}}
\bibcite{anvari_using_2021}{{15}{2021}{{Anvari and Lakens}}{{}}}
\bibcite{appelbaum_journal_2018}{{16}{2018}{{Appelbaum et~al.}}{{}}}
\bibcite{armitage_repeated_1969}{{17}{1969}{{Armitage et~al.}}{{}}}
\@writefile{toc}{\contentsline {fm}{Bibliography}{365}{chapter*.147}\protected@file@percent }
\bibcite{arslan_how_2019}{{18}{2019}{{Arslan}}{{}}}
\bibcite{babbage_reflections_1830}{{19}{1830}{{Babbage}}{{}}}
\bibcite{bacchetti_current_2010}{{20}{2010}{{Bacchetti}}{{}}}
\bibcite{baguley_understanding_2004}{{21}{2004}{{Baguley}}{{}}}
\bibcite{baguley_standardized_2009}{{22}{2009}{{Baguley}}{{}}}
\bibcite{baguley_serious_2012}{{23}{2012}{{Baguley}}{{}}}
\bibcite{bakan_test_1966}{{24}{1966}{{Bakan}}{{}}}
\bibcite{bakker_questionable_2021}{{25}{2021}{{Bakker et~al.}}{{}}}
\bibcite{ball_effects_2002}{{26}{2002}{{Ball et~al.}}{{}}}
\bibcite{barber_pitfalls_1976}{{27}{1976}{{Barber}}{{}}}
\bibcite{bartos_z-curve20_2020}{{28}{2020}{{Barto{\v s} and Schimmack}}{{}}}
\bibcite{bauer_unifying_1996}{{29}{1996}{{Bauer and Kieser}}{{}}}
\bibcite{bausell_power_2002}{{30}{2002}{{Bausell and Li}}{{}}}
\bibcite{becker_failsafe_2005}{{31}{2005}{{Becker}}{{}}}
\bibcite{bem_feeling_2011}{{32}{2011}{{Bem}}{{}}}
\bibcite{ben-shachar_effectsize_2020}{{33}{2020}{{{Ben-Shachar} et~al.}}{{}}}
\bibcite{bender_adjusting_2001}{{34}{2001}{{Bender and Lange}}{{}}}
\bibcite{benjamini_its_2016}{{35}{2016}{{Benjamini}}{{}}}
\bibcite{benjamini_controlling_1995}{{36}{1995}{{Benjamini and Hochberg}}{{}}}
\bibcite{berger_interplay_2004}{{37}{2004}{{Berger and Bayarri}}{{}}}
\bibcite{berkeley_defence_1735}{{38}{1735}{{Berkeley}}{{}}}
\bibcite{bird_self-plagiarism_2008}{{39}{2008}{{Bird and Sivilotti}}{{}}}
\bibcite{bishop_fallibility_2018}{{40}{2018}{{Bishop}}{{}}}
\bibcite{bland_introduction_2015}{{41}{2015}{{Bland}}{{}}}
\bibcite{borenstein_introduction_2009}{{42}{2009}{{Borenstein}}{{}}}
\bibcite{bosco_correlational_2015}{{43}{2015}{{Bosco et~al.}}{{}}}
\bibcite{bretz_multiple_2011}{{44}{2011}{{Bretz et~al.}}{{}}}
\bibcite{bross_critical_1971}{{45}{1971}{{Bross}}{{}}}
\bibcite{brown_errors_1983}{{46}{1983}{{Brown}}{{}}}
\bibcite{brown_grim_2017}{{47}{2017}{{Brown and Heathers}}{{}}}
\bibcite{brunner_estimating_2020}{{48}{2020}{{Brunner and Schimmack}}{{}}}
\bibcite{bryan_behavioural_2021}{{49}{2021}{{Bryan et~al.}}{{}}}
\bibcite{brysbaert_how_2019}{{50}{2019}{{Brysbaert}}{{}}}
\bibcite{brysbaert_power_2018}{{51}{2018}{{Brysbaert and Stevens}}{{}}}
\bibcite{buchanan_mote_2017}{{52}{2017}{{Buchanan et~al.}}{{}}}
\bibcite{bulus_bound_2021}{{53}{2021}{{Bulus and Dong}}{{}}}
\bibcite{burriss_changes_2015}{{54}{2015}{{Burriss et~al.}}{{}}}
\bibcite{button_power_2013}{{55}{2013}{{Button et~al.}}{{}}}
\bibcite{button_minimal_2015}{{56}{2015}{{Button et~al.}}{{}}}
\bibcite{caplan_how_2021}{{57}{2021}{{Caplan}}{{}}}
\bibcite{carter_publication_2014}{{58}{2014}{{Carter and McCullough}}{{}}}
\bibcite{carter_correcting_2019}{{59}{2019}{{Carter et~al.}}{{}}}
\bibcite{cascio_open_1983}{{60}{1983}{{Cascio and Zedeck}}{{}}}
\bibcite{cevolani_verisimilitude_2011}{{61}{2011}{{Cevolani et~al.}}{{}}}
\bibcite{chalmers_avoidable_2009}{{62}{2009}{{Chalmers and Glasziou}}{{}}}
\bibcite{chambers_past_2022}{{63}{2022}{{Chambers and Tzavella}}{{}}}
\bibcite{chang_adaptive_2016}{{64}{2016}{{Chang}}{{}}}
\bibcite{chatziathanasiou_beware_2022}{{65}{2022}{{Chatziathanasiou}}{{}}}
\bibcite{chin_questionable_2021}{{66}{2021}{{Chin et~al.}}{{}}}
\bibcite{cho_is_2013}{{67}{2013}{{Cho and Abe}}{{}}}
\bibcite{cohen_statistical_1988}{{68}{1988}{{Cohen}}{{}}}
\bibcite{cohen_things_1990}{{69}{1990}{{Cohen}}{{}}}
\bibcite{cohen_earth_1994}{{70}{1994}{{Cohen}}{{}}}
\bibcite{colling_registered_2020}{{71}{2020}{{Colling et~al.}}{{}}}
\bibcite{colquhoun_false_2019}{{72}{2019}{{Colquhoun}}{{}}}
\bibcite{cook_assessing_2014}{{73}{2014}{{Cook et~al.}}{{}}}
\bibcite{cook_p-value_2002}{{74}{2002}{{Cook}}{{}}}
\bibcite{cooper_reporting_2020}{{75}{2020}{{Cooper}}{{}}}
\bibcite{cooper_handbook_2009}{{76}{2009}{{Cooper et~al.}}{{}}}
\bibcite{copay_understanding_2007}{{77}{2007}{{Copay et~al.}}{{}}}
\bibcite{correll_avoid_2020}{{78}{2020}{{Correll et~al.}}{{}}}
\bibcite{cousineau_superb_2019}{{79}{2019}{{Cousineau and Chiasson}}{{}}}
\bibcite{cowles_origins_1982}{{80}{1982}{{Cowles and Davis}}{{}}}
\bibcite{cox_problems_1958}{{81}{1958}{{Cox}}{{}}}
\bibcite{cribbie_recommendations_2004}{{82}{2004}{{Cribbie et~al.}}{{}}}
\bibcite{cruwell_whats_2023}{{83}{2023}{{Cr{\"u}well et~al.}}{{}}}
\bibcite{cumming_replication_2008}{{84}{2008}{{Cumming}}{{}}}
\bibcite{cumming_understanding_2013}{{85}{2013}{{Cumming}}{{}}}
\bibcite{cumming_new_2014}{{86}{2014}{{Cumming}}{{}}}
\bibcite{cumming_introduction_2016}{{87}{2016}{{Cumming and {Calin-Jageman}}}{{}}}
\bibcite{cumming_confidence_2006}{{88}{2006}{{Cumming and Maillardet}}{{}}}
\bibcite{danziger_extraneous_2011}{{89}{2011}{{Danziger et~al.}}{{}}}
\bibcite{de_groot_methodology_1969}{{90}{1969}{{de Groot}}{{}}}
\bibcite{debruine_understanding_2021}{{91}{2021}{{DeBruine and Barr}}{{}}}
\bibcite{delacre_why_2021}{{92}{2021}{{Delacre et~al.}}{{}}}
\bibcite{delacre_why_2017}{{93}{2017}{{Delacre et~al.}}{{}}}
\bibcite{detsky_using_1990}{{94}{1990}{{Detsky}}{{}}}
\bibcite{dienes_understanding_2008}{{95}{2008}{{Dienes}}{{}}}
\bibcite{dienes_using_2014}{{96}{2014}{{Dienes}}{{}}}
\bibcite{dmitrienko_traditional_2013}{{97}{2013}{{Dmitrienko and D'Agostino~Sr}}{{}}}
\bibcite{dodge_method_1929}{{98}{1929}{{Dodge and Romig}}{{}}}
\bibcite{dubin_theory_1969}{{99}{1969}{{Dubin}}{{}}}
\bibcite{duhem_aim_1954}{{100}{1954}{{Duhem}}{{}}}
\bibcite{dunn_multiple_1961}{{101}{1961}{{Dunn}}{{}}}
\bibcite{dupont_sequential_1983}{{102}{1983}{{Dupont}}{{}}}
\bibcite{ebersole_many_2016}{{103}{2016}{{Ebersole et~al.}}{{}}}
\bibcite{eckermann_value_2010}{{104}{2010}{{Eckermann et~al.}}{{}}}
\bibcite{edwards_academic_2017}{{105}{2017}{{Edwards and Roy}}{{}}}
\bibcite{elson_press_2014}{{106}{2014}{{Elson et~al.}}{{}}}
\bibcite{erdfelder_gpower_1996}{{107}{1996}{{Erdfelder et~al.}}{{}}}
\bibcite{eysenck_exercise_1978}{{108}{1978}{{Eysenck}}{{}}}
\bibcite{fanelli_positive_2010}{{109}{2010}{{Fanelli}}{{}}}
\bibcite{faul_gpower_2007}{{110}{2007}{{Faul et~al.}}{{}}}
\bibcite{ferguson_comment_2014}{{111}{2014}{{Ferguson}}{{}}}
\bibcite{ferguson_vast_2012}{{112}{2012}{{Ferguson and Heene}}{{}}}
\bibcite{ferguson_providing_2021}{{113}{2021}{{Ferguson and Heene}}{{}}}
\bibcite{ferron_power_1996}{{114}{1996}{{Ferron and Onghena}}{{}}}
\bibcite{feyerabend_against_1993}{{115}{1993}{{Feyerabend}}{{}}}
\bibcite{feynman_cargo_1974}{{116}{1974}{{Feynman}}{{}}}
\bibcite{fiedler_tools_2004}{{117}{2004}{{Fiedler}}{{}}}
\bibcite{fiedler_questionable_2016}{{118}{2016}{{Fiedler and Schwarz}}{{}}}
\bibcite{field_minimizing_2004}{{119}{2004}{{Field et~al.}}{{}}}
\bibcite{fisher_design_1935}{{120}{1935}{{Fisher}}{{}}}
\bibcite{fisher_statistical_1956}{{121}{1956}{{Fisher}}{{}}}
\bibcite{fraley_n-pact_2014}{{122}{2014}{{Fraley and Vazire}}{{}}}
\bibcite{francis_frequency_2014}{{123}{2014}{{Francis}}{{}}}
\bibcite{franco_publication_2014}{{124}{2014}{{Franco et~al.}}{{}}}
\bibcite{fraser_questionable_2018}{{125}{2018}{{Fraser et~al.}}{{}}}
\bibcite{freiman_importance_1978}{{126}{1978}{{Freiman et~al.}}{{}}}
\bibcite{frick_appropriate_1996}{{127}{1996}{{Frick}}{{}}}
\bibcite{fricker_assessing_2019}{{128}{2019}{{Fricker et~al.}}{{}}}
\bibcite{fried_method_1993}{{129}{1993}{{Fried et~al.}}{{}}}
\bibcite{friede_sample_2006}{{130}{2006}{{Friede and Kieser}}{{}}}
\bibcite{fugard_supporting_2015}{{131}{2015}{{Fugard and Potts}}{{}}}
\bibcite{funder_evaluating_2019}{{132}{2019}{{Funder and Ozer}}{{}}}
\bibcite{gannon_blending_2019}{{133}{2019}{{Gannon et~al.}}{{}}}
\bibcite{gelman_beyond_2014}{{134}{2014}{{Gelman and Carlin}}{{}}}
\bibcite{gerring_mere_2012}{{135}{2012}{{Gerring}}{{}}}
\bibcite{gillon_medical_1994}{{136}{1994}{{Gillon}}{{}}}
\bibcite{glockner_irrational_2016}{{137}{2016}{{Gl{\"o}ckner}}{{}}}
\bibcite{glover_likelihood_2004}{{138}{2004}{{Glover and Dixon}}{{}}}
\bibcite{goldacre_compliance_2018}{{139}{2018}{{Goldacre et~al.}}{{}}}
\bibcite{good_bayesnon-bayes_1992}{{140}{1992}{{Good}}{{}}}
\bibcite{goodyear-smith_analysis_2012}{{141}{2012}{{{Goodyear-Smith} et~al.}}{{}}}
\bibcite{gopalakrishna_prevalence_2022}{{142}{2022}{{Gopalakrishna et~al.}}{{}}}
\bibcite{gosset_application_1904}{{143}{1904}{{Gosset}}{{}}}
\bibcite{gotz_small_2022}{{144}{2022}{{G{\"o}tz et~al.}}{{}}}
\bibcite{green_simr_2016}{{145}{2016}{{Green and MacLeod}}{{}}}
\bibcite{green_how_1991}{{146}{1991}{{Green}}{{}}}
\bibcite{greenland_statistical_2016}{{147}{2016}{{Greenland et~al.}}{{}}}
\bibcite{greenwald_consequences_1975}{{148}{1975}{{Greenwald}}{{}}}
\bibcite{grunwald_safe_2019}{{149}{2019}{{Gr{\"u}nwald et~al.}}{{}}}
\bibcite{gupta_intention_2011}{{150}{2011}{{Gupta}}{{}}}
\bibcite{hacking_logic_1965}{{151}{1965}{{Hacking}}{{}}}
\bibcite{hagger_multilab_2016}{{152}{2016}{{Hagger et~al.}}{{}}}
\bibcite{hallahan_statistical_1996}{{153}{1996}{{Hallahan and Rosenthal}}{{}}}
\bibcite{hallinan_information_2023}{{154}{2023}{{Hallinan et~al.}}{{}}}
\bibcite{halpern_sample_2001}{{155}{2001}{{Halpern et~al.}}{{}}}
\bibcite{halpern_continuing_2002}{{156}{2002}{{Halpern et~al.}}{{}}}
\bibcite{hand_deconstructing_1994}{{157}{1994}{{Hand}}{{}}}
\bibcite{hardwicke_data_2018}{{158}{2018}{{Hardwicke et~al.}}{{}}}
\bibcite{harms_making_2018}{{159}{2018}{{Harms and Lakens}}{{}}}
\bibcite{harrer_doing_2021}{{160}{2021}{{Harrer et~al.}}{{}}}
\bibcite{hauck_new_1984}{{161}{1984}{{Hauck and Anderson}}{{}}}
\bibcite{hedges_power_2001}{{162}{2001}{{Hedges and Pigott}}{{}}}
\bibcite{hempel_philosophy_1966}{{163}{1966}{{Hempel}}{{}}}
\bibcite{hilgard_maximal_2021}{{164}{2021}{{Hilgard}}{{}}}
\bibcite{hill_empirical_2008}{{165}{2008}{{Hill et~al.}}{{}}}
\bibcite{hodges_testing_1954}{{166}{1954}{{Hodges and Lehmann}}{{}}}
\bibcite{hoenig_abuse_2001}{{167}{2001}{{Hoenig and Heisey}}{{}}}
\bibcite{huedo-medina_assessing_2006}{{168}{2006}{{{Huedo-Medina} et~al.}}{{}}}
\bibcite{hung_behavior_1997}{{169}{1997}{{Hung et~al.}}{{}}}
\bibcite{hyde_gender_2008}{{170}{2008}{{Hyde et~al.}}{{}}}
\bibcite{ioannidis_why_2005}{{171}{2005}{{Ioannidis}}{{}}}
\bibcite{ioannidis_exploratory_2007}{{172}{2007}{{Ioannidis and Trikalinos}}{{}}}
\bibcite{iyengar_selection_1988}{{173}{1988}{{Iyengar and Greenhouse}}{{}}}
\bibcite{jaeschke_measurement_1989}{{174}{1989}{{Jaeschke et~al.}}{{}}}
\bibcite{jeffreys_theory_1939}{{175}{1939}{{Jeffreys}}{{}}}
\bibcite{jennison_group_2000}{{176}{2000}{{Jennison and Turnbull}}{{}}}
\bibcite{johansson_hail_2011}{{177}{2011}{{Johansson}}{{}}}
\bibcite{john_measuring_2012}{{178}{2012}{{John et~al.}}{{}}}
\bibcite{johnson_revised_2013}{{179}{2013}{{Johnson}}{{}}}
\bibcite{jones_test_1952}{{180}{1952}{{Jones}}{{}}}
\bibcite{jostmann_weight_2009}{{181}{2009}{{Jostmann et~al.}}{{}}}
\bibcite{jostmann_short_2016}{{182}{2016}{{Jostmann et~al.}}{{}}}
\bibcite{julious_sample_2004}{{183}{2004}{{Julious}}{{}}}
\bibcite{kaiser_directional_1960}{{184}{1960}{{Kaiser}}{{}}}
\bibcite{kaplan_likelihood_2015}{{185}{2015}{{Kaplan and Irvin}}{{}}}
\bibcite{kass_bayes_1995}{{186}{1995}{{Kass and Raftery}}{{}}}
\bibcite{keefe_defining_2013}{{187}{2013}{{Keefe et~al.}}{{}}}
\bibcite{kelley_confidence_2007}{{188}{2007}{{Kelley}}{{}}}
\bibcite{kelley_effect_2012}{{189}{2012}{{Kelley and Preacher}}{{}}}
\bibcite{kelley_sample_2006}{{190}{2006}{{Kelley and Rausch}}{{}}}
\bibcite{kenett_information_2016}{{191}{2016}{{Kenett et~al.}}{{}}}
\bibcite{kennedy-shaffer_before_2019}{{192}{2019}{{Kennedy-Shaffer}}{{}}}
\bibcite{kenny_unappreciated_2019}{{193}{2019}{{Kenny and Judd}}{{}}}
\bibcite{keppel_design_1991}{{194}{1991}{{Keppel}}{{}}}
\bibcite{kerr_harking_1998}{{195}{1998}{{Kerr}}{{}}}
\bibcite{king_point_2011}{{196}{2011}{{King}}{{}}}
\bibcite{kish_survey_1965}{{197}{1965}{{Kish}}{{}}}
\bibcite{komic_research_2015}{{198}{2015}{{Komi{\'c} et~al.}}{{}}}
\bibcite{kraft_interpreting_2020}{{199}{2020}{{Kraft}}{{}}}
\bibcite{kruschke_bayesian_2011}{{200}{2011}{{Kruschke}}{{}}}
\bibcite{kruschke_bayesian_2013}{{201}{2013}{{Kruschke}}{{}}}
\bibcite{kruschke_doing_2014}{{202}{2014}{{Kruschke}}{{}}}
\bibcite{kruschke_rejecting_2018}{{203}{2018}{{Kruschke}}{{}}}
\bibcite{kruschke_bayesian_2017}{{204}{2017}{{Kruschke and Liddell}}{{}}}
\bibcite{kuhn_structure_1962}{{205}{1962}{{Kuhn}}{{}}}
\bibcite{kuipers_models_2016}{{206}{2016}{{Kuipers}}{{}}}
\bibcite{lakatos_methodology_1978}{{207}{1978}{{Lakatos}}{{}}}
\bibcite{lakens_calculating_2013}{{208}{2013}{{Lakens}}{{}}}
\bibcite{lakens_performing_2014}{{209}{2014}{{Lakens}}{{}}}
\bibcite{lakens_equivalence_2017}{{210}{2017}{{Lakens}}{{}}}
\bibcite{lakens_value_2019}{{211}{2019}{{Lakens}}{{}}}
\bibcite{lakens_pandemic_2020}{{212}{2020}{{Lakens}}{{}}}
\bibcite{lakens_practical_2021}{{213}{2021}{{Lakens}}{{}}}
\bibcite{lakens_sample_2022}{{214}{2022a}{{Lakens}}{{}}}
\bibcite{lakens_why_2022}{{215}{2022b}{{Lakens}}{{}}}
\bibcite{lakens_is_2023}{{216}{2023}{{Lakens}}{{}}}
\bibcite{lakens_justify_2018}{{217}{2018a}{{Lakens et~al.}}{{}}}
\bibcite{lakens_simulation-based_2021}{{218}{2021}{{Lakens and Caldwell}}{{}}}
\bibcite{lakens_improving_2020-2}{{219}{2020}{{Lakens and DeBruine}}{{}}}
\bibcite{lakens_too_2017}{{220}{2017}{{Lakens and Etz}}{{}}}
\bibcite{lakens_reproducibility_2016}{{221}{2016}{{Lakens et~al.}}{{}}}
\bibcite{lakens_improving_2020}{{222}{2020}{{Lakens et~al.}}{{}}}
\bibcite{lakens_equivalence_2018}{{223}{2018b}{{Lakens et~al.}}{{}}}
\bibcite{lan_discrete_1983}{{224}{1983}{{Lan and DeMets}}{{}}}
\bibcite{latan_crossing_2021}{{225}{2021}{{Latan et~al.}}{{}}}
\bibcite{laudan_science_1981}{{226}{1981}{{Laudan}}{{}}}
\bibcite{laudan_science_1986}{{227}{1986}{{Laudan}}{{}}}
\bibcite{lawrence_lesson_2021}{{228}{2021}{{Lawrence et~al.}}{{}}}
\bibcite{leamer_specification_1978}{{229}{1978}{{Leamer}}{{}}}
\bibcite{lehmann_testing_2005}{{230}{2005}{{Lehmann and Romano}}{{}}}
\bibcite{lenth_practical_2001}{{231}{2001}{{Lenth}}{{}}}
\bibcite{lenth_post_2007}{{232}{2007}{{Lenth}}{{}}}
\bibcite{leon_role_2011}{{233}{2011}{{Leon et~al.}}{{}}}
\bibcite{levine_communication_2008}{{234}{2008}{{Levine et~al.}}{{}}}
\bibcite{leys_how_2019}{{235}{2019}{{Leys et~al.}}{{}}}
\bibcite{linden_heterogeneity_2021}{{236}{2021}{{Linden and H{\"o}nekopp}}{{}}}
\bibcite{lindley_statistical_1957}{{237}{1957}{{Lindley}}{{}}}
\bibcite{lindsay_replication_2015}{{238}{2015}{{Lindsay}}{{}}}
\bibcite{louis_effective_2009}{{239}{2009}{{Louis and Zeger}}{{}}}
\bibcite{lovakov_empirically_2021}{{240}{2021}{{Lovakov and Agadullina}}{{}}}
\bibcite{luttrell_replicating_2017}{{241}{2017}{{Luttrell et~al.}}{{}}}
\bibcite{maier_justify_2022}{{242}{2022}{{Maier and Lakens}}{{}}}
\bibcite{makel_both_2021}{{243}{2021}{{Makel et~al.}}{{}}}
\bibcite{marshall_does_2013}{{244}{2013}{{Marshall et~al.}}{{}}}
\bibcite{maxwell_designing_2004}{{245}{2004}{{Maxwell and Delaney}}{{}}}
\bibcite{maxwell_designing_2017}{{246}{2017}{{Maxwell et~al.}}{{}}}
\bibcite{maxwell_ethics_2011}{{247}{2011}{{Maxwell and Kelley}}{{}}}
\bibcite{maxwell_sample_2008}{{248}{2008}{{Maxwell et~al.}}{{}}}
\bibcite{mayo_statistical_2018}{{249}{2018}{{Mayo}}{{}}}
\bibcite{mazzolari_myths_2022}{{250}{2022}{{Mazzolari et~al.}}{{}}}
\bibcite{mccarthy_registered_2018}{{251}{2018}{{McCarthy et~al.}}{{}}}
\bibcite{mcelreath_statistical_2016}{{252}{2016}{{McElreath}}{{}}}
\bibcite{mcgrath_when_2006}{{253}{2006}{{McGrath and Meyer}}{{}}}
\bibcite{mcgraw_common_1992}{{254}{1992}{{McGraw and Wong}}{{}}}
\bibcite{mcguire_perspectivist_2004}{{255}{2004}{{McGuire}}{{}}}
\bibcite{mcintosh_power_2021}{{256}{2021}{{McIntosh and Rittmo}}{{}}}
\bibcite{meehl-theory-testing_1967}{{257}{1967}{{Meehl}}{{}}}
\bibcite{meehl_theoretical_1978}{{258}{1978}{{Meehl}}{{}}}
\bibcite{meehl_appraising_1990}{{259}{1990a}{{Meehl}}{{}}}
\bibcite{meehl_why_1990}{{260}{1990b}{{Meehl}}{{}}}
\bibcite{meehl_cliometric_2004}{{261}{2004}{{Meehl}}{{}}}
\bibcite{melara_driven_2003}{{262}{2003}{{Melara and Algom}}{{}}}
\bibcite{mellers_frequency_2001}{{263}{2001}{{Mellers et~al.}}{{}}}
\bibcite{meyners_equivalence_2012}{{264}{2012}{{Meyners}}{{}}}
\bibcite{meyvis_increasing_2018}{{265}{2018}{{Meyvis and Van~Osselaer}}{{}}}
\bibcite{millar_maximum_2011}{{266}{2011}{{Millar}}{{}}}
\bibcite{miller_what_2009}{{267}{2009}{{Miller}}{{}}}
\bibcite{miller_quest_2019}{{268}{2019}{{Miller and Ulrich}}{{}}}
\bibcite{moe_should_1984}{{269}{1984}{{Moe}}{{}}}
\bibcite{moran_i_2022}{{270}{2022}{{Moran et~al.}}{{}}}
\bibcite{morey_power_2020}{{271}{2020}{{Morey}}{{}}}
\bibcite{morey_fallacy_2016}{{272}{2016}{{Morey et~al.}}{{}}}
\bibcite{morey_pre-registered_2021}{{273}{2021}{{Morey et~al.}}{{}}}
\bibcite{morris_using_2019}{{274}{2019}{{Morris et~al.}}{{}}}
\bibcite{morse_significance_1995}{{275}{1995}{{Morse}}{{}}}
\bibcite{moshontz_psychological_2018}{{276}{2018}{{Moshontz et~al.}}{{}}}
\bibcite{motyl_state_2017}{{277}{2017}{{Motyl et~al.}}{{}}}
\bibcite{mrozek_what_2002}{{278}{2002}{{Mrozek and Taylor}}{{}}}
\bibcite{mudge_setting_2012}{{279}{2012}{{Mudge et~al.}}{{}}}
\bibcite{mullan_town_1985}{{280}{1985}{{Mullan and Jacoby}}{{}}}
\bibcite{murphy_testing_1999}{{281}{1999}{{Murphy and Myors}}{{}}}
\bibcite{murphy_statistical_2014}{{282}{2014}{{Murphy et~al.}}{{}}}
\bibcite{neyman_inductive_1957}{{283}{1957}{{Neyman}}{{}}}
\bibcite{neyman_problem_1933}{{284}{1933}{{Neyman and Pearson}}{{}}}
\bibcite{nickerson_null_2000}{{285}{2000}{{Nickerson}}{{}}}
\bibcite{niiniluoto_verisimilitude_1998}{{286}{1998}{{Niiniluoto}}{{}}}
\bibcite{niiniluoto_critical_1999}{{287}{1999}{{Niiniluoto}}{{}}}
\bibcite{norman_truly_2004}{{288}{2004}{{Norman et~al.}}{{}}}
\bibcite{nosek_registered_2014}{{289}{2014}{{Nosek and Lakens}}{{}}}
\bibcite{nuijten_prevalence_2015}{{290}{2015}{{Nuijten et~al.}}{{}}}
\bibcite{nunnally_place_1960}{{291}{1960}{{Nunnally}}{{}}}
\bibcite{obels_analysis_2020}{{292}{2020}{{Obels et~al.}}{{}}}
\bibcite{oddie_content_2013}{{293}{2013}{{Oddie}}{{}}}
\bibcite{odonnell_registered_2018}{{294}{2018}{{O'Donnell et~al.}}{{}}}
\bibcite{okada_is_2013}{{295}{2013}{{Okada}}{{}}}
\bibcite{olejnik_generalized_2003}{{296}{2003}{{Olejnik and Algina}}{{}}}
\bibcite{olsson-collentine_heterogeneity_2020}{{297}{2020}{{{Olsson-Collentine} et~al.}}{{}}}
\bibcite{open_science_collaboration_estimating_2015}{{298}{2015}{{Open Science Collaboration}}{{}}}
\bibcite{orben_crud_2020}{{299}{2020}{{Orben and Lakens}}{{}}}
\bibcite{parker_sample_2003}{{300}{2003}{{Parker and Berman}}{{}}}
\bibcite{parkhurst_statistical_2001}{{301}{2001}{{Parkhurst}}{{}}}
\bibcite{parsons_psychological_2019}{{302}{2019}{{Parsons et~al.}}{{}}}
\bibcite{pawitan_all_2001}{{303}{2001}{{Pawitan}}{{}}}
\bibcite{pemberton_text_2019}{{304}{2019}{{Pemberton et~al.}}{{}}}
\bibcite{perneger_whats_1998}{{305}{1998}{{Perneger}}{{}}}
\bibcite{perugini_safeguard_2014}{{306}{2014}{{Perugini et~al.}}{{}}}
\bibcite{perugini_practical_2018}{{307}{2018}{{Perugini et~al.}}{{}}}
\bibcite{peters_performance_2007}{{308}{2007}{{Peters et~al.}}{{}}}
\bibcite{phillips_statistical_2001}{{309}{2001}{{Phillips et~al.}}{{}}}
\bibcite{pickett_questionable_2017}{{310}{2017}{{Pickett and Roche}}{{}}}
\bibcite{platt_strong_1964}{{311}{1964}{{Platt}}{{}}}
\bibcite{pocock_group_1977}{{312}{1977}{{Pocock}}{{}}}
\bibcite{polanin_transparency_2020}{{313}{2020}{{Polanin et~al.}}{{}}}
\bibcite{popper_logic_2002}{{314}{2002}{{Popper}}{{}}}
\bibcite{primbs_are_2022}{{315}{2022}{{Primbs et~al.}}{{}}}
\bibcite{proschan_two-stage_2005}{{316}{2005}{{Proschan}}{{}}}
\bibcite{proschan_statistical_2006}{{317}{2006}{{Proschan et~al.}}{{}}}
\bibcite{psillos_scientific_1999}{{318}{1999}{{Psillos}}{{}}}
\bibcite{quertemont_how_2011}{{319}{2011}{{Quertemont}}{{}}}
\bibcite{rabelo_questionable_2020}{{320}{2020}{{Rabelo et~al.}}{{}}}
\bibcite{rice_heads_1994}{{321}{1994}{{Rice and Gaines}}{{}}}
\bibcite{richard_one_2003}{{322}{2003}{{Richard et~al.}}{{}}}
\bibcite{richardson_eta_2011}{{323}{2011}{{Richardson}}{{}}}
\bibcite{rogers_using_1993}{{324}{1993}{{Rogers et~al.}}{{}}}
\bibcite{rogers_how_1992}{{325}{1992}{{Rogers}}{{}}}
\bibcite{ropovik_neglect_2021}{{326}{2021}{{Ropovik et~al.}}{{}}}
\bibcite{rosenthal_contrasts_2000}{{327}{2000}{{Rosenthal et~al.}}{{}}}
\bibcite{royall_statistical_1997}{{328}{1997}{{Royall}}{{}}}
\bibcite{rozeboom_fallacy_1960}{{329}{1960}{{Rozeboom}}{{}}}
\bibcite{rucker_undue_2008}{{330}{2008}{{R{\"u}cker et~al.}}{{}}}
\bibcite{sarafoglou_survey_2022}{{331}{2022}{{Sarafoglou et~al.}}{{}}}
\bibcite{scheel_excess_2021}{{332}{2021a}{{Scheel et~al.}}{{}}}
\bibcite{scheel_why_2021}{{333}{2021b}{{Scheel et~al.}}{{}}}
\bibcite{schimmack_ironic_2012}{{334}{2012}{{Schimmack}}{{}}}
\bibcite{schnuerch_controlling_2020}{{335}{2020}{{Schnuerch and Erdfelder}}{{}}}
\bibcite{schoemann_determining_2017}{{336}{2017}{{Schoemann et~al.}}{{}}}
\bibcite{schonbrodt_sequential_2017}{{337}{2017}{{Sch{\"o}nbrodt et~al.}}{{}}}
\bibcite{schuirmann_comparison_1987}{{338}{1987}{{Schuirmann}}{{}}}
\bibcite{schulz_sample_2005}{{339}{2005}{{Schulz and Grimes}}{{}}}
\bibcite{schumi_through_2011}{{340}{2011}{{Schumi and Wittes}}{{}}}
\bibcite{schweder_confidence_2016}{{341}{2016}{{Schweder and Hjort}}{{}}}
\bibcite{scull_rosenhan_2023}{{342}{2023}{{Scull}}{{}}}
\bibcite{seaman_equivalence_1998}{{343}{1998}{{Seaman and Serlin}}{{}}}
\bibcite{sedlmeier_studies_1989}{{344}{1989}{{Sedlmeier and Gigerenzer}}{{}}}
\bibcite{shmueli_explain_2010}{{345}{2010}{{Shmueli}}{{}}}
\bibcite{simmons_false-positive_2011}{{346}{2011}{{Simmons et~al.}}{{}}}
\bibcite{simmons_life_2013}{{347}{2013}{{Simmons et~al.}}{{}}}
\bibcite{simonsohn_small_2015}{{348}{2015}{{Simonsohn}}{{}}}
\bibcite{simonsohn_p-curve_2014}{{349}{2014}{{Simonsohn et~al.}}{{}}}
\bibcite{smithson_confidence_2003}{{350}{2003}{{Smithson}}{{}}}
\bibcite{sotola_garbage_2022}{{351}{2022}{{Sotola}}{{}}}
\bibcite{spanos_who_2013}{{352}{2013}{{Spanos}}{{}}}
\bibcite{spellman_short_2015}{{353}{2015}{{Spellman}}{{}}}
\bibcite{spiegelhalter_art_2019}{{354}{2019}{{Spiegelhalter}}{{}}}
\bibcite{spiegelhalter_monitoring_1986}{{355}{1986}{{Spiegelhalter et~al.}}{{}}}
\bibcite{stanley_meta-regression_2014}{{356}{2014}{{Stanley and Doucouliagos}}{{}}}
\bibcite{stanley_finding_2017}{{357}{2017}{{Stanley et~al.}}{{}}}
\bibcite{steiger_beyond_2004}{{358}{2004}{{Steiger}}{{}}}
\bibcite{sterling_publication_1959}{{359}{1959}{{Sterling}}{{}}}
\bibcite{stewart_ipd_2002}{{360}{2002}{{Stewart and Tierney}}{{}}}
\bibcite{stodden_empirical_2018}{{361}{2018}{{Stodden et~al.}}{{}}}
\bibcite{stroebe_alleged_2014}{{362}{2014}{{Stroebe and Strack}}{{}}}
\bibcite{stroop_studies_1935}{{363}{1935}{{Stroop}}{{}}}
\bibcite{swift_questionable_2022}{{364}{2022}{{Swift et~al.}}{{}}}
\bibcite{taper_philosophy_2011}{{365}{2011}{{Taper and Lele}}{{}}}
\bibcite{taylor_bias_1996}{{366}{1996}{{Taylor and Muller}}{{}}}
\bibcite{teare_sample_2014}{{367}{2014}{{Teare et~al.}}{{}}}
\bibcite{tendeiro_review_2019}{{368}{2019}{{Tendeiro and Kiers}}{{}}}
\bibcite{ter_schure_accumulation_2019}{{369}{2019}{{{ter Schure} and Gr{\"u}nwald}}{{}}}
\bibcite{terrin_adjusting_2003}{{370}{2003}{{Terrin et~al.}}{{}}}
\bibcite{thompson_effect_2007}{{371}{2007}{{Thompson}}{{}}}
\bibcite{tversky_features_1977}{{372}{1977}{{Tversky}}{{}}}
\bibcite{tversky_belief_1971}{{373}{1971}{{Tversky and Kahneman}}{{}}}
\bibcite{ulrich_properties_2018}{{374}{2018}{{Ulrich and Miller}}{{}}}
\bibcite{uygun_tunc_falsificationist_2022}{{375}{2022}{{Uygun~Tun{\c c} and Tun{\c c}}}{{}}}
\bibcite{uygun_tunc_epistemic_2021}{{376}{2021}{{Uygun~Tun{\c c} et~al.}}{{}}}
\bibcite{valentine_how_2010}{{377}{2010}{{Valentine et~al.}}{{}}}
\bibcite{aert_correcting_2018}{{378}{2018}{{van Aert and van Assen}}{{}}}
\bibcite{van_de_schoot_use_2021}{{379}{2021}{{{van de Schoot} et~al.}}{{}}}
\bibcite{dongen_multiple_2019}{{380}{2019}{{van Dongen et~al.}}{{}}}
\bibcite{van_fraassen_scientific_1980}{{381}{1980}{{Van~Fraassen}}{{}}}
\bibcite{rijnsoever_i_2017}{{382}{2017}{{van Rijnsoever}}{{}}}
\bibcite{van_t_veer_pre-registration_2016}{{383}{2016}{{{van 't Veer} and {Giner-Sorolla}}}{{}}}
\bibcite{varkey_principles_2021}{{384}{2021}{{Varkey}}{{}}}
\bibcite{verschuere_registered_2018}{{385}{2018}{{Verschuere et~al.}}{{}}}
\bibcite{viamonte_cost-benefit_2006}{{386}{2006}{{Viamonte et~al.}}{{}}}
\bibcite{viechtbauer_conducting_2010}{{387}{2010}{{Viechtbauer}}{{}}}
\bibcite{vohs_multisite_2021}{{388}{2021}{{Vohs et~al.}}{{}}}
\bibcite{vosgerau_99_2019}{{389}{2019}{{Vosgerau et~al.}}{{}}}
\bibcite{vuorre_curating_2018}{{390}{2018}{{Vuorre and Curley}}{{}}}
\bibcite{wacholder_assessing_2004}{{391}{2004}{{Wacholder et~al.}}{{}}}
\bibcite{wagenmakers_practical_2007}{{392}{2007}{{Wagenmakers}}{{}}}
\bibcite{wagenmakers_registered_2016}{{393}{2016}{{Wagenmakers et~al.}}{{}}}
\bibcite{wald_sequential_1945}{{394}{1945}{{Wald}}{{}}}
\bibcite{waldron_not_2022}{{395}{2022}{{Waldron and Allen}}{{}}}
\bibcite{wassmer_group_2016}{{396}{2016}{{Wassmer and Brannath}}{{}}}
\bibcite{weinshall-margel_overlooked_2011}{{397}{2011}{{{Weinshall-Margel} and Shapard}}{{}}}
\bibcite{wellek_testing_2010}{{398}{2010}{{Wellek}}{{}}}
\bibcite{westberg_combining_1985}{{399}{1985}{{Westberg}}{{}}}
\bibcite{westfall_statistical_2014}{{400}{2014}{{Westfall et~al.}}{{}}}
\bibcite{westlake_use_1972}{{401}{1972}{{Westlake}}{{}}}
\bibcite{whitney_balanced_2016}{{402}{2016}{{Whitney}}{{}}}
\bibcite{wicherts_degrees_2016}{{403}{2016}{{Wicherts et~al.}}{{}}}
\bibcite{wiebels_leveraging_2021}{{404}{2021}{{Wiebels and Moreau}}{{}}}
\bibcite{wigboldus_encourage_2016}{{405}{2016}{{Wigboldus and Dotsch}}{{}}}
\bibcite{williams_impact_1995}{{406}{1995}{{Williams et~al.}}{{}}}
\bibcite{wilson_practical_2015}{{407}{2015}{{Wilson}}{{}}}
\bibcite{wilson_vanvoorhis_understanding_2007}{{408}{2007}{{Wilson~VanVoorhis and Morgan}}{{}}}
\bibcite{winer_statistical_1962}{{409}{1962}{{Winer}}{{}}}
\bibcite{wingen_no_2020}{{410}{2020}{{Wingen et~al.}}{{}}}
\bibcite{wiseman_registered_2019}{{411}{2019}{{Wiseman et~al.}}{{}}}
\bibcite{wittes_role_1990}{{412}{1990}{{Wittes and Brittain}}{{}}}
\bibcite{wong_potential_2022}{{413}{2022}{{Wong et~al.}}{{}}}
\bibcite{wynants_prediction_2020}{{414}{2020}{{Wynants et~al.}}{{}}}
\bibcite{yarkoni_choosing_2017}{{415}{2017}{{Yarkoni and Westfall}}{{}}}
\bibcite{yuan_post_2005}{{416}{2005}{{Yuan and Maxwell}}{{}}}
\bibcite{zabell_r_1992}{{417}{1992}{{Zabell}}{{}}}
\bibcite{zumbo_note_1998}{{418}{1998}{{Zumbo and Hubley}}{{}}}
\gdef \@abspage@last{403}
